Знакомство с машинным обучением

Меня зовут Евгений Соколов, и я рад приветствовать вас на курсе «Обучение на размеченных данных». Это второй курс специализации «Машинное обучение и анализ данных», в котором мы начнем знакомиться, собственно, с машинным обучением. Центральной темой этого курса является обучение с учителем. На самом деле, мы немного затрагивали эту тему, когда говорили про интерполяцию в прошлом курсе. Интерполяция — это значит восстановление функции по нескольким точкам, в которых известны ее значения. Обучение с учителем — это тоже восстановление общей закономерности по конечному числу примеров. Хотя постановки задач похожи, у них есть много отличий в том, как они решаются и какие требования выдвигаются к решению. Мы будем обсуждать эти различия в нашем курсе. Давайте разберем не очень сложный пример, на котором поймем, в чем заключается обучение с учителем и машинное обучение. Представьте, что у нас есть некоторый сайт про фильмы, на который можно зайти, найти страницу нужного фильма, почитать про него, когда он снят, кто в нем играет, какой бюджет был у этого фильма и, возможно, даже купить его и посмотреть. И есть некоторый пользователь, который заходит на наш сайт, находит страницу нужного ему фильма, читает и задается вопросом, смотреть или не смотреть, интересен ему этот фильм или не интересен. И мы хотим понять это за него. Как это можно сделать? Есть несколько подходов к решению. Подход первый, самый глупый — это дать пользователю посмотреть этот фильм. Понятно, что он потратит 1,5–2 часа, фильм может не понравится, он будет недоволен. Подход второй — показывать ему случайную рекомендацию. То есть говорить понравится или не понравится просто из генератора случайных чисел. Подход тоже не самый лучший: пользователь может смотреть фильм, он опять ему не понравится, и он будет недоволен нашим сайтом. Наконец, можно пригласить психолога-киномана разрешить ситуацию. Этот человек оценит пользователя, поймет, что ему нравится, а что — нет, оценит фильм, вспомнит про него всё и поймет, кому он может нравиться, сопоставит эту информацию и выдаст пользователю рекомендацию, смотреть или не смотреть. Этот подход довольно сложный. Скорее всего, таких специалистов не очень много в мире, и будет сложно отмасштабировать это на миллионы пользователей нашего сайта. Но на самом деле это и не нужно. Давайте поймем, что у нас много примеров, много ситуаций, когда другие пользователи заходили на страницу фильмов, принимали решение посмотреть фильм и дальше ставили оценку, по которой можно понять, понравилось им или не понравилось. Это примеры, та информация, из которой можно восстановить общую зависимость. В этом и заключается задача машинного обучения. Давайте введем пару обозначений, которыми мы будем пользоваться в нашем курсе. Машинное обучение — это раздел математики, поэтому в нем, конечно же, есть место формулам. Объектом будем называть то, для чего нужно сделать предсказание. В нашем примере объектом является пара, состоящая из пользователя и фильма, и для нее нужно предсказать, понравится ли этот фильм этому пользователю. Объекты будем обозначать маленькой буквой x. Далее, пространство объектов — это множество всех возможных объектов, для которых может понадобиться делать предсказание. В нашем случае это множество всех возможных пар «пользователь-фильм». Пространство объектов будем обозначать буквой x красивое. Ответом будем называть то, что нужно предсказать. В нашем случае ответ — это понравится пользователю фильм или не понравится. Обозначать ответы будем маленькой буквой y. Наконец, пространство ответов — это множество всех возможных ответов, с которыми мы можем работать. В нашем примере это множество состоит из двух элементов: −1 и +1. −1 означает, что пользователю фильм не понравился, +1 означает, что пользователю фильм понравился. Обозначать пространство ответов будем буквой y красивое. Как мы уже выясняли с вами в прошлом курсе, объекты — это сущности из реального мира, а компьютер не понимает, что это такое, он не знает, что такое пользователь или фильм, ему нужно объяснить эти объекты с помощью чисел, которые компьютер уже может понимать. Признак — это некая числовая характеристика объекта, а совокупность всех признаков, которых d штук, называется признаковым описанием объекта. Кстати, хотя я говорю, что признак — это число, мы с вами увидим, что есть и другие случаи, когда признак — это элемент множества, или строка, или что-то еще, но всё это — нечто, понятное компьютеру. Признаковое описание — это d-мерный вектор и можно с ним работать как с вектором, складывать, умножать на числа и так далее, то есть это — некий объект линейной алгебры. В нашем примере признаки могут быть самые разные: прошлые оценки этого пользователя другим фильмам; его анкетные данные; оценки, которые другие пользователи ставили этому фильму и так далее. Центральным понятием машинного обучения является обучающая выборка. Это то, это те примеры, на основе которых мы будем строить общую закономерность. Обучающая выборка обозначается большой буквой X и состоит из l пар объектов и ответов. xi-тое — это i-тый объект обучающей выборки, yi-тое — это истинный ответ на нем, то, что нужно предсказать. Иногда отдельный большой вопрос — это как собрать обучающую выборку, откуда ее взять. В нашем случае это довольно просто: она будет состоять из прошлых событий, когда пользователь оценивал какой-то фильм. Наконец, нам нужно что-то, что будет делать предсказания, что-то, что поможет нам решать нашу задачу с фильмами и пользователями. Это называется алгоритмом или моделью и обозначается a(x). Это, по сути, функция, которая переводит объекты в ответы, которая отображает пространство объектов в пространство ответов. a(x) принимает на вход, собственно, объект x. Кстати, слово «алгоритм» обозначает, что эта функция должна быть легко реализуема на компьютере, что ее должно быть легко использовать в системах машинного обучения. Простым примером алгоритмов являются линейные алгоритмы, о которых мы тоже говорили в прошлом курсе. Идея линейных алгоритмов очень простая: давайте возьмем все признаки и сложим их с некоторыми весами, и еще прибавим некоторую, некоторый константный коэффициент w0. Поскольку такая линейная комбинация признаков — это, по сути, любое вещественное число, а в нашей задаче ответов всего два, −1 и +1, понравился фильм или не понравился, то нужно взять знак от этой суммы, то есть для задачи классификации, для задачи определения понравится фильм или не понравился, алгоритм будет иметь вид знака от линейной комбинации всех признаков объекта. Давайте поймем, что не все алгоритмы одинаково подходят для решения нашей задачи. Например, рассмотрим константный алгоритм a(x) = 1. Алгоритм, который для всех пар «пользователь-фильм» говорит, что фильм этому пользователю понравится. Понятно, что это довольно бесполезный алгоритм, который вряд ли принесет пользу нашему сайту, поэтому нам нужно ввести некоторую характеристику полезности, характеристику качества алгоритма для данной конкретной задачи. Эта характеристика называется функционалом ошибки и обозначается как Q. Q принимает на вход алгоритм и выборку и возвращает некоторую характеристику того, насколько хорошо работает данный алгоритм на данной выборке. В нашем случае это может быть, например, доля неправильных ответов, то есть берем всю выборку x и смотрим, на какой доле пар «пользователь- фильм» наш алгоритм ошибся, выдал неправильное предсказание. Понятно, что чем меньше будет такая доля неверных ответов, тем лучше. Обратите внимание на еще один факт: функция Q называется функционалом ошибки, а не функцией. Функционал, потому что она принимает на вход другую функцию, алгоритм является функцией, как вы помните. Итак, задача обучения состоит в подборе такого алгоритма a, на котором достигается минимум функционала ошибки. Сразу возникает вопрос: а из какого множества нужно выбирать лучший алгоритм? Для этого вводится понятие семейства алгоритмов, которое обозначается буквой A красивое. По сути, это множество всех алгоритмов, среди которых мы будем искать лучший, тот, который лучше всего подходит для решения нашей задачи, которая составляет минимум к функционалу ошибки. Простейшим примером семейства алгоритмов являются решающие пни. Каждый решающий пень делает очень простую вещь: он берет некоторый один фиксированный признак xj-тое и сравнивает его значение на данном объекте с некоторым порогом t. Если значение признака меньше этого порога, то алгоритм возвращает ответ −1, говорит, что этому пользователю фильм не понравится. Если же значение j-того признака больше или равно порога t, то алгоритм дает ответ +1, говорит, что пользователю фильм понравится. Это очень простые алгоритмы, они могут проверять только очень простые факты вроде «Пользователь посмотреть больше трех комедий». Понятно, что здесь нужно проверять более сложные, парные взаимодействия, например, «Пользователь посмотрел больше трех комедий» и «Данный фильм является комедией». Но решающие пни на это не способны, для этого нужны более сложные семейства алгоритмов. Тем не менее, решающие пни пригодятся нам в этом курсе для составления сложных композиций алгоритмов. Обратите внимание на одно обозначение, которое используется на этом слайде. Это квадратные скобки, скобки Айверсона или нотация Айверсона. Внутри скобок Айверсона находится некое логическое выражение, например, «значение j-того признака меньше порога t». Если это выражение — верное, то значение скобок равно 1, если же значение неверное, то значение скобок равно 0. Итак, чтобы заниматься машинным обучением, нужно уметь отвечать на три вопроса: как измерять качество, какой функционал ошибки использовать в данной задаче; какое взять семейство алгоритмов, из чего выбирать оптимальный алгоритм для данной задачи; и, наконец, как этот выбор производить, как делать обучение алгоритма? При этом есть ряд других вопросов, которые не менее важны, но относятся скорее к анализу данных, а не к машинному обучению. Анализ данных — это более широкая область науки, которая включает в себя множество различных эвристик, очень полезных для этой работы. Например, как сформировать признаки, какие выбрать признаки, чтобы на них задача решалась лучше всего, или как готовить признаки, как их предобрабатывать, как они должны выглядеть, чтобы алгоритм хорошо обучался на них, или, например, какую выбрать метрику, чтобы алгоритм не только хорошо настраивался, но и приносил реальную экономическую пользу заказчику. В этом уроке мы поговорим о совсем базовых понятиях: о постановках задач машинного обучения и о том, какие признаки бывают машинного обучения. Это очень простые и базовые вещи, которые пока не имеют отношения к реальным задачам, но нам очень важно о них поговорить, чтобы использовать общую терминологию, говорить на одном языке, а уже в следующем уроке мы перейдем к реальным примерам и к реальным семействам алгоритмов, а именно к линейным.

В этом видео мы поговорим о том, какие бывают типы задач обучения на размеченных данных или обучения с учителем, и обсудим несколько их примеров. В прошлый раз мы обсуждали общую постановку задачи обучения с учителем. В ней есть обучающая выборка, то есть набор пар «объект и ответ» — объектов и ответов, которые нужно предсказывать для этих объектов. И нужно найти такой алгоритм из семейства алгоритмов A (красивое), на котором будет достигаться минимум функционала ошибки, то есть найти такой алгоритм, который будет лучше всего решать нашу задачу, лучше всего подходить к нашей обучающей выборке. В зависимости от того, какие именно ответы должны возвращать алгоритмы в этой задаче, зависит, с каким типом задачи мы имеем дело. Иными словами, тип задачи определяется пространством ответов, которое мы обозначали Y (красивое). Замечу, что бывают и другие задачи, не только обучения с учителем, но об этом в следующем видео. А первый пример, о котором мы поговорим, это задача бинарной классификации. В этих задачах пространство ответов состоит из всего двух элементов, их обычно обозначают как 0 и 1 или –1 или +1. Множества объектов, которые относятся... которые имеют один ответ, например ответ «–1», называются классом, и говорят, что нужно уметь относить объект к одному из двух классов или классифицировать эти объекты. Давайте рассмотрим простой пример. Если у нас каждый объект описывается всего двумя признаками, то есть выборка двумерная, то можно эту выборку нарисовать. По одной оси отложим значение первого признака, по другой — значение второго признака, и каждая точка в этих осях будет обозначать один объект обучающей выборки. По сути, задача классификации состоит в том, чтобы провести некоторую разделяющую кривую, которая будет отсекать один класс от другого, разделять синие и красные точки. Примеров задачи бинарной классификации очень много. Например, можно предсказывать, понравится ли пользователю фильм — то, о чем мы уже говорили. Или, например, вернет ли клиент кредит или не вернет — задача кредитного скоринга, очень популярная в банковской сфере. Или, например, нужно ли делать пациенту операцию, будет ли операция иметь долгосрочный положительный эффект. Или можно просто предсказывать, качественное ли вино, сделано ли оно по всем канонам или это дешевая подделка. Классов может быть не два, а больше. Задача, в которой конечное число классов, например K штук, называется многоклассовой классификацией. Визуально это означает следующее. Допустим, признаков все еще два, но при этом цветов точек (а цвет обозначает класс точки, класс объекта) будет больше. В этом случае надо провести не одну разделяющую кривую, а много. Для каждого класса будет своя кривая, которая отсекает этот класс от всех остальных. Понятно, что это уже более сложная задача. Какие есть примеры задач многоклассовой классификации? Например, можно пытаться понять, из какого сорта винограда сделано вино. Понятно, что сортов конечное количество, значит это многоклассовая классификация. Или, например, можно определять тематику научной статьи. Из какой области эта статья? Она про математику, про физику, про биологию или, может быть, про философию? Или, например, можно пытаться понять по фотографии, какой тип машины там присутствует: мотоцикл, легковая или грузовая машина? Это может понадобиться, чтобы автоматически определять, какую плату за проезд по платной дороге взять с автомобилиста по фотографии его машины возле КПП. Классов может быть не конечное число. Если классов бесконечное количество, например ответом может быть любое вещественное число, то мы имеем дело с задачей регрессии. Собственно, в задачах регрессии пространство ответов — это все вещественные числа. Давайте разберем простой пример. Нам нужно предсказать рост человека по его весу. В этом случае по оси x мы отложим вес человека в килограммах — признак, по оси y отложим ответ — рост человека в сантиметрах. Каждая точка будет соответствовать одной паре «объект–ответ». В нашем примере очень легко видеть, что зависимость почти линейная. Можно провести прямую, которая будет очень хорошо предсказывать рост человека по его весу. Есть и более сложные примеры задач регрессии. Например, предсказание температуры на завтрашний день. Понятно, что температура — это вещественное число. Или, например, предсказание прибыли магазина в следующем году, или определение возраста человека по его фотографии. Еще одним примером задачи обучения с учителем является задача ранжирования. Это довольно тяжелая задача, о которой мы не будем говорить в этом курсе, но знать о ней очень полезно. Это задача, с результатом решения которой вы сталкиваетесь каждый день, когда ищете что-то в поисковике, например в Яндексе. Ранжирование поисковой выдачи заключается в следующем. Пользователь вводит некоторый запрос. Например, ему хочется найти картинки с котятами. И у нас есть множество всех страниц в Интернете, которые нам известны. Это миллиарды или даже триллионы страниц. И нужно отсортировать все эти страницы по тому, насколько они подходят под запрос пользователя, насколько они отвечают на его вопрос. Понятно, что очень непросто отсортировать, отранжировать такое количество документов, но эта задача вполне решаемая. Итак, мы обсудили основные постановки задач обучения с учителем. Это бинарная многоклассовая классификация, это регрессия. Также мы немножко поговорили о ранжировании. А в следующем видео поговорим о задачах обучения без учителя.

В этом видео мы поговорим о том, какие бывают постановки задач в машинном обучении помимо обучения с учителем. И рассмотрим несколько примеров задач обучения без учителя. Итак. Обучением с учителем называются такие задачи, в которых у нас есть и объекты, и истинные ответы на них. И нужно по этим парам восстановить общую зависимость, построить алгоритм или модель, которые будут предсказывать ответы по объектам. Задача обучения без учителя — это такая задача, в которой есть только объекты, ответов нет, и при этом с этими объектами нужно что‐то сделать. Также есть и промежуточные постановки. Например, частичное обучение. В этом случае у нас есть объекты, но ответы известны лишь на части объектов. И нужно как‐то, имея эту информацию, тоже восстановить общую зависимость, построить модель. Или, например, активное обучение. Это задача, в которой есть объекты, но получать ответ для объекта, истинный ответ, очень дорого, очень тяжело. Поэтому алгоритм должен уметь определять, на каких объектах ему надо знать ответ, чтобы лучше всего обучиться, построить наилучшую модель. В этом видео мы обсудим 3 примера постановки задачи обучения без учителя, чтоб вы понимали важность этого класса задач. Первым примером будет задача кластеризации. В этом случае у нас есть некий набор объектов, и нужно сгруппировать их, найти группы похожих объектов. У этой задачи есть 2 проблемы. Проблема первая: мы даже зачастую не знаем количество этих групп, мы не знаем, сколько кластеров имеется в наших данных. А во‐вторых, мы не знаем правильных ответов, мы не знаем истинные кластеры, которые нужно выделять. Поэтому задача решается очень тяжело, здесь нельзя измерить точно качество решения. Кстати, вот этим она и отличается от задачи классификации. В классификации тоже нужно относить объект к одной из групп, но там есть примеры объектов этих групп. Поэтому задача классификации гораздо проще, в ней можно померить качество решения. Примеров задачи кластеризации очень много. Например, эта сегментация пользователей, например интернет‐магазина или мобильного оператора. Им зачастую интересно найти группы похожих пользователей, чтобы дальше, например, заниматься маркетингом для каждой группы в отдельности. Понять, что такого особенного в этой группе, что все пользователи в ней схожие, и ориентировать рекламу именно на этот сегмент, на эту группу. Или, например, можно искать группы похожих пользователей социальных сетей. Но при этом кластеризовать — группировать — можно не только людей. Например, можно кластеризовать гены, пытаясь найти такие группы генов, которые одновременно включаются или выключаются у разных людей в разных условиях. Второй пример задачи обучения без учителя — это задача визуализации. Здесь нам нужно нарисовать многомерную выборку — выборку, которая описывается большим числом признаков. То есть надо уметь многомерную точку отразить в двумерное пространство, то есть на плоскость, или в трёхмерное пространство, то есть в пространство. При этом отобразить нужно так, чтобы визуализация, изображение нашей выборки в двумерном или трёхмерном пространстве отражало структуру исходной многомерной выборки. Чтобы глядя на это изображение, можно было понять, как устроены эти данные. что с ними можно делать. Также обычно есть требование, чтобы эта визуализация была красивой, чтоб на неё было приятно смотреть. Классическим примером задачи визуализации является визуализация data set'а MNIST. Это data set, в котором были отсканированы рукописные начертания всех цифр — от 0 до 9. Понятно, что каждый скан, каждое изображение, характеризуется сотнями пикселей. Но при этом, если грамотно отразить эту многомерную выборку на плоскость, то цифры вполне будут группироваться. Например, цифра 0 будет отдельным облаком где‐то. Причём особенностью хорошей визуализации будет то, что даже начертания одной и той же цифры будут разделяться на разные группы в зависимости от того, как именно написана эта цифра, например с засечкой или без. Третий пример задачи обучения без учителя — это задача обнаружения аномалий, поиска аномалий. В ней требуется обнаруживать, определять, что данный объект не похож на все остальные, что он является аномальным. При этом при обучении у нас есть только примеры обычных, неаномальных объектов, а примеров аномальных либо нет вообще, либо настолько мало, что невозможно воспользоваться классическими методами обучения с учителем. При этом задача очень важная. Например, можно пытаться обнаружить что в самолёте есть поломка по показателям сотен датчиков, расположенных в нём. Такое обнаружение позволит избежать аварии, понятно, что это очень полезно. Или, например, если у нас есть интернет‐сайт, например интернет‐магазин или поисковый сайт, можно пытаться, опять же, по многим показателям понять, что произошла поломка, аномалия, что с сайтом нужно что‐то делать, нужно его срочно чинить. Или, например, если есть некоторая модель машинного обучения, которая делает прогнозы, скажем, понравится ли пользователю фильм или нет, можно пытаться следить за ней, понимать, хорошо ли он делает предсказания, или что‐то поломалось. Например, из‐за того, что распределение одного из признаков поменялось. Итак, мы обсудили 3 примера постановки задач обучения без учителя: кластеризацию, визуализацию и поиск аномалий. В этом курсе мы не будем о них говорить, им будет посвящен следующий курс — «Поиск структуры в данных», приходите. А в следующем видео мы поговорим о том, какие бывают признаки в задачах машинного обучения.

В этом видео мы поговорим о признаках машинного обучения. Существует несколько классов, несколько типов признаков, и у всех свои особенности. Все нужно по-разному готовить и по-разному учитывать в алгоритмах машинного обучения. В этом видео мы больше поговорим о терминологии, чтобы закрепить ее, а о самих особенностях работы с этими признаками будем говорить в следующих уроках. Также мы немного затронем вопросы, какие проблемы могут встретиться в тех или иных видах признаков. Итак, как вы уже знаете, признак — это некоторое число или другая понятная компьютеру сущность, которая как-то описывает объект в доступной форме. Множество значений j-го признака будем обозначать буквой Dj. И первый тип признаков, о которых мы поговорим, это бинарные признаки. Это самый простой тип признаков, которые принимают значение 0 или 1. Всего два значения. Например, в задаче кредитного скоринга мы можем смотреть, клиент получает зарплату выше, чем в среднем по городу, или нет? Если ответ на вопрос «да, его зарплата выше, чем средняя», то значение признака равно 1, если ответ «нет», то значение признака равно 0. У него два значения, он является бинарным. Или другой пример: если мы классифицируем изображение фруктов, пытаясь понять, какой именно фрукт там нарисован, то мы можем сделать признак, который отвечает на вопрос: фрукт зеленый или нет? 1 — если зеленый, 0 — если нет. Тоже бинарный признак. Чуть более сложный класс признаков — это вещественные. В этом случае множество значений — это все вещественные числа. Например, в задаче кредитного скоринга это может быть возраст клиента — понятно, что это вещественное число. Или в задаче оценивание стоимости квартиры можно рассматривать признак «площадь квартиры». Или же в задаче предсказания оттока клиентов мобильного оператора можно смотреть на признак «количество звонков в колл-центр за последний месяц». Следующий класс признаков — категориальные. В случае с категориальными признаками множество значений — это некоторое неупорядоченное множество. Это означает, что мы можем сравнивать элементы этого множества лишь на равенство, на совпадение, но при этом нельзя сравнивать их между собой на больше или меньше. Простой пример категориального признака — это цвет глаз человека. Понятно, что есть несколько вариантов цвета глаз, и их нельзя сравнивать. Нельзя сказать, что зеленый цвет больше или меньше, чем голубой. Разумеется, можно вдариться в подробности и, например, сравнивать цвета по длине волны, но не факт, что во всех задачах такое сравнение имеет смысл. Еще один пример категориального признака — это город, где родился клиент банка, который сейчас просит дать ему кредит. Или еще один пример — это образование. Понятно, что образование может пойти по нескольких веткам, например высшее образование и среднее профессиональное, и их тоже нельзя сравнивать между собой. При этом опять же в некоторых задачах можно ввести осмысленный порядок на этих значениях, но об этом чуть позже. Категориальные признаки очень трудны в обращении. До сих пор появляются способы учета этих признаков в тех или иных методах машинного обучения. Частным случаем категориальных признаков являются порядковые признаки. В этом случае множество значений признака — это некоторое множество, которое является упорядоченным. То есть можно сравнивать значения между собой, но нельзя измерять расстояние между ними. Этим порядковые признаки отличаются от вещественных. Пример порядкового признака — это роль в фильме. Актер может иметь роль первого плана, роль второго плана, роль в массовке, и эти виды ролей легко сравниваются между собой. Или, например, тип населенного пункта — это тоже порядковый признак. Есть вполне определенный порядок на всех типах населенных пунктов: деревня, город, областной центр, столица — что-то в этом духе. Как я уже говорил, на образовании можно ввести порядок в некоторых задачах. Например, банк в задаче кредитного скоринга может ввести порядок на типах образования в зависимости от того, клиенты с каким образованием лучше или хуже возвращают кредиты. И, например, может получиться, что два высших образования хуже, чем одно высшее образование. Наконец, последний тип признаков на сегодня — это множествозначные признаки. Множествозначный признак — это такой признак, значение которого на объекте — это подмножество некоторого множества. Например, можно рассматривать множество всех фильмов, которые когда-либо вышли (это, наверное, сотни тысяч фильмов), и значение признака для одного посетителя сайта — это множество фильмов, которые он посмотрел, это подмножество множества всех фильмов. Или, например, в задачах анализа текстов если мы рассматриваем текст, например, сообщения в Twitter, один объект — это некоторое сообщение, некоторый набор слов, который является подмножеством Большого словаря. Давайте теперь поговорим о двух проблемах, с которыми можно столкнуться при работе с признаками. Первая из них — это выброс. Выбросом называется такой объект, значение признака на котором отличается от значений признака на большинстве объектов. Например, на этом графике нарисованы распределения некоторого признака, и видно, что у большинства объектов значение этого признака концентрируется вокруг 5, но при этом на одном или двух объектах оно равно 15. Эти объекты — выбросы. Значения на них не вписываются в общее распределение. При этом если вы будете настраивать алгоритм машинного обучения на такой признак, у него, скорее всего, будут проблемы. Он будет пытаться хорошо работать и с распространенными значениями признака, и с выбросами. Но при этом поскольку выбросы, скорее всего, приходят из другого распределения, они описываются другими закономерностями, у алгоритма могут возникнуть большие проблемы при этом. Иногда выбросы лучше просто выкинуть. Дело может быть даже не в выбросах, а в том, как распределен признак. Например, в задаче кредитного скоринга можно посмотреть на признак «город, где родился клиент». При этом из каких-то городов у банка будет много клиентов, например из Москвы или Питера, а из каких-то небольших городов с населением в несколько десятков тысяч может быть мало клиентов — один или два. В этом случае статистики по этим городам будет слишком мало, чтобы накопить какие-то данные, чтобы делать выводы на основе того, что клиент пришел из этого города. С этим тоже могут быть проблемы, и надо как-то их решать. Мы будем говорить об этом, когда будем обсуждать работу с категориальными признаками. Если же признак вещественный, то проблема может быть в его распределении следующая: представьте, что мы смотрим на распределение стоимости книг в интернет-магазине, который торгует книгами. Оно будет выглядет примерно, как на этой гистограмме. У большинства книг цена будет не очень большая — несколько сотен рублей, и здесь почти все распределение концентрируется. Но при этом есть ряд книг, которые довольно дорогие — стоят тысячу или несколько десятков тысяч рублей. Они составляют «хвост» распределения, и он является довольно тяжелым. При работе с таким распределением, если алгоритм будет настраиваться на него, у него тоже могут возникнуть проблемы. Здесь нужно либо работать по отдельности с большинством книг, у которых цена вписывается в несколько сотен, и с дорогими книгами, или же как-то преобразовывать распределение этого признака, чтобы оно было более нормальным. Итак, мы обсудили основные типы признаков: это бинарные; вещественные; категориальные и порядковые; и множествозначные. Поговорили и о том, какие примеры этих признаков могут быть. А также обсудили две проблемы с признаками: они могут иметь выбросы, значение которых надо лучше выкинуть, а также могут быть проблемы в самом распределении признака, например слишком редкие значения или перекошенное распределение. На этом вводные лекции заканчиваются, и вам предстоит сделать задание по программированию, где вы посмотрите на реальные данные и заметите, какие могут быть проблемы в этих данных. А в следующем уроке мы уже начнем говорить о о реальных алгоритмах машинного обучения, а именно о линейных моделях.

1.1. Знакомство с машинным обучением
Приветствуем Вас на курсе «обучение на размеченных данных». Это второй курс специализации «Машинное
обучение и анализ данных», в котором начинается знакомство собственно с машинным обучением. Центральной темой этого курса является обучение с учителем. На самом деле эта тема была уже затронута в прошлом
курсе, когда речь шла про интерполяцию. Интерполяция — задача восстановления функции по нескольким
точкам, в которых известны ее значения.
Обучение с учителем — тоже восстановление общей закономерности по конечному числу примеров. Хотя
постановки задач похожи, у них есть много отличий в том, как они решаются и какие требования выдвигаются
к решению. Эти различия будут обсуждаться в данном курсе.
1.1.1. Пример: понравится ли фильм пользователю
Для начала будет рассмотрен не очень сложный пример, на котором можно понять, в чем заключается суть
обучения с учителем и машинного обучения. Пусть есть некоторый сайт, посвященный кино, на который
можно зайти, найти страницу нужного фильма, прочитать информацию про него: когда он снят, кто в нем
играет и какой бюджет у этого фильма, а также, возможно, купить его и посмотреть. Пусть есть некоторые
пользователи, которые находят страницу нужного фильма, читают и задаются вопросом «смотреть или нет?».
Необходимо понять, понравится ли пользователю фильм, если выдать ему рекомендацию о фильме. Есть
несколько подходов к решению:
• Подход первый, самый глупый — дать пользователю посмотреть этот фильм.
• Второй подход — дать случайный ответ и показать случайную рекомендацию. В обоих случаях пользователь может быть разочарован фильмом и он будет недоволен сайтом.
• Третий подход — пригласить психолога-киномана, чтобы разрешить ситуацию. Этот человек оценит
пользователя, оценит фильм и поймет, понравится ли этот фильм этому пользователю, сопоставив
информацию. Этот подход довольно сложный. Скорее всего таких специалистов не очень много, и будет
сложно отмасштабировать это решение на миллионы пользователей сайта. Но на самом деле это не
нужно.
Существует множество примеров — ситуаций, когда другие пользователи заходили на страницы фильмов,
принимали решение посмотреть фильм и далее ставили оценку, по которой можно понять, понравился им
фильм или нет. Задача машинного обучения состоит в восстановлении общей закономерности из информации
в этих примерах.
1.1.2. Основные обозначения
В рамках данного курса будут использоваться следующие обозначения: x — объект, X — пространство объектов, y = y(x) — ответ на объекте x, Y — пространство ответов.
Объектом называется то, для чего нужно сделать предсказание. В данном примере объектом является
пара (пользователь, фильм). Пространство объектов — это множество всех возможных объектов, для ко1
торых может потребоваться делать предсказание. В данном примере это множество всех возможных пар
(пользователь, фильм).
Ответом будет называться то, что нужно предсказать. В данном случае ответ — понравится пользователю фильм или нет. Пространство ответов, то есть множество всех возможных ответов, состоит из двух
возможных элементов: -1 (пользователю фильм не понравился) и +1 (понравился).
Признаковым описанием объекта называется совокупность всех признаков:
x = (x
1
, x2
, . . . , xd
).
Признак - это число, характеризующее объект. Признаковое описание является d-мерным вектором.
1.1.3. Выборка, алгоритм обучения
Центральным понятием машинного обучения является обучающая выборка X = (xi
, yi)
`
i=1. Это те самые примеры, на основе которых будет строиться общая закономерность. Отдельная задача — получение обучающей
выборки. В вышеупомянутом случае yi - это оценка фильма пользователем.
Предсказание будет делаться на основе некоторой модели (алгоритма) a(x), которая представляет из себя
функцию из пространства X в пространство Y. Эта функция должна быть легко реализуема на компьютере, чтобы ее можно было использовать в системах машинного обучения. Примером такой модели является
линейный алгоритм:
a(x) = sign(w0 + w1x
1 + . . . + wdx
d
).
Операция взятия знака sign берется ввиду того, что пространство Y состоит из двух элементов.
Не все алгоритмы подходят для решения задачи. Например константный алгоритм a(x) = 1 не подходит.
Это довольно бесполезный алгоритм, который вряд ли принесет пользу сайту.
Поэтому вводится некоторая характеристика качества работы алгоритма — функционал ошибки. Q(a, X)
— ошибка алгоритма a на выборке X. Например, функционал ошибки может быть долей неправильных
ответов. Следует особо отметить, что Q называется функционалом ошибки, а не функцией. Это связано с
тем, что первым его аргументом является функция.
Задача обучения состоит в подборе такого алгоритма a, для которого достигается минимум функционала
ошибки. Лучший в этом смысле алгоритм выбирается из некоторого семейства A алгоритмов.
1.1.4. Решающие пни
Простейшим примером семейства алгоритмов являются решающие пни:
A =
x
j < t
|∀j, t	
.
Здесь квадратные скобки соответствуют так называемой нотации Айверсона. Если логическое выражение
внутри этих скобок — истина, то значение скобок равно 1, в ином случае — нулю.
Алгоритм работает следующим образом. Если значение определенного признака x
j меньше некоторого
порогового значения t, то данный алгоритм возвращает ответ 0 (фильм не понравится), в ином случае — +1
(пользователю фильм понравится).
Решающие пни могут быть использованы для построения сложных композиций алгоритмов.
1.2. Обучение на размеченных данных
1.2.1. Постановка задачи
В этом разделе речь пойдет о том, какие бывают типы задач при обучении на размеченных данных, или
обучении с учителем. Общая постановка задачи обучения с учителем следующая. Для обучающей выборки X = (xi
, yi)
`
i=1 нужно найти такой алгоритм a ∈ A, на котором будет достигаться минимум функционала
ошибки:
Q(a, X) → min
a∈A
.
В зависимости от множества возможных ответов Y, задачи делятся на несколько типов.
2
1.2.2. Задача бинарной классификации
В задаче бинарной классификации пространство ответов состоит из двух ответов Y = {0, 1}. Множество
объектов, которые имеют один ответ, называется классом. Говорят, что нужно относить объекты к одному
из двух классов, другими словами, классифицировать эти объекты.
Рис. 1.1: Задача бинарной классификации
Примеры задач бинарной классификации:
• Понравится ли пользователю фильм?
• Вернет ли клиент кредит?
1.2.3. Задача многоклассовой классификации
Классов может быть больше, чем два. В таком случае имеет место задача многоклассовой классификации.
Рис. 1.2: Задача многоклассовой классификации
Примеры задач многоклассовой классификации:
• Из какого сорта винограда сделано вино?
• Какая тема статьи?
• Машина какого типа изображена на фотографии: мотоцикл, легковая или грузовая машина?
3
1.2.4. Задача регрессии
Когда y является вещественной переменной, говорят о задаче регрессии.
Рис. 1.3: Задача регрессии
Примеры задач регрессии:
• Предсказание температуры на завтра.
• Прогнозирование выручки магазина за год.
• Оценка возраста человека по его фото.
1.2.5. Задача ранжирования
Еще одним примером задачи обучения с учителем является задача ранжирования. Эта задача довольно
тяжелая, и речь о ней в данном курсе не пойдет, но знать о ней полезно. Мы сталкиваемся с ней каждый
день, когда ищем что-либо в интернете. После того, как мы ввели запрос, происходит ранжирование страниц
по релевантности их запросу, то есть для каждой страницы оценивается ее релевантность в виде числа, а
затем страницы сортируются по убыванию релевантности. Задача состоит в предсказании релевантности для
пары (запрос, страница).
1.3. Обучение без учителя
В этом разделе мы обсудим, какие бывают постановки задач машинного обучения, кроме обучения с учителем.
Обучением с учителем называются такие задачи, в которых есть и объекты, и истинные ответы на них.
И нужно по этим парам восстановить общую зависимость. Задача обучения без учителя — это такая задача,
в которой есть только объекты, а ответов нет. Также бывают «промежуточные» постановки. В случае частичного обучения есть объекты, некоторые из которых с ответами. В случае активного обучения получение
ответа обычно очень дорого, поэтому алгоритм должен сначала решить, для каких объектов нужно узнать
ответ, чтобы лучше всего обучиться.
Рассмотрим несколько примеров постановки задач без учителя.
1.3.1. Задача кластеризации
Первый пример — задача кластеризации. Дано множество объектов. Необходимо найти группы похожих
объектов. Есть две основные проблемы: не известно количество кластеров и не известны истинные кластеры,
которые нужно выделять. Поэтому задача решается очень тяжело — здесь невозможно оценить качество
решения. Этим и отличается задача классификации — там тоже нужно делить объекты на группы, но в
классификации группы, а точнее классы, фиксированы, и известны примеры объектов из разных групп.
4
Рис. 1.4: Задача кластеризации
Примеры задач кластеризации:
• Сегментация пользователей (интернет-магазина или оператора связи)
• Поиск схожих пользователей в социальных сетях
• Поиск генов с похожими профилями экспрессии
1.3.2. Задача визуализации
Второй пример — задача визуализации: необходимо нарисовать многомерную (а конкретно, d-мерную) выборку так, чтобы изображение наглядно показывало структуру объектов.
Рис. 1.5: Задача визуализации
Примером задачи визуализации является задача визуализации набора данных MNIST. Этот набор данных
был получен в результате оцифровки рукописных начертаний цифр. Каждый скан цифры характеризуется
5
вектором признаков - яркостей отдельных пикселей. Необходимо таким образом отобразить этот набор данных
на плоскость, чтобы разные цифры оказались в разных ее областях.
1.3.3. Поиск аномалий
Третий пример задачи обучения без учителя — поиск аномалий. Необходимо обнаружить, что данный объект
не похож на все остальные, то есть является аномальным.
При обучении есть примеры только обычных, не аномальных, объектов. А примеров аномальных объектов
либо нет вообще, либо настолько мало, что невозможно воспользоваться классическими методами обучения
с учителем (методами бинарной классификации).
При этом задача очень важная. Например, к такому типу задач относится:
• Определение поломки в системах самолета (по показателям сотен датчиков)
• Определение поломки интернет—сайта
• Выявление проблем в модели машинного обучения.
Все упомянутые задачи не будут обсуждаться в рамках данного курса. Им будет посвящен следующий
курс — «Поиск структуры в данных».
1.4. Признаки в машинном обучении
В этом разделе речь пойдет о признаках в машинном обучении. Существует несколько классов, или типов
признаков. И у всех свои особенности — их нужно по-разному обрабатывать и по-разному учитывать в алгоритмах машинного обучения. В данном разделе будет обсуждаться используемая терминология, о самих же
особенностях речь пойдет в следующих уроках.
Признаки описывают объект в доступной и понятной для компьютера форме. Множество значений j-го
признака будет обозначаться Dj .
1.4.1. Бинарные признаки
Первый тип признаков — бинарные признаки. Они принимают два значения: Dj = {0, 1}. К таковым относятся:
• Выше ли доход клиента среднего дохода по городу?
• Цвет фрукта — зеленый?
Если ответ на вопрос да — признак полагается равным 1, если ответ на вопрос нет — то равным 0.
1.4.2. Вещественные признаки
Более сложный класс признаков — вещественные признаки. В этом случае Dj = R. Примерами таких признаков являются:
• Возраст
• Площадь квартиры
• Количество звонков в call-центр
Множество значений последнего указанного признака, строго говоря, является множеством натуральных
чисел N, а не R, но такие признаки тоже считают вещественными.
1.4.3. Категориальные признаки
Следующий класс признаков — категориальные признаки. В этом случае Dj — неупорядоченное множество.
Отличительная особенность категориальных признаков — невозможность сравнения «больше-меньше» значений признака. К таковым признакам относятся:
• Цвет глаз
• Город
• Образование (В некоторых задачах может быть введен осмысленный порядок)
Категориальные признаки очень трудны в обращении — до сих пор появляются способы учета этих признаков
в тех или иных методах машинного обучения.
6
1.4.4. Порядковые признаки
Частным случаем категориальных признаков являются порядковые признаки. В этом случае Dj — упорядоченное множество. Примеры:
• Роль в фильме (Первый план, второй план, массовка)
• Тип населенного пункта (упорядочены по населенности)
• Образование
Хотя и порядковые, и вещественные признаки упорядочены, они отличаются тем, что в случае порядковых
признаков «расстояние» между двумя значениями признака не имеет смысла. Например, отличие значения
3 от значения 2 может быть не таким существенным, как отличие 1 от 0.
1.4.5. Множествозначные признаки
Множествозначный признак — это такой признак, значением которого на объекте является подмножество
некоторого множества. Пример:
• Какие фильмы посмотрел пользователь
• Какие слова входят в текст
1.4.6. Распределение признака
Далее речь пойдет о проблемах, с которыми можно столкнуться при работе с признаками. Первая из них —
существование выбросов. Выбросом называется такой объект, значение признака на котором отличается от
значения признака на большинстве объектов.
Рис. 1.6: Пример выброса
Наличие выбросов представляет сложность для алгоритмов машинного обучения, которые будут пытаться
учесть и их тоже. Поскольку выбросы описываются совершенно другим законом, чем основное множество
объектов, выбросы обычно исключают из данных, чтобы не мешать алгоритму машинного обучения искать
закономерности в данных.
Проблема может быть и в том, как распределен признак. Не всегда признак имеет такое распределение,
которое позволяет ответить на требуемый вопрос. Например, может быть слишком мало данных о клиентах
из небольшого города, так как собрать достаточную статистику не представлялось возможным.
Линейные модели

Мы начинаем урок, посвященный линейным моделям. В нем мы поговорим о том, как они устроены в задачах классификации и регрессии, как их обучать и с какими проблемами можно столкнуться при использовании этих моделей. А начнем мы этот урок с видео, в котором обсудим, как выглядят линейные модели в задачах регрессии. Давайте сначала вспомним некоторые обозначения, которые мы ввели в прошлом уроке. Буквой X красивая мы обозначаем пространство всех объектов, то есть все возможные объекты, для которых может понадобиться делать прогнозы. А буквой Y красивая обозначаем пространство ответов, то есть все возможные ответы, которые могут иметь наши объекты. Маленькой буквой x обозначаем сам объект, то есть то, для чего нужно делать предсказания. Объект описывается признаками, всего их d штук, и они как-то характеризуют этот объект с помощью чисел или чего-то другого, понятного компьютеру. Большой буквой X обозначается обучающая выборка, то есть наборы из l пар, объект xi-тая и ответ yi-тая на этом объекте. а(x) — это алгоритм или модель, то есть то, что делает предсказание, что предсказывает ответ y по объекту, по его признаковому описанию. Качество алгоритма a измеряется с помощью функционала ошибки Q, которая принимает на вход алгоритм и выборку, на которой измеряется качество этого алгоритма. Процесс обучения заключается в поиске такого алгоритма из семейства алгоритмов A красивое, который минимизирует функционал ошибки. Как я обещал, в этом видео мы обсуждаем задачу регрессии, то есть пространство ответов Y совпадает с множеством вещественных чисел. Ответом может быть любое вещественное число. Чтобы научиться решать задачу регрессии, нужно уметь отвечать на 3 вопроса: во-первых, как выглядит функционал ошибки, то есть как мы измеряем, насколько хорошо или плохо отрабатывает алгоритм на конкретной выборке; второе — это семейство алгоритмов, как оно устроено, как выглядит множество тех алгоритмов, из которых мы выбираем лучшие; и третье — это метод обучения, то есть как именно мы выбираем лучшие с точки зрения функционала ошибки алгоритм из семейства алгоритмов, из этого множества. В этом видео мы ответим на первые 2 вопроса, а о третьем будем мы говорить в следующих видео этого урока. Давайте для начала рассмотрим простой пример с предсказанием прибыли магазина. Пусть в этой задаче есть всего один признак — прибыль магазина в прошлом месяце, а предсказать нужно прибыль магазина в следующем месяце. Понятно, что прибыль — это вещественная переменная, то есть это задача регрессии. Если мы разместим точки обучающей выборки на таком графике, где по оси x находится признак, то есть прибыль в прошлом месяце, а по оси y находится целевая переменная или ответ, то есть прибыль в следующем месяце, то точки расположатся как-то так. Видно, что есть некоторая зависимость, чем больше была прибыль в прошлом месяце, тем больше будет прибыль и в следующем месяце. Можно провести прямую, то есть сказать, что зависимость более-менее линейная, и с помощью этой прямой пытаться предсказывать прибыль в следующем месяце по прибыли в предыдущем месяце. Видно, что в целом прямая угадывает тенденцию, она более-менее описывает зависимость между ответом и признаком. При этом, разумеется, она делает это неидеально, то есть в каждой точке есть некоторая ошибка — истинный ответ на каждом объекте несколько отклоняется от прогноза, но в среднем это ошибка не такая большая, возможно, она нас устроит. На самом деле понятно, что один признак — это не очень серьезно. Если признак всего один, мы можем, как это было сейчас в примере, просто нарисовать нашу выборку, зависимость ответа от признака, и пробовать руками восстановить зависимость. Гораздо сложнее и интереснее работать с многомерными выборками, которые описываются большим количеством признаков. В этом случае нарисовать выборку и понять, подходит ли там линейная модель или нет, нельзя. Можно лишь найти ее и посчитать ее качество и по нему как-то понять — хорошее оно получилось или нет, можно использовать здесь линейную модель или нельзя. Отмечу, что вообще нельзя придумать модель, которая идеально описывает ваши данные, идеально описывает то, как порождается ответ по признакам. Но при этом модели все равно бывают полезными, из них можно извлекать какую-то пользу, если ошибка, которую они допускают, не очень большая. Итак, мы подошли к тому, чтобы обсудить, как именно выглядит семейство алгоритмов в случае с линейными моделями. Линейная модель, линейный алгоритм для задачи регрессии выглядит вот так. Из чего он состоит? Мы берем все признаки объекта, здесь они обозначаются как xj-тая. xj-тая — это j-тый признак объекта, и складываем их с некоторыми весами в wj-тое, при j-том признаке стоит j-тый вес. Также мы прибавляем к этой сумме вес w0. Это свободный коэффициент, или еще его иногда называют сдвигом. Давайте обратим внимание, что сдвиг немножко портит вид модели, он делает его неоднородным. Чтобы устраниться, давайте добавим к данным еще один признак, константный, который на каждом объекте принимает значение 1. В этом случае вес при нем по смыслу будет совпадать со свободным коэффициентом или со сдвигом, и сам w0 будет больше не нужен, его роль будет играть вес при этом признаке. В этом случае признаков будет d + 1, и линейная модель будет выглядеть просто как сумма всех признаков с некоторыми весами. Обратите внимание, что по сути это скалярное произведение вектора весов на вектор признаков. Мы будем часто пользоваться этим обозначением в наших лекциях. Далее давайте обсудим, как измерять ошибку линейного алгоритма на обучающей выборке или на какой-то другой выборке. Давайте рассмотрим пример. Пусть у нас есть объект, (III) на котором равен 10. И посмотрим разные варианты того, что может предсказать наш алгоритм. Предположим, алгоритм от x выдает ответ: 11, этот ответ не совпадает с истинным ответом: 10 и отклоняется на 1. Наверное, это не очень сильное отклонение. Или, например, если ответ нашего алгоритма: 9. Его отклонение будет: −1, поскольку алгоритм ошибается в другую сторону, возможно, это тоже не очень плохо. А что, если алгоритм возвращает число 20? В этом случае отклонение от истины гораздо больше. Разница равна 10. Если же алгоритм возвращает 1, отклонение тоже большое, но в другую сторону. Оно равно −9. В общем-то здесь, понятно, проблема, по которой нельзя использовать отклонение, то есть а(x) − y, как некую меру ошибки. Меру ошибки, или функционал ошибки, мы хотим минимизировать. При этом минимизация отклонения приведет к тому, что алгоритм будет оптимально выдавать минус бесконечность на всех объектах, если мы захотим, чтобы отклонение было как можно меньше. Чтобы устранить проблему, первое, что приходит в голову — это взять модуль от этой разности, минимум модуля — это 0, и достигается он в том случае, если ответ алгоритма и истинный ответ совпадают. Это уже гораздо больше подходит нам, мы можем минимизировать модули отклонения ответов алгоритма от истинных ответов на всех объектах и тем самым настраивать наш алгоритм. Но у модуля есть большая проблема. Эта функция негладкая. У модуля нет производной в нуле, и из-за этого использование градиентных методов оптимизации может быть затруднительно. Чтобы решить и эту проблему давайте просто возведем в квадрат модуль. Квадрат разности — это все еще хорошая функция. Ее минимум равен 0 и достигается, если прогноз алгоритма и истинный ответ совпадают. И при этом квадрат является гладкой функцией, у него есть производная в каждой точке, поэтому его можно минимизировать теми методами градиентными, которые мы будем обсуждать далее. Мы приходим к функционалу ошибки, который называется среднеквадратичной ошибкой. В нем мы вычисляем квадрат отклонения ответа алгоритма от истинного ответа, а(xi-того) и от y-i-того. И суммируем, точнее усредняем, эти квадраты отклонений по всей обучающей выборке. Это и называется среднеквадратичной ошибкой. Обратите внимание, что подставляя сюда линейную модель, то есть вместо a(x) подставляя скалярное произведение w на xi-тое, мы получаем уже не функционал, а функцию, поскольку теперь наша ошибка зависит не от некой функции a(x), а от вектора весов w. И оптимизировать нужно именно по этому вектору весов, что уже гораздо проще. Итак, мы с вами обсудили, как выглядят линейные алгоритмы, или линейные модели, для задачи регрессии и договорились, что будем измерять их качества с помощью среднеквадратичного отклонения, среднеквадратичной ошибки. В следующем видео поговорим о том, как оптимизировать эту ошибку, как настраивать алгоритмы под этот функционал ошибки.

В этом видео мы поговорим о том, как обучать линейную регрессию, как настраивать ее параметры. В прошлый раз мы договорились, что измерять качество линейной модели мы будем с помощью среднеквадратичного функционала ошибки, который считает квадрат отклонения прогноза линейной модели от истинного ответа и усредняет эти квадраты отклонений по всем объектам обучающей выборки. Здесь параметрами являются веса при признаках. Всего у нас d признаков, весов, значит, тоже d, а значит у нас d неизвестных, d чисел, которые нам нужно настроить. При этом мы считаем, что среди признаков есть константный признак, значения которого на всех объектах равны 1, благодаря этому нам не нужно включать константные члены в нашу формулу. Но прежде чем мы перейдем к оптимизации этого функционала, давайте обсудим, как записать в матричном виде среднеквадратичную ошибку. Начнем мы с матрицы «объекты–признаки». Это матрица, в которой l строк, то есть столько, сколько объектов, и d столбцов, то есть столько, сколько признаков. В i-том j-том элементе этой матрицы записаны значения j-того признака на i-том объекте. Таким образом, мы получаем что в i-той строке этой матрицы записаны все признаки i-того объекта, а в j-том столбце этой матрицы записаны значения j-того признака на всех объектах. Также нам понадобится вектор ответов — это вектор y, i-тый элемент которого равен yi-тому, то есть истинному ответу на i-том объекте обучающей выборки. В этом случае мы можем записать в матричном виде среднеквадратичную ошибку, она будет выглядеть вот так. Обратите внимание, когда мы умножаем матрицу «объекты–признаки» X на вектор весов w, мы получаем вектор размера l, то есть такого размера, сколько у нас всего объектов, и i-тый элемент этого вектора — это и есть прогноз нашей модели, скалярное произведение вектора весов на значение признаков на i-том объекте. Вычитаем из этого вектора вектор y, получаем отклонение прогнозов алгоритма от истинных ответов, и, вычисляя евклидову норму, возводя ее в квадрат и после этого поделив на число объектов, получаем среднеквадратичную ошибку. Это то, что нам нужно минимизировать. Нам эта формула пригодится, например, для реализации на компьютере. Так очень удобно вычислять значение среднеквадратичной ошибки на всей выборке. Можно показать, что если взять градиент от этой функции, приравнять его к нулю, выразить вектор весов через все остальное, то можно получить аналитическое решение задачи минимизации среднеквадратичной ошибки. Оно будет выглядеть вот так. Чтобы найти оптимальный вектор весов, нужно умножить матрицу X транспонированное на X, обратить это произведение, умножить на матрицу X транспонированное и умножить на вектор ответов y. Конечно, очень хорошо, что решение записывается аналитически. В этом случае можно не заниматься оптимизацией, но у аналитического решения есть ряд очень серьезных проблем. Самая главная проблема состоит в том, что вам нужно обращать матрицу X транспонированное на X. Обращение это очень тяжелая операция. Матрица X транспонированное на X имеет размеры d на d, то есть число признаков на число признаков. Обращение такой матрицы требует порядка d в кубе операций, Если у вас тысячи или десятки тысяч признаков, обращение будет занимать очень много времени. Также при этом обращении могут возникнуть численные проблемы, если матрица X транспонированное на X устроена не очень хорошо. Поэтому гораздо более простым и удобным подходом является оптимизационный. Несмотря на то что решение можно записать аналитически, давайте все равно с помощью метода оптимизации искать его, а именно с помощью градиентного спуска. Можно показать, что среднеквадратичная ошибка — это выпуклая и гладкая функция. Из выпуклости следует, что у нее всего 1 минимум, а из гладкости следует, что в каждой ее точке можно посчитать градиент, и поэтому можно использовать градиентный спуск для оптимизации. Давайте подробно обсудим алгоритм градиентного спуска. Начинается он с того, что мы каким-то образом находим начальное приближение для вектора весов w с верхним индексом 0. Его можно искать самыми разными способами. Один из самых простых — это инициализировать все элементы вектора весов нулями. То есть w0... каждая компонента w0 — это ноль. Есть и другие подходы. Например, можно инициализировать случайными и не очень большими числами. Далее в цикле мы повторяем следующие операции. На t-той итерации цикла мы берем приближение с предыдущей итерации, то есть wt − 1, и вычитаем из него вектор градиента в этой точке, умноженный на некоторый коэффициент ηt, который называет шагом. Почему мы именно так изменяем вектор весов? Мы обсуждали в прошлом курсе, что градиент показывает в сторону наискорейшего возрастания функции, а антиградиент, то есть вектор градиента с минусом, показывает в сторону наискорейшего убывания. Таким образом, если мы хотим как можно сильнее уменьшить функционал ошибки Q, нам нужно изменять вектор весов именно в сторону антиградиента, что здесь и происходит. Коэффициент ηt (или шаг) нужен для того, чтобы регулировать, насколько далеко мы шагаем в сторону антиградиента. Дело в том, что оказывается оптимальным шагать не очень сильно, мы увидим с вами это чуть дальше. Эти градиентные шаги повторяются до тех пор, пока не наступит сходимость. Сходимость можно определять по-разному. В нашем случае мы ее определяем как ситуацию, в которой векторы весов от шага к шагу начали меняться не слишком сильно. То есть норма отклонения вектора весов на текущем шаге от вектора весов на предыдущем шаге, должна отличаться не более, чем на ε. В этом случае мы завершаем градиентный спуск. Если же изменение довольно большое, мы продолжаем его. Есть и другие подходы к определению сходимости. Например, можно сравнивать значение функционала ошибки между текущей итерацией и предыдущей, или использовать еще какие-то способы. Итак, мы с вами обсудили, как в матричном виде записать среднеквадратичный функционал ошибки для линейной регрессии, и выяснили, что у него есть аналитическое решение, которое тем не менее обладает рядом проблем, его довольно тяжело вычислить. Поэтому гораздо проще использовать градиентный спуск. Мы с вами обсудили, как он устроен и почему в нем шаг делается именно в сторону антиградиента. В следующем видео мы посмотрим, как выглядит применение градиентного спуска конкретно для задачи линейной регрессии.

В этом видео мы поговорим о том, как применять градиентный спуск для обучения линейной регрессии. И давайте начнем с простого примера, со случая, когда признак всего один. Эта ситуация называется парной регрессией. В этом случае линейная модель выглядит как a от х равняется w 1 умножить на x плюс w 0. То есть мы берем значение нашего единственного признака x, умножаем на некоторый вес, некоторый коэффициент w 1, и прибавляем свободный коэффициент w 0, который также называется сдвигом. Получается, что у нашей модели есть два параметра: w 1 и w 0. Их нужно настраивать. Функционал ошибки возьмем среднеквадратичный, то есть посчитаем квадраты отклонения прогноза модели от истинного ответа и усредним по всем объектам. Давайте рассмотрим, как будет работать в случае с парной регрессией градиентный спуск на примере конкретной выборки. Например, это может быть задача предсказания прибыли магазина в следующем месяце на основе его прибыли в предыдущем месяце. Выборка выглядит вот так. По оси x отложено значение единственного признака, по оси y отложено значение ответа. Если нарисовать функционал качества в осях w 0 и w 1, он будет выглядеть как-то так. То есть это некоторая функция параболического вида, у нее где-то есть минимум. Напомню, градиентный спуск заключается в том, что мы как-то инициализируем вектор весов и дальше до сходимости повторяем градиентный шаг. То есть вычитаем из текущего приближения вектора весов градиент функционала ошибки в этой точке с некоторым коэффициентом в этой точке [INAUDIBLE]. Сходимость наступает, когда вектор весов перестает меняться слишком сильно от одной итерации к другой. Чтобы запустить градиентный спуск, нам нужно вычислить градиент, то есть вектор частных производных функционала ошибки по всем его параметрам. У нас параметра два, w 1 и w 0. Мы не будем вдаваться в математические выкладки, можно показать, что частные производные записываются вот так. Можете проверить дома, что это действительно правда. Итак, чтобы посмотреть, как работает градиентный спуск на нашей выборке, будем рисовать две картинки. На левой картинке мы изображаем пространство параметров. По оси x отложен параметр w 0, по оси y параметр — w 1. Точка в этом пространстве обозначает конкретную модель. Выбирая конкретные места, мы получаем конкретную линейную регрессию. На правом графике мы изображаем нашу выборку в осях «признак — ответ» и алгоритм, который настроен, который соответствует точке на левом графике. Итак, если мы возьмем начальное приближение случайно, возьмем в его качестве некоторую точку в окрестности нуля, то получим некоторый не очень хороший алгоритм. Он совершенно не соответствует тому, какая зависимость есть в нашей выборке. Сделаем первый градиентный шаг. Он сдвинется вверх и немножко вправо, и мы видим, что после даже первого градиентного шага алгоритм гораздо больше соответствует истинной зависимости. Направление нашей прямой уже более или менее угадывает общую тенденцию в данных. Сделаем еще несколько градиентных шагов. Наша точка в пространстве параметра будет двигаться в том же направлении, а наша прямая, наш алгоритм, будет все ближе и ближе к нашему облаку точек, к нашему облаку объектов. После того, как мы сделаем 100 итераций, наша точка в пространстве параметров немножко завернет, а сам алгоритм будет уже очень неплохо апроксимировать, неплохо приближать данные. Видно, что модель после сотой итерации уже довольно неплохая. После того, как мы сделаем тысячу итераций, точка в пространстве параметров, то есть набор параметров, сдвинется еще сильнее в том же направлении и алгоритм станет еще лучше описывать данные. После двух тысяч итераций мало что изменится. Видно, что уже наступила сходимость, и мы получили довольно неплохой алгоритм, который соответствует зависимости между признаком и ответом. При этом, если посмотреть на график того, как менялось значение функционала ошибки по мере итерации, мы увидим, что это изменение было монотонным, начиналось оно в довольно высокой точки, затем уменьшалось, и в какой-то момент вышло на асимптоту. Очень важно в градиентном спуске понимать, как выбрать размер шага [INAUDIBLE]. Давайте немножко поговорим об этом. Вообще, нет никаких конкретных правил, конкретных рекомендаций, каким именно выбрать шаг для данной задачи. Выбор шага это искусство, но при этом есть некоторые соображения, которые могут помочь. Если взять длину шага слишком маленькой, то градиентный спуск будет очень не спеша, но верно шагать в сторону минимума, как на этой картинке. Видно, что шаги по мере приближения к минимуму становятся все более и более маленькими, нужно довольно много итераций, чтобы градиентный спуск сошелся с таким размером шага. Если же взять размер шага очень большим, то, конечно, градиент будет показывать в сторону минимума, но поскольку мы шагаем по нему слишком далеко, есть риск, что мы будем перепрыгивать точку минимума, и, более того, есть риск расхождения, то есть градиентный спуск будет уходить все дальше и дальше от точки минимума, что и происходит на этой картинке. Можно заметить, что если мы еще находимся очень далеко от точки минимума, то нет ничего плохого в том, чтобы делать длинные шаги, чтобы далеко шагать в сторону антиградиента. Если же мы уже сделали много итераций градиентного спуска и есть подозрения, что находимся близко к точке минимума, то шаги должны быть аккуратными, чтобы мы не перескочили минимум, чтобы мы не начали шагать не в ту сторону. Таким образом, возникает идея делать шаг переменным. Чем больше итераций мы сделали, тем меньше должен быть размер шага. Например, можно в этом случае для размера шага [INAUDIBLE] взять формулу k поделить на t, где t это номер текущей итерации, а k — некоторая константа. видно, что чем больше число итераций, тем меньше будет шаг, а константу k нужно как-то подбирать в зависимости от задачи, например, пробовать разные значения и посмотреть, когда сходимость есть, а когда нет. В случае с многомерной линейной регрессией подход будет тот же самый, нужно только по-другому расчитать градиент. Функционал в случае с многомерной линейной регрессией, как мы уже выяснили, записывается в матричном виде. Это будет норма, квадрат нормы отклонения вектора X w, то есть вектора прогнозов, от вектора y, то есть вектора истинных ответов. И потом еще это делится на l, на размер выборки. Нужно минимизировать этот функционал ошибки. Можно показать, что градиент этого функционала в точке w вычисляется по вот такой формуле. Нужно взять матрицу X, то есть матрицу «объекты — признаки», транспонировать ее, умножить на вектор отклонений X w — y, то есть на вектор ошибок алгоритма на каждом объекте обучения, и потом умножить все это на скаляр 2 поделить на l. Именно вдоль этого вектора нужно шагать на каждом шаге градиентного спуска. Итак, мы с вами обсудили, как будет выглядеть градиентный спуск для парной, то есть одномерной, и многомерной линейной регрессии, обсудили важность выбора шага. А в следующем видео мы поговорим о модификации градиентного спуска, стохастическом градиентном спуске, который хорошо подходит для настройки линейной регрессии.

В этом видео мы поговорим о стохастическом градиентном спуске, который особенно хорошо подходит для обучения линейных моделей. Итак, мы уже знаем, как работает обычный градиентный спуск. Мы начинаем с некоторой инициализации вектора весов, например, нулями или другими значениями, и дальше повторяем в цикле градиентные шаги. Градиентный шаг состоит в том, что мы вычитаем из текущего приближения вектора весов w (t − 1) вектор градиента, с некоторым коэффициентом ηt. Повторяя эти шаги до тех пор, пока не наступит сходимость, то есть пока вектор весов не начнет меняться слишком слабо. Давайте внимательнее посмотрим на то, как устроен градиентный шаг. Вектор градиента в векторной форме выглядит вот так. Если расписать j-ю компоненту этого вектора, то получим следующую формулу. В ней стоит суммирование по всем объектам обучающей выборки, по i от 1 до l, где мы суммируем следующие слагаемые, которые, по сути, показывают, как надо изменить j-й вес, чтобы как можно сильнее улучшить качество на объекте xi. А вся сумма показывает, как нужно изменить j-й вес, чтобы улучшить качество на всей обучающей выборке. Собственно, в этой формуле и состоит один из главных недостатков градиентного спуска. Здесь стоит суммирование по всей обучающей выборке. Если выборка большая, то один градиентный шаг будет занимать слишком много времени. Так мы приходим к модификации градиентного спуска, который называется стохастическим градиентным спуском. Его главная особенность в том, что на одной итерации мы вычитаем не вектор градиента, вычисленный по всей выборке, а делаем следующее. Мы случайно выбираем один объект из обучающей выборки, например, xi, и дальше вычисляем градиент функционала только на этом объекте, то есть градиент только одного слагаемого в функционале ошибки, и вычитаем именно этот градиент из текущего приближения вектора весов. Очень показательно посмотреть на график сходимости для градиентного спуска и стохастического градиентного спуска. В градиентном спуске мы стараемся на каждую итерацию уменьшить ошибку на всей выборке, и поэтому график получается гладким. По мере увеличения числа итераций ошибка уменьшается монотонно, поскольку мы уменьшаем ее на всей выборке. В случае же со стохастическим градиентным спуском, мы уменьшаем на каждую итерацию ошибку только на одном объекте, но при этом мы можем увеличить ее на другом объекте, поэтому график получается пилообразный. Мы на какой-то итерации можем увеличивать ошибку, но при этом в целом он уменьшается. И рано или поздно мы выходим на довольно неплохое качество, на довольно низкую ошибку. Итак, у стохастического градиентного спуска есть много преимуществ. Во-первых, в нем гораздо быстрее вычисляется один шаг, один градиентный шаг. Так же ему не требуется хранение всей обучающей выборки в памяти. Мы можем считывать по одному объекту из выборки и для каждого следующего объекта делать градиентный шаг. За счет этого стохастический градиентный спуск позволяет обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. Так же он подходит для онлайн обучения, ситуации, в которой мы получаем за каждый шаг только один объект, и должны как-то изменить модель, чтобы учесть этот объект. Итак, мы обсудили, что градиентный спуск требует суммирование по всем объектам обучающей выборки на каждой итерации, что может быть проблемой, если выборка большая. Стохастический градиентный спуск решает эту проблему, используя лишь один объект обучающей выборки на каждой своей итерации. При этом он имеет много преимуществ и позволяет, например, обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. В следующем видео мы поговорим о том, как применять линейные модели в задачах классификации.

В этом видео мы поговорим про линейную классификацию: то есть как применять линейные модели к задачам классификации. И будем говорить о самом простом виде классификации — бинарной классификации, где ответы принимают значения из множества −1 и +1, то есть всего 2 возможных значения. Как вы помните, чтобы работать с той или иной моделью, нужно уметь отвечать на 3 вопроса: первый — это как мы измеряем качество, как устроен функционал ошибки; второй — как устроено семейство алгоритмов, то есть то множество алгоритмов, из которого мы выбираем наилучший с точки зрения функционала; и третий — это как мы обучаем алгоритм, то есть выбираем лучший из семейства с точки зрения функционала ошибки. В этом видео мы поговорим о семействе алгоритмов, а в следующем — о том, как измерять их ошибки и как обучать эти алгоритмы. Мы уже говорили про линейную регрессию. Линейные классификаторы устроены очень похоже. В линейной регрессии мы складывали все признаки с весами, при этом вес при j-том признаке обозначали как wj-тое, и после этого суммирования проявляли еще свободный коэффициент w0, который также называется сдвигом. В случае с регрессией нас эта формула полностью устраивала, поскольку она принимала вещественные значения, теперь же алгоритм должен возвращать бинарные значения: −1 или +1. Чтобы добиться этого, можно просто взять знак от этого выражения, именно это и будет видом линейного классификатора. Заметим, что формула не очень однородная, в ней есть свободный коэффициент, чтобы убрать его, давайте просто добавим еще один признак выборки, константный признак, который на каждом объекте принимает значение 1, единичный признак. В этом случае свободный коэффициент уже не нужен, его роль будет выполнять вес при этом константном признаке, и формула приобретает такое значение. Заметим, что по сути такая взвешенная сумма признаков — это скалярное произведение вектора весов на вектор признаков, и значит итоговый вид линейного классификатора — это знак скалярного произведения w на x, этой формулой мы и будем пользоваться дальше. Давайте разберемся, какой геометрический смысл у линейного классификатора. В случае с линейной регрессией мы обсуждали, что это по сути приближение зависимости ответа от признаков с помощью прямой или гиперплоскости. Что же это будет в случае с классификацией? Для этого давайте запишем то, что стоит под функцией знака — скалярное произведение w на x, и приравняем к 0, получим такое уравнение. Давайте нарисуем вектор весов w и будем искать все такие точки x, которые удовлетворяют этому уравнению, то есть все такие точки, для которых скалярное произведение этой точки, этого вектора на w = 0. Равенство нулю скалярного произведения означает, что угол между этими векторами = 90 градусов, то есть что они перпендикулярны. Получается, что точки, удовлетворяющие этому уравнению — это все векторы, ортогональные вектору весов. Из аналитической геометрии известно, что это множество представляет собой плоскость. Получается, что уравнение задает плоскость, более того, с одной стороны от этой плоскости значение скалярного произведения будет больше 0, а с другой стороны от плоскости — меньше 0. Получается, что линейный классификатор проводит гиперплоскость в пространстве признаков, и все объекты, которые с одной стороны, относят к классу +1, а те, которые с другой стороны — к классу −1. В случае с двумя признаками это выглядит как-то так: у нас есть выборка, мы проводим разделяющую прямую, и все объекты, которые с одной стороны, относим к классу −1, все, которые с другой стороны, относим к классу +1. Заметим, что линейные классификаторы вычисляют значение скалярного произведения, которое имеет вещественное значение, а затем берет только знак, отбрасывая часть информации. При этом, наверное, само значение скалярного произведения тоже имеет смысл. Действительно, оказывается, что если мы возьмем модуль этого скалярного произведения и отнормируем его, то есть поделим на норму вектора весов, то это выражение будет равно расстоянию от точки x до гиперплоскости, которая задается вектором нормали, вектором весов w. Получается, что линейный классификатор сначала измеряет расстояние от точки до гиперплоскости со знаком и дальше смотрит лишь на знак, то есть на то, с какой стороны от гиперплоскости лежит эта точка. Так мы приходим к очень важному понятию в линейной классификации — к понятию отступа. Отступом называется выражение вида: скалярное произведение вектора весов на объект, умноженное на истинный ответ на этом объекте, который, напомню, равен +1 и −1. Какой смысл у этого выражения? Давайте обратим внимание: если скалярное произведение имеет положительный знак и истинный ответ равен +1 — это верная классификация и произведение скалярного произведения на истинный ответ будет больше 0. Если скалярное произведение меньше 0, и истинный ответ равен −1, то это тоже будет правильная классификация, и их произведение снова будет больше 0. Если же знак ответа и знак скалярного произведения противоположные, то классификация будет ошибочной и знак отступа будет меньше 0. Получается, что отступ — это некоторая величина, которая характеризует корректность ответа. Если отступ больше 0, то алгоритм дает корректный ответ, если отступ меньше 0 — алгоритм дает некорректный ответ. При этом само абсолютное значение отступа свидетельствует о расстоянии от точки до разделяющей гиперплоскости. Принято считать, что если точка находится рядом с разделяющей гиперплоскостью, то классификация неуверенная, наш алгоритм сомневается, к какому классу относить ее, если же точка находится далеко от разделяющей гиперплоскости, то классификация уверенная, при этом, если алгоритм прав, то он просто уверен в этом, все хорошо, если же алгоритм ошибается, и при этом отступ по модулю очень большой, это означает, что алгоритм очень сильно ошибается в классификации этого объекта, возможно, этот объект является выбросом и никак не вписывается в нашу модель, или же алгоритм не подходит для решения этой задачи. Итак, мы с вами обсудили, что линейный классификатор по сути строит гиперплоскость в пространстве признаков и с ее помощью разделяет 2 класса. Также мы ввели понятие отступа, знак которого позволяет понять — корректный ответ дает классификатор или нет на этом объекте, а абсолютное значение отступа говорит об уверенности классификатора в этом объекте. В следующем видео мы поговорим о том, как измерять качества, как измерять ошибку линейного классификатора и как его настраивать.

В этом видео мы поговорим о том, как измерять ошибку в задачах классификации и как обучать линейные классификаторы. В прошлый раз мы выяснили, что в задачах бинарной классификации линейный классификатор строит гиперплоскость, которая пытается разделить два класса. При этом те объекты, которые оказываются слева от нее, она относит к одному классу, а те, которые справа от нее, — к другому классу. В случае с регрессией измерить качество было довольно просто. Прогноз и ответ — это вещественные числа. Их бесконечно много, и мы требовали, чтобы они были как можно ближе друг к другу. При этом есть много способов измерить сходство двух вещественных чисел. Это квадратичное отклонение или абсолютное отклонение. Можно придумать и другие подходы к измерению сходства чисел. В случае с классификацией возникает вполне естественный подход. У нас ответов конечное число. Соответственно, можем требовать точного совпадения класса, предсказанного алгоритмом A(Xi), и истинного класса Yi. Соответственно, функционал, который мы получаем, — это доля неправильных ответов, доля ошибочных ответов. Он записывается вот так. Это сумма индикаторов того, что предсказанный класс A(Xi) не совпал с истинным классом Yi. И все это усредняется по всей обучающей выборке. Давайте вспомним, что в прошлый раз мы изучали понятие отступа, который позволяет понять, ошибается или нет алгоритм на данном объекте. Отступ на этом объекте задается как произведение истинного ответа Yi на скалярное произведение вектора весов W на вектор признаков Xi. Если отступ меньше нуля, то алгоритм ошибается на данном объекте. Соответственно, наш функционал долю неправильных ответов можно переписать, как среднее значение индикатора того, что отступ на (i) объекте меньше нуля. Давайте посмотрим, как выглядит функция, которая стоит под знаком суммы. Индикатор того, что отступ меньше нуля. По оси "Икс" отложим отступ Mi, отступ на этом объекте, по оси "Игрек" — значение функции потерь, значение индикатора. Мы видим, что эта функция пороговая. Она равна единице, если отступ меньше нуля, и нулю, если отступ больше нуля. Эта функция является разрывной, у нее разрыв в нуле. Из-за этого ее нельзя оптимизировать градиентными методами. Конечно, можно воспользоваться методами негладкой оптимизации, которые мы изучали в прошлом курсе, но они довольно сложные в реализации и не дают гарантии сходимости к локальному оптимуму. Поэтому давайте попробуем как-то изменить задачу, чтобы она стала гладкой. Для этого возьмем индикатор того, что отступ меньше нуля, нашу пороговую функцию потерь. Оценим сверху этот индикатор некоторой гладкой функцией "L с волной", которая также зависит от отступа M. То есть это должна быть такая функция, которая больше или равна единице, если отступ отрицательный, и больше или равна нуля, если отступ положительный. Далее, используя данную верхнюю оценку "L с волной", мы можем оценить весь функционал ошибки, весь функционал доли неверных ответов. Верхняя оценка на этот функционал будет выглядеть так: это среднее значение нашей гладкой функции потерь "L с волной" по всей обучающей выборке. Обратите внимание: в этом случае мы будем минимизировать не долю неправильных ответов, а среднее значение нашей гладкой функции потерь "L с волной". При этом мы надеемся, что если мы приведем к нулю данное среднее значение гладкой функции, то при этом прижмется к нулю и то, что она оценивает сверху, прижмется к нулю доля неправильных ответов. Но при этом, конечно же, нет никаких гарантий, что, минимизируя верхнюю оценку, мы будем точно минимизировать и то, что она оценивает, то есть долю неправильных ответов. Но при этом мы получаем очень удобную, хорошую гладкую задачу минимизации. Давайте рассмотрим несколько примеров таких гладких оценок. Например, это может быть логистическая функция потерь L(M), которая записывается как логарифм, под которым стоит единица плюс экспонента от минус отступа. Она используется в логистической регрессии, которую вы будете изучать позже в нашем курсе. Другие примеры — это экспоненциальная функция потерь или кусочно-линейная, которые используются в методе опорных векторов. Вот графики этих функций. Видно, что они все, действительно, оценивают сверху пороговую функцию потерь. При этом все они делают это по-разному. Какие-то имеют экспоненциальный рост, какие-то более медленный темп роста при уменьшении отступа. Давайте возьмем для примера логистическую функцию потерь и запишем функционал для нее. Он будет выглядеть вот так. Мы усредняем значение данной функции. Этот функционал будет гладким. Чтобы понять, как его оптимизировать, давайте поставим вместо отступа его определение. То есть Yi истинный ответ, умноженный на скалярное произведение вектора весов на вектор признаков Xi. Видно, что мы получили гладкий, хороший функционал, у которого легко посчитать градиенты по вектору весов W и осуществлять градиентный спуск или пользоваться любым другим вашим любимым методом оптимизации. Итак, что мы делаем при решении задачи классификации, при обучении линейного классификатора? Мы оцениваем сверху долю неправильных ответов, наш базовый функционал ошибки, с помощью некоторой гладкой функции потерь, например, логистической. И далее минимизируем эту гладкую функцию потерь с помощью любого метода оптимизации — стохастического градиентного спуска, градиентного спуска или чего-то еще. И при этом надеемся, что минимизации данного функционала будет также приводить к минимизации доли неправильных ответов. Кстати, обратите внимание: в случае с логистической функцией потерь, даже если все отступы стали больше нуля, все равно алгоритм градиентной оптимизации будет стремиться увеличивать отступы, то есть увеличивать уверенность классификатора в этих ответах. Это довольно хорошее свойство. Итак, мы с вами выяснили, что в задачах классификации есть вполне логичный функционал потерь — доля ошибок, при этом он негладкий, и нужно его оценивать сверху. И далее классификатор настраивается путем минимизации гладкой аппроксимации функционала ошибки. На этом наш урок про линейные методы заканчивается, и заканчивается первый модуль курса. А следующий модуль мы начнем с того, что обсудим проблему переобучения и методы борьбы с ней.

Линейные модели
2.1. Линейные модели в задачах регрессии
Данный урок будет посвящен линейным моделям. Речь пойдет о задачах классификации и регрессии, как
их обучать, и с какими проблемами можно столкнуться при использовании этих моделей. В этом блоке мы
обсудим, как выглядят линейные модели в задачах регрессии.
2.1.1. Повторение обозначений из прошлого урока
Для начала необходимо напомнить некоторые обозначения, которые были введены на прошлом уроке.
• X — пространство объектов
• Y — пространство ответов
• x = (x
1
, ..., xd
) — признаковое описание объекта
• X = (xi
, yi)
`
i=1 — обучающая выборка
• a(x) — алгоритм, модель
• Q(a, X) — функционал ошибки алгоритма a на выборке X
• Обучение: a(x) = argmina∈A Q(a, X)
Напомним, что в задаче регрессии пространство ответов Y = R. Чтобы научиться решать задачу регрессии,
необходимо задать:
• Функционал ошибки Q: способ измерения того, хорошо или плохо работает алгоритм на конкретной
выборке.
• Семейство алгоритмов A: как выглядит множество алгоритмов, из которых выбирается лучший.
• Метод обучения: как именно выбирается лучший алгоритм из семейства алгоритмов.
2.1.2. Пример задачи регрессии: предсказание прибыли магазина
Пусть известен один признак — прибыль магазина в прошлом месяце, а предсказать необходимо прибыль
магазина в следующем. Поскольку прибыль — вещественная переменная, здесь идет речь о задаче регрессии.
Прибыль в прошлом месяце
Прибыль в текущем месяце
Рис. 2.1: Точки обучающей выборки.
1
По этому графику можно сделать вывод о существовании зависимости между прибылью в следующем и
прошлом месяцах. Если предположить, что зависимость приблизительно линейная, ее можно представить в
виде прямой на этом графике. По этой прямой и можно будет предсказывать прибыль в следующем месяце,
если известна прибыль в прошлом.
В целом такая модель угадывает тенденцию, то есть описывает зависимость между ответом и признаком.
При этом, разумеется, она делает это не идеально, с некоторой ошибкой. Истинный ответ на каждом объекте
несколько отклоняется от прогноза.
Один признак — это не очень серьезно. Гораздо сложнее и интереснее работать с многомерными выборками, которые описываются большим количеством признаков. В этом случае нарисовать выборку и понять,
подходит или нет линейная модель, нельзя. Можно лишь оценить ее качество и по нему уже понять, подходит
ли эта модель.
Следует отметить, что вообще нельзя придумать модель, которая идеально описывает ваши данные, то
есть идеально описывает, как порождается ответ по признакам.
2.1.3. Описание линейной модели
Далее обсудим, как выглядит семейство алгоритмов в случае с линейными моделями. Линейный алгоритм в
задачах регрессии выглядит следующим образом:
a(x) = w0 +
X
d
j=1
wjx
j
,
где w0 — свободный коэффициент, x
j — признаки, а wj — их веса.
Если добавить (d + 1)-й признак, который на каждом объекте принимает значение 1, линейный алгоритм
можно будет записать в более компактной форме
a(x) = X
d+1
j=1
wjx
j = hw, xi,
где используется обозначение hw, xi для скалярного произведения двух векторов.
В качестве меры ошибки не может быть выбрано отклонение от прогноза Q(a, y) = a(x) − y, так как в
этом случае минимум функционала не будет достигаться при правильном ответе a(x) = y. Самый простой
способ — считать модуль отклонения:
|a(x) − y|.
Но функция модуля не является гладкой функцией, и для оптимизации такого функционала неудобно использовать градиентные методы. Поэтому в качестве меры ошибки часто выбирается квадрат отклонения:
(a(x) − y)
2
.
Функционал ошибки, именуемый среднеквадратичной ошибкой алгоритма, задается следующим образом:
Q(a, x) = 1
`
X
`
i=1
(a(xi) − yi)
2
В случае линейной модели его можно переписать в виде функции (поскольку теперь Q зависит от вектора, а
не от функции) ошибок:
Q(w, x) = 1
`
X
`
i=1
(hw, xii − yi)
2
.
2.2. Обучение модели линейной регрессии
В этом блоке речь пойдет о том, как обучать модель линейной регрессии, то есть как настраивать ее параметры. В прошлый раз было введено следующее выражение для качества линейной модели на обучающей
выборке:
Q(w, x) = 1
`
X
`
i=1
(hw, xii − yi)
2 → min
w
.
Следует напомнить, что в число признаков входит также постоянный признак, равный 1 для всех объектов,
что позволяет исключить постоянную составляющую в последнем соотношении.
2
2.2.1. Переход к матричной форме записи
Прежде, чем будет рассмотрена задача оптимизации этой функции, имеет смысл переписать используемые
соотношения в матричной форме. Матрица «объекты–признаки» X составлена из признаковых описаний всех
объектов из обучающей выборки:
X =


x11 ... x1d
... ... ...
x`1 ... x`d


Таким образом, в ij элементе матрицы X записано значение j-го признака на i объекте обучающей выборки.
Также понадобится вектор ответов y, который составлен из истинных ответов для всех объектов:
y =


y1
...
y`

 .
В этом случае среднеквадратичная ошибка может быть переписана в матричном виде:
Q(w, X) = 1
`
kXw − yk
2 → min
w
.
Эта формула пригодится, в частности, при реализации линейной регрессии на компьютере.
2.2.2. Аналитический метод решения
Можно найти аналитическое решение задачи минимизации:
w∗ = (XT X)
−1XT
y.
Основные сложности при нахождении решения таким способом:
• Для нахождения решения необходимо вычислять обратную матрицу. Операция обращения матрицы
требует, в случае d признаков, выполнение порядка d
3 операции, и является вычислительно сложной
уже в задачах с десятком признаков.
• Численный способ нахождения обратной матрицы не может быть применен в некоторых случаях (когда
матрица плохо обусловлена).
2.2.3. Оптимизационный подход к решению
Другой, несколько более удобный, способ найти решение — использовать численные методы оптимизации.
Несложно показать, что среднеквадратическая ошибка — это выпуклая и гладкая функция. Выпуклость
гарантирует существование лишь одного минимума, а гладкость — существование вектора градиента в каждой
точке. Это позволяет использовать метод градиентного спуска.
При использовании метода градиентного спуска необходимо указать начальное приближение. Есть много
подходов к тому, как это сделать, в том числе инициализировать случайными числами (не очень большими).
Самый простой способ это сделать — инициализировать значения всех весов равными нулю:
w
0 = 0.
На каждой следующей итерации, t = 1, 2, 3, ..., из приближения, полученного в предыдущей итерации w
t−1
,
вычитается вектор градиента в соответствующей точке w
t−1
, умноженный на некоторый коэффициент ηt,
называемый шагом:
w
t = w
t−1 − ηt∇Q(w
t−1
, X).
Остановить итерации следует, когда наступает сходимость. Сходимость можно определять по-разному. В данном случае разумно определить сходимость следующим образом: итерации следует завершить, если разница
двух последовательных приближений не слишком велика:
kw
t − w
t−1
k < ε.
Подробно метод градиентного спуска обсуждался в прошлом курсе этой специализации.
3
2.3. Градиентный спуск для линейной регрессии
2.3.1. Случай парной регрессии
В случае парной регрессии признак всего один, а линейная модель выглядит следующим образом:
a(x) = w1x + w0,
где w1 и w0 — два параметра.
Среднеквадратичная ошибка принимает вид:
Q(w0, w1, X) = 1
`
X
`
i=1
(w1xi + w0 − yi)
2
.
Для нахождения оптимальных параметров будет применяться метод градиентного спуска, про который уже
было сказано ранее. Чтобы это сделать, необходимо сначала вычислить частные производные функции ошибки:
∂Q
∂w1
=
2
`
X
`
i=1
(w1xi + w0 − yi)xi
,
∂Q
∂w0
=
2
`
X
`
i=1
(w1xi + w0 − yi).
2.3.2. Демонстрация градиентного спуска в случае парной регрессии
Следующие два графика демонстрируют применение метода градиентного спуска в случае парной регрессии. Справа изображены точки выборки, а слева — пространство параметров. Точка в этом пространстве
обозначает конретную модель.
Рис. 2.2: Демонстрация метода градиентного спуска.
4
График зависимости функции ошибки от числа произведенных операции выглядит следующим образом:
0 20 40 60 80 100
0
50
100
150
200
250
300
номер итерации
ошибки
Рис. 2.3: Ошибка в зависимости от номера итерации
2.3.3. Выбор размера шага в методе градиентного спуска
Очень важно при использовании метода градиентного спуска правильно подбирать шаг. Каких-либо конкретных правил подбора шага не существует, выбор шага — это искусство, но существует несколько полезных
закономерностей.
w1
w2
w3
w4
w5
w1
w3
w5
w7
w2
w4
w6
Рис. 2.4: Случаи маленького и большого шага
Если длина шага слишком мала, то метод будет неспеша, но верно шагать в сторону минимума. Если же
взять размер шага очень большим, появляется риск, что метод будет перепрыгивать через минимум. Более
того, есть риск того, что градиентный спуск не сойдется.
Имеет смысл использовать переменный размер шага: сначала, когда точка минимума находится еще далеко, двигаться быстро, а позже, спустя некоторое количество итерации — делать более аккуратные шаги.
Один из способов задать размер шага следующий:
ηt =
k
t
,
где k — константа, которую необходимо подобрать, а t — номер шага.
2.3.4. Случай многомерной линейной регрессии
В случае многомерной линейной регрессии используется тот же самый подход — необходимо решать задачу
минимизации:
Q(w, X) = 1
`
kXw − yk
2 → min
w
,
где kxk — норма вектора x. Формула для вычисления градиента принимает следующий вид:
∇wQ(w, X) = 2
`
XT
(Xw − y)
5
Стоит отметить, что вектор Xw − y, который присутствует в данном выражении, представляет собой вектор
ошибок.
2.4. Стохастический градиентный спуск
В этом блоке речь пойдет о стохастическом градиентном спуске, который особенно хорошо подходит для
обучения линейных моделей.
2.4.1. Недостатки обычного метода градиентного спуска
В обычном методе градиентного спуска на каждом шаге итерации следующее приближение получается из
предыдущего вычитанием вектора градиента, умноженного на шаг ηt:
w
t = w
t−1 − ηt∇Q(w
t−1
, X).
При этом выражение для градиента в матричной форме имеет вид:
∇wQ(w, X) = 2
`
XT
(Xw − y)
Выражение для j-ой компоненты градиента, таким образом, содержит суммирование по всем объектам обучающей выборки:
∂Q
∂wj
=
2
`
X
`
i=1
x
j
i
(hw, xii − yi).
В этом и состоит основной недостаток метода градиентного спуска — в случае большой выборки даже одна
итерация метода градиентного спуска будет производиться долго.
2.4.2. Стохастический градиентный спуск
Идея стохастического градиентного спуска основана на том, что в сумме в выражении для j-компоненты
градиента i-ое слагаемое указывает то, как нужно поменять вес wj , чтобы качество увеличилось для i-го
объекта выборки. Вся сумма при этом задает, как нужно изменить этот вес, чтобы повысить качество для всех
объектов выборки. В стохастическом методе градиентного спуска градиент функции качества вычисляется
только на одном случайно выбранном объекте обучающей выборки. Это позволяет обойти вышеупомянутый
недостаток обычного градиентного спуска.
Таким образом, алгоритм стохастического градиентного спуска следующий. Сначала выбирается начальное приближение:
w
0 = 0
Далее последовательно вычисляются итерации w
t
: сначала случайным образом выбирается объект xi из
обучающей выборки X и вычисляется вектор градиента функции качества на этом объекте, а следующее
приближение получается из предыдущего вычитанием умноженного на шаг ηt полученного вектора:
w
t = w
t−1 − ηt∇Q(w
t−1
, {xi}).
Итерации прекращаются при достижении определенного условия, например:
kw
t − w
t−1
k < ε.
2.4.3. Сходимость стохастического градиентного спуска
Показательно посмотреть на графики сходимости градиентного спуска и стохастического градиентного спуска. В обычном градиентном спуске на каждом шаге уменьшается суммарная ошибка на всех элементах обучающей выборки. График в таком случае обычно получается монотонным.
6
0 20 40 60 80 100
0
50
100
150
200
250
300
номер итерации
ошибки
Рис. 2.5: Ошибка в зависимости от номера итерации
Напротив, в стохастическом методе весовые коэффициенты меняются таким образом, чтобы максимально
уменьшить ошибку для одного случайно выбранного объекта. Это приводит к тому, что график выглядит
пилообразным, то есть на каждой конкретной итерации полная ошибка может как увеличиваться, так и
уменьшаться. Но в итоге с ростом номера итерации значение функции уменьшается.
2.4.4. Особенности стохастического градиентного спуска
Стохастический градиентный спуск (SGD) обладает целым рядом преймуществ. Во-первых, каждый шаг выполняется существенно быстрее шага обычного градиентного метода, а также не требуется постоянно хранить
всю обучающую выборку в памяти. Это позволяет использовать для обучения выборки настолько большие,
что они не помещаются в память компьютера. Стохастический градиентный спуск также можно использовать
для онлайн-обучения, то есть в ситуации, когда на каждом шаге алгоритм получает только один объект и
должен учесть его для коррекции модели.
2.5. Линейная классификация
2.5.1. Задача бинарной классификации
В этом разделе рассматривается задача линейной классификации, то есть применение линейных моделей к
задаче классификации. Речь пойдет о самом простом виде классификации — бинарной классификации. В
случае бинарной классификации множество возможных значений ответов состоит из двух элементов:
Y = {−1, +1}.
Как уже было сказано, чтобы работать с той или иной моделью нужно:
• Выбрать функционал (функцию) ошибки, то есть задать способ определения качества работы того или
иного алгоритма на обучающей выборке.
• Построить семейство алгоритмов, то есть множество алгоритмов, из которого потом будет выбираться
наилучший с точки зрения определенного функционала ошибки.
• Ввести метод обучения, то есть определить способ выбора лучшего алгоритма из семейства.
2.5.2. Линейный классификатор
Ранее была рассмотрена задача линейной регрессии. В этом случае алгоритм представлял собой линейную
комбинацию признаков с некоторыми весами и свободным коэффициентом.
Линейные классификаторы устроены похожим образом, но они должны возвращать бинарные значения,
а следовательно требуется также брать знак от получившегося выражения:
a(x) = sign

w0 +
X
d
j=1
wjx
j

 .
7
Как и раньше, добавлением еще одного постоянного для всех объектов признака можно привести формулу к
более однородному виду:
a(x) = signX
d+1
j=1
wjx
j = signhw, xi
2.5.3. Геометрический смысл линейного классификатора
Выражение hw, xi = 0 является уравнением некоторой плоскости в пространстве признаков.
y
z
x
~w
Рис. 2.6: Геометрический смысл линейного классификатора
При этом для точек по одну сторону от этой плоскости скалярное произведение hw, xi будет положительным, а с другой — отрицательным.
Таким образом, линейный классификатор проводит плоскость в пространстве признаков и относит объекты по разные стороны от нее к разным классам.
Согласно геометрическому смыслу скалярного произведения, расстояние от конкретного объекта, который
имеет признаковое описание x, до гиперплоскости hw, xi = 0 равно
|hw,xi|
kwk
. С этим связано такое важное
понятие в задачах линейной классификации как понятие отступа:
Mi = yihw, xii.
Отступ является величиной, определяющей корректность ответа. Если оступ больше нуля Mi > 0, то классификатор дает верный ответ для i-го объекта, в ином случае — ошибается.
Причем чем дальше отступ от нуля, тем больше уверенность как в правильном ответе, так и в том,
что алгоритм ошибается. Если отступ для некоторого объекта отрицательный и большой по модулю, это
значит, что алгоритм неправильно описывает данные: либо этот объект является выбросом, либо алгоритм
не пригоден для решения данной задачи.
2.6. Функции потерь в задачах классификации
2.6.1. Пороговая функция потерь
В случае линейной классификации естественный способ определить качество того или иного алгоритма —
вычислить для объектов обучающей выборки долю неправильных ответов:
Q(a, x) = 1
`
X
`
i=1
[a(xi) 6= yi
]
8
С помощью введенного ранее понятия отступа можно переписать это выражение для случая линейной классификации в следующем виде:
Q(a, x) = 1
`
X
`
i=1

yihw, xii < 0

=
1
`
X
`
i=1

Mi < 0

Функция, стоящая под знаком суммы, называется функцией потерь. В данном случае это пороговая функция
потерь, график которой в зависимости от отступа выглядит следующим образом:
Mi
0
1
Рис. 2.7: График пороговой функции потерь
Такая функция является разрывной в точке 0, что делает невозможным применение метода градиентного
спуска. Можно, конечно, использовать методы негладкой оптимизации, о которых шла речь в прошлом курсе,
но они сложны в реализации.
2.6.2. Оценка функции потерь
Используя любую гладкую оценку пороговой функции:

Mi < 0

≤ L˜(Mi)
можно построить оценку Q˜(a, X) для функционала ошибки Q(a, X):
Q(a, X) ≤ Q˜(a, X) = 1
`
X
`
i=1
L˜(Mi).
В этом случае минимизировать нужно будет не долю неправильных ответов, а некоторую другую функцию,
которая является оценкой сверху:
Q(a, X) ≤ Q˜(a, X) = 1
`
X
`
i=1
L˜(Mi) → min
a
.
Здесь используется предположение, что в точке минимума этой верхней оценки число ошибок также будет
минимально. Строго говоря, это не всегда так.
2.6.3. Примеры оценок функции потерь
Примерами таких оценок функции потерь являются:
• Логистическая функция потерь (используется в логистической регрессии, о которой пойдет речь позже
в данном курсе):
L˜(M) = log2

exp(−M)

• Экспоненциальная функция потерь:
L˜(M) = exp(−M)

• Кусочно-линейная функция потерь (используется в методе опорных векторов):
L˜(M) = max(0, 1 − M)
Mi
0
1
2
Рис. 2.8: Графики различных функций потерь: пороговая (красная линия), экспоненциальная (синяя), логистическая (оранжевая) и кусочно-линейная (серая).
2.6.4. Логистическая функция потерь
В случае логистической функции потерь функционал ошибки имеет вид:
Q˜(a, X) = 1
`
X
`
i=1
ln
exp(−Mi)

=
1
`
X
`
i=1
ln
exp(−yihw, xii)

.
Получившееся выражение является гладким, а, следовательно, можно использовать, например, метод градиентного спуска.
Следует обратить внимание, что в случае, если число ошибок стало равно нулю, все равно в ходе обучения
алгоритма линейной классификации будут увеличиваться отступы, то есть будет увеличиваться уверенность
в полученных результатах
Проблема переобучения и борьба с ней

Мы начинаем урок, посвящённый проблеме переобучения и вопросу оценивания качества алгоритмов. По итогам этого урока вы будете понимать, как оценить качество алгоритма на новых неизвестных данных, а также как сравнить много алгоритмов и выбрать из них лучший. А начнём урок мы с того, что разберёмся с тем, что такое переобучение, и почему это очень плохо. Давайте рассмотрим простой пример. Допустим, мы решаем задачу классификации и построили некоторый алгоритм, например, линейный классификатор, и измеряем долю ошибок на обучающей выборке. Допустим, она получилась 0.2, то есть мы допускаем ошибку на двадцати процентах объектов обучающей выборки. Предположим, что нас это устроило, и мы используем этот алгоритм дальше. Но как понять из того, что у него небольшая доля ошибок на обучении, извлёк ли он закономерности, может ли он хорошо работать на новых данных? На самом деле, никаких гарантий нет. Легко может оказаться, что мы возьмём новую выборку, применим к ней наш уже обученный алгоритм и получим, что доля ошибок на новой выборке равна 0.9, то есть алгоритм ошибается на 90 % объектов. Это никуда не годится. Значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из него закономерности и применить эти знания для классификации новых объектов. Но при этом, заметьте, что мы получили хорошее качество на обучении. То есть алгоритм как-то смог подогнаться под обучение, не извлекая из него закономерностей. Эта проблема и называется переобучение. Чтобы чуть лучше понять, в чём заключается переобучение, давайте рассмотрим классический пример про линейную регрессию. Итак, рассмотрим некоторую выборку. Объекты выборки обозначены синими точками, это одномерная выборка и сдача регрессии. По оси x отложено значение признака, по оси y — значение ответа. Истинная зависимость между ответом и признаком выглядит как зелёная кривая. Видно, что это такая нелинейная зависимость с двумя экстремумами. И давайте будем пробовать разные модели, с помощью которых будем пытаться предсказывать ответы. И начнём мы с константной регрессии, то есть алгоритм a(x) будет иметь вид w0, где w0 — некоторая константа. Настроив эту модель под данные, мы получим некоторую красную горизонтальную прямую, которая видно, что никуда не годится: она довольно плохо обобщает информацию. Эта проблема называется недообучением. Мы не смогли построить хороший алгоритм из-за того, что семейство алгоритмов слишком простое, оно не может уловить закономерности. Понятно, что решением является усложнение семейства алгоритмов. Хорошо, давайте рассмотрим линейную регрессию, то есть алгоритмы вида w0 + w1 * x. Настроив такой алгоритм под нашу выборку, мы всё ещё недообучимся. Видно, что получилось чуть лучше, но красная прямая всё ещё довольно плохо описывает наши данные, потому что она является линейной, а закономерность является нелинейной. Хорошо, давайте возьмём многочлен третьей степени. То есть алгоритм вида w0 + w1 * x + w2 * x² + w3 * x³, — многочлен третьей степени. Настроив его на нашу выборку, мы увидим, что полученный алгоритм, то есть красная кривая, очень хорошо приближает истинную зависимость. Скорее всего, нас устраивает такая модель. Мы её и оставим, будем ей пользоваться. Но при этом, смотрите, совпадение между красными и зелёными кривыми неидеальное. Что если ещё чуть-чуть усложнить алгоритм? Может, мы получим ещё более качественную модель. Хорошо, давайте возьмём многочлен девятой степени. И в этом случае мы получим вот такую закономерность. Видно, что восстановленная зависимость, красная кривая, — очень плохая. Да, она даёт идеальные ответы на всех объектах обучающей выборки, она проходит через все синие точки. Но при этом в любой другой точке ответ никуда не годится. Эти ответы никак не соответствуют истинной зелёной зависимости. Это является переобучением. Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие ответы на новых точках. Итак, мы выяснили, что недообучение — это проблема, в которой алгоритм имеет плохое качество и на обучающей выборке, и на новых данных. А переобучение — это проблема, при которой алгоритм имеет хорошее качественной обучение, но плохое качество о новых данных. При этом с недообучением понятно как бороться: нужно усложнять семейство алгоритмов, брать более сложные алгоритмы, например, многочлены высокой степени вместо линейных. А вот с переобучением всё сложнее. Дело в том, что хороший алгоритм, который хорошо обобщает информацию, будет иметь хорошее качественное обучение. Переобученный алгоритм тоже будет иметь хорошее качество на обучающей выборке. Отличаются они только по качеству на новых данных. Хороший алгоритм будет хорошо работать в новых данных, а переобученный — плохо. Получается, что, имея лишь обучающую выборку, а мы имеем лишь её в момент настройки алгоритма, мы не можем понять, переобучился он или нет. Нам нужна какая-то дополнительная информация или дополнительные данные, чтобы выявить переобучение. Мы приходим к нескольким подходам к выявлению переобучения. Например, можно откладывать часть выборки, не использовать её при обучении, и дальше уже обученный алгоритм проверять на этой отложенной выборке. Или, например, есть кросс-валидация — это усложнённая версия отложенной выборки, о которой мы будем говорить в этом уроке. Также есть некоторые меры сложности модели, которые позволяют без дополнительной выборки понять, получилась ли модель слишком сложной или нет. Об этом мы и поговорим в следующем видео. И в качестве небольшой затравки давайте посмотрим, что получилось, когда мы настраивали многочлен девятой степени. Заметьте, что, по сути, обучение такого многочлена — это обучение линейной регрессии над признаками x, x в квадрате, и так далее, до x в девятой степени, то есть над девятью признаками. И если посмотреть на веса модели, которая получилась, окажется, что порядок весов очень большой — это миллионы и десятки миллионов. Если же посмотреть на порядок весов в модели третьей степени (в многочлене третьей степени), которая хорошо подходила под данные, можно увидеть, что там порядок гораздо ниже. Таким образом, наверное, абсолютные значения весов как-то говорят о том, насколько сложная модель у нас получилась. Итак, мы с вами выяснили, что переобучение — это проблема, которая состоит в излишней подгонке алгоритма под обучающую выборку, из-за чего страдает его качество на новых данных. Также мы выяснили, что одним из симптомов переобучения линейных моделей являются большие веса в этих моделях, что мы будем использовать в следующем уроке, когда будем говорить про регуляризацию — способ борьбы с переобучением в линейных методах.

В этом видео мы поговорим про регуляризацию — способ борьбы с переобучением в линейных моделях. В прошлый раз мы с вами убедились, что мерой сложности или симптомом переобученности линейной модели являются большие веса при признаках. Например, когда мы пытались обучить полином 9-й степени под вот такую выборку, мы получали переобученную модель, коэффициенты которой были огромными — миллионы и десятки миллионов. Еще одна ситуация, в которой можно столкнуться с переобучением — это мультиколлинеарность. Так называется проблема, при которой признаки выборки являются линейно зависимыми, то есть есть некоторый вектор значений признака на всех объектах, который выражается через векторы других признаков. Или, иными словами, это означает, что существуют такие веса α1, ..., αd, что какой бы объект обучающей выборки xi мы не взяли, оказывается, что если мы просуммируем с этими коэффициентами все значения признаков на этом объекте xi, получим 0. Это, по сути, есть определение линейной зависимости. Более компактно это можно записать как равенство нулю скалярного произведения вектора коэффициентов α на вектор признаков xi. Итак, в чем проблема мультиколлинеарности? Давайте представим, что мы решаем некоторую оптимизационную задачу, например минимизируем среднеквадратичную ошибку, то есть средний квадрат отклонения прогноза от истинного ответа yt. И нашли оптимальную точку w* — точку, на которой достигается минимум этого функционала. Хорошо, а теперь давайте возьмем этот оптимальный вектор весов w* и прибавим к нему тот вектор коэффициентов α из определения линейной зависимости с некоторым множителем t, скалярным множителем. И давайте посмотрим, как будет выглядеть прогноз алгоритма с этим новым модифицированным вектором весов на некотором объекте x. Для этого нужно посчитать скалярное произведение вектора w* + tα на вектор x. По правилам скалярного произведения это выражение распадается на сумму двух скалярных произведений. Первое — это w* умножить на x, второе — это α умножить на x с некоторым скалярным множителем t. Но при этом давайте вспомним, что α умножить на x скалярное — это 0, просто по определению линейной зависимости. Получаем, что прогноз нашего модифицированного алгоритма равен w* умножить на x, то есть прогнозу исходного оптимального алгоритма. Значит, мы получили новый алгоритм с новым векторов весов, который во всем совпадает с исходным алгоритмом. Получается, что и значение функционала качества, функционала ошибки на этом алгоритме будет такое же — он тоже будет оптимальным. Итак, в случае с мультиколлинеарностью у нас бесконечно много оптимальных алгоритмов, при этом многие из них будут иметь очень большие значения весов, но далеко не все из них хорошо обобщают информацию, обладают хорошей обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением. Итак, мы выяснили, что симптомом переобучения являются большие веса в линейной модели — давайте будем штрафовать за это модель, чтобы бороться с переобучением. Делать это будем с помощью регуляризатора. Итак, допустим, есть некоторый функционал ошибки Q, которому на вход подаются, напомню, векторы весов w и выборка x. Будем прибавлять к нему квадратичный регуляризатор, то есть L2 — норму вектора весов, или просто сумму квадратов весов. И теперь заменим функционал ошибки на следующий: он будет представлять собой сумму исходного функционала Q и регуляризатора с некоторым коэффициентом λ. И будем минимизировать эту сумму. Ее минимизация приведет к тому, что мы хотим одновременно сделать ошибку на обучающей выборке как можно меньше, то есть минимизировать Q, но и при этом не слишком сильно увеличить веса при признаках, то есть не слишком сильно увеличить норму весов w. При этом у нас появляется новый параметр в модели — коэффициент регуляризации λ, который стоит перед своим регуляризатором. Чем больше мы делаем λ, тем менее сложные модели будут получаться. Если мы будем увеличивать λ все сильнее и сильнее, то в какой-то момент окажется, что оптимально просто занулить все веса, сделать их нулевыми. То есть слишком большая λ приведет к слишком простой константной модели. В то же время если λ делать маленькой, то есть риск переобучения, риск, что модель окажется слишком сложной. Таким образом, нужно искать некоторый баланс — выбирать λ такой, что, с одной стороны, она не допускает переобучения, с другой — позволяет делать модель достаточно сложной, чтобы уловить все закономерности в данных. Обычно λ подбирается по кросс-валидации, о которой будем говорить в следующем видео. А пока давайте выясним, какой смысл имеет добавление регуляризатора. Оказывается, что наша новая задача — Q + λ умножить на регуляризатор, и это мы минимизируем — эквивалентна условной задаче оптимизации, которая выглядит следующим образом. Мы минимизируем исходный функционал ошибки Q при ограничении. А ограничение состоит в том, что норма вектора весов не должна превосходить некоторую константу C. Получается, что мы решаем исходную задачу, но при этом ограничиваем по норме векторы весов, ровно то, что мы и хотели делать — штрафовать за слишком большую норму весов. Геометрически это означает, что если у нас есть некоторый функционал ошибки, который выпуклый и его линии уровня выглядят как-то вот так, то без регуляризатора мы бы просто искали минимум этого функционала — находили минимальную точку. После же добавления регуляризатора мы требуем, чтобы и решение находилось внутри некоторой круглой области с центром в 0. И теперь мы находим такое решение, которое находится внутри этой области и при этом как можно ближе к оптимальному решению без регуляризатора. Пока что мы говорили только про L2-регуляризатор — сумму квадратов весов. Он штрафует за сложность модели, и позволяет бороться с переобучение, и при этом является гладким и выпуклым, то есть его добавление к функционалу не будет усложнять процесс оптимизации, например, градиентный спуск. Но также есть L1-регуляризатор, который представляет собой L1-норму вектора весов, или просто сумму модулей весов. Он не является гладким — модуль не имеет производной в 0, то есть оптимизация функционала с таким регуляризатором будет затруднительна, но при этом такой регуляризатор обладает очень интересным свойством. Если использовать его, то часть весов в итоговом векторе весов будут нулевыми, то есть он производит отбор признаков — использует в модели не все признаки, а только самые важные из них. Это очень интересное свойство, которое часто пригождается на практике. Итак, мы обсудили, что большие веса в линейных моделях — это симптом переобучения. И для борьбы с этим переобучением можно пытаться «задавить» симптом, то есть штрафовать за слишком большие значения весов. Это можно делать с помощью L2-регуляризации, которая является самым частым выбором и штрафует за сложность модели. Или с помощью L1-регуляризации, которая чуть сложнее при оптимизации, но при этом позволяет отбирать признаки. В следующем видео мы поговорим про то, что такое кросс-валидация, и как оценивать качество алгоритма на новых данных.

В этом видео мы поговорим о том, как оценивать качество алгоритмов, как понимать, насколько хорошо алгоритм будет работать на новых данных. Как мы уже выясняли, например, переобучение сложно поймать только по обучающей выборке, и хороший алгоритм, который хорошо обобщает, и переобученный, будут показывать хорошее качество на обучении. И нужны какие-то дополнительные данные, дополнительная информация, чтобы понять, переобучился алгоритм или нет. Да, для этого еще можно использовать меры переобученности, например, регуляризатор — норму весов, но при этом все равно они не говорят о том, насколько хорошо алгоритм будет работать на новых данных. В этом видео мы попробуем понять, как предсказать, как понять, насколько хорошо он будет работать. То есть, например, какая у новых данных у алгоритма будет доля ошибок, если это классификация, или среднеквадратичная ошибка, если это задача регрессии. Понятно, что по обучающей выборке их оценивать нельзя, алгоритм подгонялся под обучающую выборку и, скорее всего, на ней значение качества будет неплохое. Самая простая идея того, как оценивать качество алгоритма, это построение отложенной выборки. Мы берем все данные, которые у нас есть, и разбиваем на две части. При этом первая выступает в качестве обучающей выборки, на нее мы настраиваем алгоритм, вторая выступает в качестве тестовой выборки, то есть на ней мы измеряем качество алгоритма, обученного на первой части. При этом мы измеряем качество как угодно, либо это среднеквадратичная ошибка, либо доля ошибок, либо что-то еще, в зависимости от специфики задачи. При этом сразу встает вопрос о том, в каких пропорциях разбивать данные на обучение и на тест. Если взять тестовую выборку слишком маленькой, отложенную выборку слишком маленькой, то, с одной стороны, обучающая выборка будет репрезентативной, и ее размер будет почти совпадать с размером настоящей обучающей выборки. Но, с другой, контрольная выборка, тестовая выборка, окажется слишком маленькой, в ней будет слишком мало объектов, чтобы надежно оценить качество, скорее всего, оценка качества будет зашумленной. Если же взять отложенную выборку слишком большой, то оценка по ней будет надежной, но, с другой стороны, обучение будет слишком маленьким, сильно меньше, чем настоящее обучение, и, например, мы можем увидеть качество очень небольшим, но из-за того, что обучения мало, что данных было слишком мало для обучения. Поэтому можно искать опять же какой-то баланс. Здесь нет конкретных советов, обычно берут разбиение в соотношении 70 к 30 или 80 к 20, где 70 и 80, соответственно, это размер обучения. Так же, например, есть подход, в котором размер обучающей выборки составляет 0,632 от общего размера данных. Преимуществом отложенной выборки является то, что обучать алгоритм нужно всего лишь один раз, на обучающей выборке. Но при этом результат очень сильно зависит от разбиения. Рассмотрим простой пример. Допустим, мы предсказываем стоимость жилья по некоторым характеристикам. И есть особая категория жилья, двухэтажные квартиры. Если вдруг окажется, что все двухэтажные квартиры, а их очень немного, попали в отложенную выборку, то мы увидим на них очень плохое качество, поскольку алгоритм не видел их на обучении, он ничего не знает о таких ситуациях и будет плохо предсказывать для них. При этом мы никогда не узнаем, что если бы хотя бы один такой объект оказался в обучении, то качество было бы гораздо лучше. Таким образом, результат измерения качества по отложенной выборке сильно зависит от того, как мы выбираем отложенную выборку, это не очень хорошо. Чтобы решить проблему, сразу приходит в голову следующий подход. Давайте много раз, n раз, разобьем все наши данные на обучение и тест, то есть много раз сгенерируем отложенную выборку. При этом каждый раз будем обучаться по обучающей выборке, измерять качество на отложенной выборке. Поскольку процедура повторяется n раз, мы получим n показателей качества, усредним их и получим итоговую оценку. Да, возможно, это уже решает проблему, но при этом, поскольку разбиения случайные, все еще нет гарантий, что каждый объект хотя бы раз побывает в обучении. Нужен более системный подход. Таким подходом является кросс-валидация. В ней предлагается следующее. Возьмем всю выборку и разобьем на k блоков примерно одинакового размера. И дальше каждый блок по очереди будет выступать в качестве тестового. Итак, сначала возьмем первый блок в качестве тестового, а все остальные в качестве обучения. Обучим алгоритм на обучающей выборке, измерим качество на тестовом блоке, запомним его. Далее возьмем второй блок в качестве тестового, все остальные сольем в обучающую выборку, обучимся и измерим качество, и так далее. Каждый блок побывает один раз тестовым, получим k показателей качества. Усредним их и получим оценку качества по кросс-валидации. При этом в кросс-валидации снова есть параметр, который нужно как-то выбирать, это число блоков k. Здесь ситуация примерно та же, что и с отложенной выборкой, если блоков мало, например, 3, то, с одной стороны, тестовая выборка при каждом разбиении на обучение и контроль, будет большой, то есть оценка по ней будет надежной, устойчивой, но при этом обучение окажется меньше, чем на самом деле, и есть риск, что оценка будет смещенной. Если же блоков мы берем много, то, с одной стороны, оценки ненадежные, тестовая выборка всегда маленькая, С другой стороны, оценки несмещенные, поскольку обучающая выборка всегда большая. Снова нет конкретных рекомендаций, каким выбирать k, обычно его берут равным трем, пяти или десяти, при этом, чем больше у вас данных, тем, как правило, меньше нужно больше блоков, потому что много блоков нужно, чтобы обучение было побольше, если у вас данных и так много, то даже удаление одной трети от всей выборки не приведет к тому, что у вас данных станет мало для обучения. При этом заметьте, что в кросс-валидации вам нужно обучать алгоритм k раз, поэтому опять же, если обучение алгоритма очень трудоемкое, очень много требует времени, то нужно брать k поменьше. Еще один совет, который относится ко всем этим способам. Всегда перемешивайте выборку перед тем, как делать отложенную выборку или кросс-валидацию. Дело в том, что в файле с данными выборка может быть отсортирована по какому-то неслучайному признаку. Например, сначала могут идти все мальчики, а потом все девочки. И если вы не перемешаете выборку и просто разобьете в соотношении 50 к 50, то получится, что в обучении у вас есть только мальчики, в контроле — только девочки, и, скорее всего, алгоритм будет показывать очень плохое качество, и вы долго будете пытаться понять, почему. Но при этом есть ситуации, в которых выборку нельзя перемешивать и нужно вполне понятным способом разбивать ее на обучение и контроль. Например, если вы строите алгоритм, который будет предсказывать погоду на следующие дни, понятно, что в момент, когда вы будете применять модель, у вас будет информация только о прошлом, и на основе нее нужно будет предсказывать будущее. Поэтому и когда вы будете разбивать выборку на обучение и тест, вам нужно следить, чтобы в обучении были дни, которые идут перед днями в тесте, иначе обучение будет заглядывать в будущее, и качество будет получаться завышенным. Итак, мы обсудили, что для грамотного оценивания качества алгоритма, нужно использовать данные не из обучающей выборки, для этого можно, например, делать отложенную выборку, или же оценивать качество по кросс-валидации. В следующем видео мы поговорим о том, как использовать эти подходы, чтобы сравнивать модели или выбирать гиперпараметры в них.

В этом видео мы поговорим о том, как выбирать гиперпараметры и сравнивать разные алгоритмы с помощью уже изученных нами схем — отложенной выборки или кросс-валидации. Давайте начнем с того, что разберемся, что такое гиперпараметры. Так называются те параметры алгоритмов, которые нельзя настраивать по обучающей выборке. Простым примером гиперпараметра является параметр регуляризации, поскольку регуляризатор штрафует модель и не дает ей слишком сильно подогнаться под обучающую выборку, понятно, что с точки зрения ошибки на обучение оптимально выставить параметр регуляризации в 0, то есть выключить регуляризатор. Другой пример гиперпараметра — это, например, степень полинома, с помощью которого мы описываем данные. В нашем примере про переобучение с точки зрения обучающей выборки оптимально было брать полином в степени 9, поскольку он проходил через через все точки обучения, давал нулевую ошибку на обучение. Но при этом понятно, что обобщающая способность у него была никакая. Более общая задача — это сравнение разных алгоритмов, например, сравнение качества алгоритмов, настроенных с разными значениями гиперпараметров. Или, предположим, вы можете настраивать алгоритмы на среднеквадратичную ошибку и на среднеабсолютную ошибку и пытаться понять, что из этого лучше. Или выбирать типы регуляризации: L2 или L1 — и тоже как-то сравнивать алгоритмы, обученные с разными видами регуляризации. Или сравнивать разные классы моделей, например, линейные модели и решающие деревья, которые будем изучать в следующем модуле. Всё это называется сравнением алгоритмов. Понятно, что для этого нужно использовать либо обучающую... либо отложенную выборку, либо кросс-валидацию, но при этом нужно соблюдать осторожность. Вот почему: давайте рассмотрим пример, в котором мы сравниваем тысячу разных типов алгоритмов с помощью отложенной выборки. Каждый их них мы обучаем на обучающей выборке, измеряем качество на отложенной выборке и дальше выбираем из них лучшие по качеству на отложенной выборке. При этом заметьте, что отложенная выборка, по сути, превратилась в обучающую. У нас было большое семейство алгоритмов, и мы из них выбрали лучшие отложенные выборки. По сути, мы подогнались под нее, и у нас снова появился риск переобучения под отложенную выборку. Чтобы бороться с этим, нужно немножко усовершенствовать нашу схему оценивания качества. Разобьем все данные на три части: на обучение, валидацию и контроль. Каждый из нашей тысячи алгоритмов будем обучать на обучающей выборке и измерять качество на валидационной выборке. Получим тысячу показателей качества и по ним выберем лучший из этой тысячи алгоритмов — тот, который допускает наименьшую ошибку. После того, как лучший алгоритм выбран, мы измерим его качество на контрольной выборке и проверим его на адекватность, то есть что оно устраивает нас. По сути, именно контрольная выборка будет играть роль новых данных. Например, можно проверять, что доля ошибки не слишком большая и отличается от одной второй, то есть от случайного угадывания, от подбрасывания монетки. Или что среднеквадратичная ошибка лучше, чем у константного алгоритма. Если же в вашей схеме предпочтительней использовать кросс-валидацию, нужно разбить выборку на две части. Одна — это контрольная, на которой будет измеряться качество итогового алгоритма, а другая — та, на которой будет делаться кросс-валидация. То есть по стандартной схеме разбивается на K блоков, каждый блок по очереди выступает в качестве контрольного, на нём измеряется качество, а алгоритмы обучены по всем остальным блокам. После того как по кросс-валидации выбран лучший из множества алгоритм, его адекватность измеряется на контрольной выборке. Итак, мы выяснили, что для выбора гиперпараметров или сравнения алгоритмов нужно использовать стандартные схемы: отложенную выборку или кросс-валидацию. Но при этом, если вы сравниваете очень много разных моделей, есть риск переобучения, и чтобы его избежать, нужно выделять контрольную выборку, на которой вы проверяете итоговый алгоритм на адекватность. На этом урок про сравнение моделей заканчивается, и вы узнали много нового. Например, как использовать регуляризацию, чтобы бороться с переобучением линейных моделей, или как строить схему проверки качества, которая позволит понять, насколько хорошо алгоритм будет работать на новых данных.

Проблема переобучения и борьба с
ней
3.1. Проблема переобучения
3.1.1. Пример: проблема переобучения в задачах классификации
Допустим при решении задачи классификации был построен некоторый алгоритм, например линейный классификатор, причем доля ошибок на объектах из обучающей выборки была равна 0.2, и такая доля ошибок
является допустимой.
Но поскольку алгоритм не обладает обобщающей способностью, нет никаких гарантий, что такая же
доля ошибок будет для новой выборки. Вполне может возникнуть ситуация, что для новой выборки ошибка
станет равной 0.9. Это значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из
нее закономерности и применить их для классификации новых объектов. При этом алгоритм как-то смог
подогнаться под обучающую выборку и показал хорошие результаты при обучении без извлечения истинной
закономерности. В этом и состоит проблема переобучения.
3.1.2. Пример: проблема переобучения в задачах линейной регрессии
Глубже понять проблему переобучения можно на данном примере. На следующем графике изображена истинная зависимость и объекты обучающей выборки:
0 1 2 3 4 5 6 7 8 9
4
2
0
2
4
Рис. 3.1: Истинная зависимость (зеленая линия) и элементы обучающей выборки (изображены синими точками).
Видно, что истинная зависимость является нелинейной и имеет два экстремума.
1
В модели a(x) = w0, после того, как она будет настроена под данные, на графике получается некоторая
горизотальная кривая, которая довольно плохо обобщает информацию об объектах из выборки.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.2: Модель a(x) = w0.
Имеет место недообучение. Хороший алгоритм не был построен, поскольку семейство алгоритмов слишком
мало и с его помощью невозможно уловить закономерность.
В линейной регрессии используется семейство алгоритмов a(x) = w0 + w1x.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.3: Модель a(x) = w0 + w1x.
В этом случае также будет иметь место недообучение. Получилось лучше, но прямая тоже плохо описывает
данные.
Если семейство алгоритмов — множество многочленов 4-ей степени:
a(x) = w0 + w1x + w2x
2 + ... + w4x
4
,
то после обучения получившаяся кривая будет достаточно хорошо описывать и обучающую выборку, и истинную зависимость.
2
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.4: Модель a(x) = w0 + w1x + w2x
2 + ... + w4x
4
.
В таком случае качество алгоритма хорошее, но нет идеального совпадения. Встает вопрос, а можно ли
добиться совпадения увеличением сложности алгоритма.
При использовании многочленов 9-ой степени уже имеет место переобучение.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.5: Модель a(x) = w0 + w1x + w2x
2 + ... + w9x
9
.
Восстановленная зависимость дает идеальные ответы на всех объектах обучающей выборки, но при этом в
любой другой точке сильно отличается от истинной зависимости. Такая ситуация называется переобучением.
Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие
ответы на новых точках.
3.1.3. Недообучение и переобучение
Таким образом, недообучение — ситуация, когда алгоритм плохо описывает и обучающую выборку, и новые
данные. В этом случае алгоритм необходимо усложнять.
В случае переобучения, данные из обучающей выборки будут описываться хорошо, а новые данные плохо.
Выявить переобучение, используя только обучающую выборку, невозможно, поскольку и хорошо обученный,
и переобученный алгоритмы будут хорошо ее описывать. Необходимо использовать дополнительные данные.
Существуют несколько подходов к выявлению переобучения:
• Отложенная выборка. Часть данных из обучающей выборки не участвуют в обучении, чтобы позже
проверять на ней обученный алгоритм.
• Кросс-валидация, несколько усложненный метод отложенной выборки. (Об этом способе речь пойдет
позже.)
3
• Использовать меры сложности модели. Об этом пойдет речь далее.
3.2. Регуляризация
В этом разделе речь пойдет о регуляризации — способе борьбы с переобучением в линейных моделях.
3.2.1. «Симптомы» переобучения. Мультиколлинеарность.
Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках.
Например, в предыдущем разделе при обучении модели
a(x) = w0 + w1x + w2x
2 + ... + w9x
9
веса оказывались огромными:
a(x) = 0.5 + 12458922x + 43983740x
2 + ... + 2740x
9
.
Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется
проблема, при которой признаки в выборке являются линейно зависимыми. Другими словами, существуют
коэффициенты α1, ..., αd такие, что для любого объекта xi из выборки выполняется:
α1x
1
i + ... + αdx
d
i = 0.
Более компактно последнее выражение можно переписать в виде:
hα, xii = 0.
Допустим, было найдено решение задачи оптимизации:
w∗ = argminw
1
`
X
`
i=1

hw, xii − yi
2
Другой вектор весов, полученный сдвигом в направлении вектора α:
w1 = w∗ + tα,
так как для элементов x выборки выполняется:
hw∗ + tα, xi = hw∗, xi + thα, xi = hw∗, xi,
также будет являться решением задачи оптимизации. Другими словами, он будет также хорошо описывать
данные в выборке, как и исходный алгоритм. Фактически, решениями задачи оптимизации являются бесконечное множество алгоритмов, но многие из них имеют большие веса, и далеко не все обладают хорошей
обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением.
3.2.2. Регуляризация
Выше было продемонстрировано, что если веса в линейной модели большие, существует высокий риск переобучения. Чтобы бороться с этим, минимизируется уже не выражение для функционала ошибки Q(a, X), а
новый функционал, получаемый прибавлением регуляризатора. Самый простой регуляризатор — квадратичный регуляризатор:
kwk
2 =
X
d
j=1
w
2
j
.
В этом случае имеет место следующая задача оптимизации:
Q(w, X) + λkwk
2 → min
w
.
Таким образом, при обучении будет учитываться также то, что не следует слишком сильно увеличивать веса
признаков.

3.2.3. Коэффициент регуляризации
Введенный выше коэффициент λ, который стоит перед регуляризатором, называется коэффициентом регуляризации. Чем больше λ, тем ниже сложность модели. Например, при очень больших его значениях оптимально
просто занулить все веса. В то же время при слишком низких значениях λ высок риск переобучения, то есть
модель становится слишком сложной.
Поэтому нужно найти некоторое оптимальное значение λ, достаточно большое, чтобы не допустить переобучения, и не очень большое, чтобы уловить закономерности в данных. Обычно λ подбирается на кроссвалидации, о которой пойдет речь в следующем разделе.
3.2.4. Смысл регуляризации
Чтобы понять смысл регуляризации, вместо задачи оптимизации с квадратичным оптимизатором нагляднее
рассмотреть задачу условной оптимизации:
(
Q(w, X) → min
w
kwk
2 ≤ C
Добавление регуляризатора вводит требование, чтобы решение задачи минимизации искалось в некоторой
круглой области с центром в нуле.
W1
W2
W∗
Рис. 3.6: Геометрический смысл условной регуляризации. Красная точка — настоящий оптимум функции,
красные линии — линии уровня функции, черная точка — оптимум функции при введенном ограничении.
Таким образом, решение задачи с регуляризатором не будет характеризоваться слишком большими значениями весовых коэффициентов.
3.2.5. Виды регуляризаторов
Рассмотренный выше квадратичный регуляризатор (L2-регуляризатор) является гладким и выпуклым, что
позволяет использовать градиентный спуск.
Также существует L1-регуляризатор:
kwk1 =
X
d
j=1
|wj |,
который представляет собой L1-норму вектора весов. Он уже не является гладким, а также обладает интересным свойством. Если применять такой регуляризатор, некоторые веса оказываются равными нулю. Другими
словами, такой регуляризатор производит отбор признаков и позволяет использовать в модели не все признаки, а только самые важные из них.
5
3.3. Оценка качества алгоритмов. Кросс-валидация
В этом разделе речь пойдет об оценке качества алгоритмов и о том, как понять, как поведет себя алгоритм
на новых данных.
3.3.1. Выявление переобучения
Уже было сказано, что переобучение сложно выявить, используя только обучающую выборку: и хороший, и
переобученный алгоритмы будут показывать хорошее качество на объектах обучающей выборки. Рассмотренные в предыдущем разделе меры переобученности (значения регуляризаторов), безусловно, можно применять,
но они не дают ответа на вопрос, насколько хорошо алгоритм поведет себя на новых данных, то есть какая
у него будет доля ошибок на новых данных.
3.3.2. Отложенная выборка
Самый простой способ оценить качество алгоритма — использование отложенной выборки. В этом случае
следует разбить выборку на две части: первая из двух частей будет использоваться для обучения алгоритма,
а вторая, тестовая выборка, — для оценки его качества, в том числе для нахождения доли ошибок в задаче
классификации, MSE (среднеквадратичной ошибки) в задаче регрессии и других мер качества в зависимости
от специфики задачи.
Естественный вопрос — о том, в какой пропорции производить разбиение. Если взять тестовую выборку
слишком маленькой, оценка качества будет ненадежной, хотя обучающая выборка будет почти совпадать
с полной выборкой. В противоположенном случае, если отложенная часть будет большой, оценка качества
будет надежной, но низкое качество алгоритма может свидетельствовать о недостаточном объёме первой,
обучающей, части выборки. Обычно выборку разбивают в соотношениях 70/30, 80/20 или 0.632/0.368.
Преимуществом отложенной выборки является то, что обучать алгоритм приходится всего лишь один раз,
но при этом результат сильно зависит от того, как было произведено разбиение.
Например, оценивается стоимость жилья по некоторым признакам. И есть особая категория жилья, например двухэтажные квартиры. И если окажется, что все двухэтажные квартиры, которых немного, попали
в отложенную выборку, то после обучения алгоритм будет давать на них очень плохое качество, поскольку в
обучающей выборке таких объектов не было.
Чтобы решить эту проблему, можно использовать следующий подход: построить n различных разбиений
выборки на 2 части, для каждого разбиения найти оценку качества, а в качестве итоговой оценки качества
работы алгоритма использовать усредненное по всем разбиениям значение. Но и в данном случае, поскольку
разбиения строятся случайно, нет никаких гарантий, что особый объект хотя бы раз попадет на обучение.
3.3.3. Кросс-валидация
Более системный подход — кросс валидация. В этом случае выборка делится на k блоков примерно одинакового размера. Далее по очереди каждый из этих блоков используется в качестве тестового, а все остальные
— в качестве обучающей выборки.
После того, как каждый блок побывает в качестве тестового, будут получены k показателей качества. В
результате усреднения получается оценка качества по кросс-валидации.
При этом встает вопрос, какое число блоков использовать. Если блоков мало, получаются надежные, но
смещенные оценки. В случае большого числа блоков оценки, наоборот, получаются ненадежными (большой
разброс оценок), но несмещенными.
Нет конкретных рекомендаций относительно выбора k. Обычно выбирают k = 3, 5, 10. Чем больше k,
тем больше раз приходится обучать алгоритм. Поэтому на больших выборках следует выбирать небольшие
значения k, так как даже при удалении 1/3 выборки (а она большая) оставшихся данных будет достаточно
для обучения.
3.3.4. Совет: перемешивайте данные в выборке
Часто данные в файле записаны в отсортированном виде по какого-нибудь признаку. Поэтому всегда следует
перемешивать выборку прежде, чем производить кросс-валидацию. В ином случае алгоритм будет показывать
плохое качество и причина этого будет не так очевидна.
6
При этом есть задачи, в которых выборку нельзя перемешивать. Это задачи предсказания будущего,
например предсказание погоды на следующий день. В этом случае нужно особо следить за тем, как происходит
деление выборки.
3.4. Выбор гиперпараметров и сравнение алгоритмов
В этом разделе речь пойдет о выборе гиперпараметров и сравнении различных алгоритмов с помощью изученных ранее схем.
3.4.1. Гиперпараметры
Гиперпараметрами называются такие параметры алгоритмов, которые не могут быть получены из обучающей
выборки при обучении, поэтому их надо подбирать путем многократного обучения алгоритма. Примерами
гиперпараметров являются:
• Параметр регуляризации λ (при использовании регуляризатора)
• Степень полинома в задаче регрессии с семейством алгоритмов, заданным множеством полиномов определенной степени.
3.4.2. Сравнение разных алгоритмов
Более общая задача — сравнение разных алгоритмов:
• обученных с разными значениями гиперпараметров;
• использующих различный способ регуляризации;
• настроенных с использованием разного функционала ошибки, например среднеквадратичной ошибки и
средней абсолютной ошибки;
• которые принадлежат разным классам алгоритмов.
При сравнении алгоритмов можно использовать как отложенную выборку, так и кросс-валидацию, но при
этом следует соблюдать осторожность.
Действительно, пусть 1000 алгоритмов сравниваются по качеству на отложенной выборке. Каждый из
1000 алгоритмов, обученных на обучающей выборке, тестируется на отложенной, и в результате выбирается
лучший. Фактически на этом шаге отложенная выборка также становится своего рода обучающей, и возникает
проблема переобучения: из большого числа алгоритмов выбирается тот, который лучше всего ведет себя на
отложенной выборке, лучше подогнан под нее.
3.4.3. Улучшенная схема сравнения алгоритмов
Чтобы бороться с этим, следует использовать несколько усовершенствованную схему оценивания качества
алгоритмов, а именно все данные нужно будет делить на 3 части (в случае использования отложенной выборки): обучение, валидация и контроль. Каждый из тысячи алгоритмов будет обучен на обучающей выборке, а
его качество будет измерено на валидационной. Алгоритм с наилучшим качеством будет проверен на тестовой
выборке, чтобы исключить переобучение и проверить алгоритм на адекватность. По сути именно тестовая
выборка будет играть роль новых данных.
Если предпочтительно использовать кросс-валидацию, то данные следует разбить на 2 части. Первая из
них будет использоваться для обучения алгоритмов и оценки качества с помощью кросс-валидации, после
чего лучший алгоритм будет проверен на адекватность на контрольной выборке.
Метрики качества

Мы начинаем урок, посвященный метрикам качества. В нем мы поговорим о том, как измерять качество алгоритмов в классификации регрессии и какие аспекты качества могут возникнуть в тех или иных задачах. И давайте сначала обсудим, где могут использоваться метрики качества в машинном обучении. Первое применение — это функционалы ошибки, которую мы оптимизируем при обучении алгоритма на обучающей выборке. С этим мы уже много раз сталкивались. Мы использовали, например, среднеквадратичную ошибку, или долю неправильных ответов, или говорили про логистическую функцию — понятие и классификация. Также вы можете обучать алгоритм, используя один функционал, одну метрику качества, а вот проверять его качество на отложенной выборке или на кросс-валидации с помощью другой метрики, например, если вы знаете, что в вашей задаче много выбросов, то нужно использовать какую-то метрику, которая слабо штрафует за ошибки на таких выбросах. Далее, когда вы выбрали параметры и гиперпараметры алгоритма, и у вас есть финальная модель, которую вы собираетесь использовать, то вы можете захотеть измерить еще какую-то, третью метрику качества, которая отражает ценность, например, для бизнеса вашей модели. Скажем, если вы решаете задачу медицинской диагностики, то есть строите модель, которая будет определять: болен или нет пациент тем или иным заболеванием, то вы можете интересоваться: какую долю всех больных пациентов ваша модель сможет обнаружить, сможет понять, что у них есть проблема. Дайте поговорим о том, какие метрики качества бывают в регрессии. Наше видео именно об этом. И первая метрика, о которой мы поговорим, с которой мы уже много раз сталкивались — это среднеквадратичная ошибка, она вычисляется очень просто: мы вычисляем отклонения, прогнозы нашего алгоритма от истинного ответа на каждом объекте выборки, возводим в квадрат это отклонение и усредняем по всем объектам обучающей или какой-то другой выборки. Преимущество этого функционала в том, что его легко оптимизировать. Если мы используем линейную модель, то у него даже есть аналитическое решение, у этой задачи оптимизации. Но при этом есть и проблема: данный функционал возводит отклонение в квадрат. Таким образом, если отклонение сильное, если этот объект — выброс и ответ на нем не очень логичный, то штраф за отклонение, соответственно, на этом объекте будет очень сильный. Таким образом алгоритм может настроиться на выборосы, может дать хороший ответ на тех объектах, на который не имеет смысла настраиваться. Похожий функционал качества — это средняя абсолютная ошибка. В ней мы вычисляем модуль отклонения прогноза от истинного ответа и усредняем это по всем объектам обучающей выборки. Этот функционал немного сложнее. Его тяжелее оптимизировать из-за того, что у модуля производная есть не везде, в нуле она отсутствует. Но при этом здесь считается модуль отклонения, а не квадрат, и поэтому штраф за сильное отклонение гораздо меньше. Это функционал гораздо более устойчив к выбросам. У среднеквадратичной ошибки есть одна модификация — коэффициент детерминации, которая позволяет интерпретировать свое значение. Давайте сначала обсудим, как он задается. Основная часть коэффициента детерминации, или коэффициента R квадрат, — это дробь, у которой в числителе стоит сумма квадратов отклонений прогнозов алгоритма от истинных ответов, то есть практически среднеквадратичная ошибка, только без усреднения, просто сумма. В знаменателе стоит сумма квадратов отклонений истинных ответов от среднего истинного ответа, вычисленного по всем... по всей обучающей выборке. При этом средний истинный ответ мы обозначаем как y с верхней чертой. После того как эта дробь посчитана, мы вычитаем ее из 1. И получаем коэффициент детерминации. У этого коэффициента есть одна интересная интерпретация: он показывает, какую долю дисперсии во всем целевом векторе y наша модель смогла объяснить. Иными словами, какую долю разнообразия ответов наша модель смогла объяснить или предсказать. Как я уже говорил, коэффициент детерминации можно интерпретировать. Давайте разберемся, как именно. Оказывается, что для разумных моделей — что такое разумная модель, скажем чуть позже — коэффициент детерминации находится между 0 и 1, в отрезке от 0 до 1. При этом, если он равен 1, то это идеальная модель, которая идеально угадывает ответы на обучающей выборке. Если коэффициент детерминации равен 0, это означает, что его качество совпадает с оптимальным константным алгоритмом. Оптимальный константный алгоритм — это тот, который на всех объектах возвращает средний ответ по всей обучающей выборке, то есть y с верхней чертой, который мы вводили на прошлом слайде. Если коэффициент детерминации находится между 0 и 1, то можно говорить о том, насколько он лучше, чем константная модель, и насколько он хуже, чем идеальная модель. Например, если он равен 0,2, то, скорей всего, он не очень хороший, ближе к константной модели. Если же коэффициент детерминации алгоритма равен 0,9, скорей всего, это хороший алгоритм, который близок к оптимальному. Коэффициент детерминации может быть меньше 0, если алгоритм работает хуже, чем константный, это те алгоритмы, которые никогда не нужно рассматривать. Пока что мы говорили о метриках качества, которые симметричные, которые одинаково штрафуют как за недопрогноз, так и за перепрогноз, то есть как за завышение, так и за занижение прогноза. При этом бывают задачи, где эти ошибки имеют разную цену. Давайте разберем простой пример: представим, что мы торгуем ноутбуками одной и той же марки. И хотим предсказывать, каков будет спрос на эти ноутбуки в следующем месяце. Если наш прогноз будет занижен, то есть мы предскажем спрос ниже, чем он будет на самом деле, это очень плохо. Во-первых, мы потеряем лояльность клиентов, они будут приходить к нам за покупками, но мы не сможем продать им этот ноутбук, потому что у нас они закончились, клиенты, скорее всего, разочаруются в нас. Также мы теряем потенциальную прибыль — мы могли бы заработать, продав эти ноутбуки, но нам нечего было продать. Поэтому недопрогноз, заниженная прогнозная задача — это плохо. Если же будет иметь место перепрогноз, завышенный прогноз, то мы удовлетворим всех клиентов, но при этом у нас будут остатки ноутбуков, у нас останется несколько ноутбуков непроданными. Это не очень плохо. Да, мы потратим деньги на хранение, но ноутбуки — это довольно компактные вещи, поэтому они не займут много места. Итак, в этой задаче функция потери должна быть несимметричной, мы должны сильнее штрафовать за недопрогноз, чем за перепрогноз. В этом случае хорошо подходит квантильная ошибка, квантильная функция потерь. Давайте разберемся, как она задается. Она представляет собой сумму по всем объектам обучающей выборки вот таких сложных выражений. Давайте поймем, что они означают. Здесь стоит отклонение прогноза алгоритма от истинного ответа: yi-тое − a(xi-того), и это отклонение домножается либо на число τ (тау), если имеет место недопрогноз, то есть если прогноз меньше истинного ответа, либо на число τ − 1, если имеет место перепрогноз, то есть ответ алгоритма, прогноз, больше истинного ответа. τ — это некоторый параметр данного функционала, который варьируется от 0 до 1. Если нарисовать зависимость ошибки, посчитанной данным образом, от отклонения yi-тое − a(xi-тое), то получим вот такую картину. Видно, что эта функция потерь действительно несимметричная. При этом если τ большое, если τ близко к 1, то мы сильнее боимся недопрогноза, мы сильнее боимся занизить прогноз, если τ близко к 0, мы боимся перепрогноза. Чтобы разобраться, почему эта функция потерь называется квантильной, давайте поговорим про вероятностный смысл, вероятностную интерпретацию этих функционалов. Представьте следующую ситуацию: в нашей выборке один и тот же объект x с одним и тем же признаковым описанием повторяется n раз. Это... такая ситуация вполне может возникнуть в ряде задач. При этом ответы на этих n повторах разные, они немного отличаются друг от друга, обозначим их через y1, ..., yn. Такое может возникнуть, например, при измерении роста человека. Человек один и тот же, но при этом результат конкретного измерения зависит от показателей, от шума прибора, которым мы измеряем рост, и от самого человека, он может выпрямиться или сгорбиться, например, и из-за этого рост получится немножко другим, чем в прошлый раз. Объект один и тот же, а ответы немного разные. При этом обратите внимание: наш алгоритм должен на одном и том же объекте возвращать один и тот же прогноз. Таким образом возникает вопрос: какой ответ алгоритма на объекте x оптимален для данной выборки y1, ..., yn с точки зрения того или иного функционала ошибки. Давайте разберемся! Оказывается, если мы используем среднеквадратичную ошибку, то оптимальным прогнозом будет просто средний ответ на этом объекте, то есть среднее по y1, ..., yn. Если мы используем среднюю абсолютную ошибку, то оптимальным прогнозом будет медиана, то есть мы считаем медиану по нашей выборке. Известно, что медиана более устойчива к выборосам, чем среднее. Если же мы используем квантильную регрессию с параметром τ, то оказывается, что оптимальным прогнозом будет τ-квантиль. Это очень логично. Если τ — большое, мы боимся недопрогноза и будем брать большую квантиль, будем завышать прогноз, будем брать его выше, чем среднее значение y-ков. Если же τ — маленькое, и мы боимся перепрогноза, то мы будем брать маленькую квантиль, специально занижать прогноз, делать его ниже, чем среднее. Итак, мы поговорили о том, какие метрики качества бывают в задачах регрессии. Поговорили про среднеквадратичную среднюю абсолютную ошибку и про коэффициент детерминации, который является интерпретируемой версией среднеквадратичной ошибки. Также мы обсудили квантильную функцию потерь, которая является несимметричной и может оказаться важной в ряде задач. А в следующем видео мы поговорим о том, как измерять качество в задачах классификации.

 В этом видео мы начнем разговор о том, как можно измерять качество в задачах классификации. И, на самом деле, мы уже знаем некоторый ответ на этот вопрос. Мы использовали долю неправильных ответов, чтобы обучать линейные классификаторы. Она считается очень просто. Мы для каждого объекта выборки выясняем, дает ли алгоритм правильный ответ или нет, и если дает неправильный ответ, то записываем единичку, если правильный — то нолик, и усредняем эти нолики и единички по всем объектам выборки. Так вышло, что в задачах классификации метрики принято выбирать так, чтобы их нужно было максимизировать, тогда как в регрессии метрики были такие, что мы их минимизировали, например среднюю квадратичную ошибку или квантильные потери. Чтобы максимизировать долю неправильных ответов, нужно ее немножко модифицировать и превратить в долю правильных ответов, или accuracy на английском. Она вычисляется точно так же: мы усредняем по всем объектам выборки индикаторы того, что на данном объекте алгоритм выдает правильный ответ. Это очень простая метрика качества, которая широко используется, но при этом у нее есть две проблемы. Давайте поговорим о них подробнее. Проблема первая связана с несбалансированными выборками. Давайте рассмотрим простой пример. Пусть в выборке 1000 объектов, из них 950 относится к классу −1, и 50 — к классу +1. И при этом рассмотрим константный алгоритм a(x), который на всех объектах, абсолютно всех объектах возвращает ответ −1. Этот алгоритм бесполезен, не имеет смысла его использовать ни в каких задачах. Он не восстанавливает никакие закономерности в данных. При этом его доля верных ответов на данной выборке будет равна 0,95 или 95 %. Это очень много, но не соответствует нашим ожиданиям. Понятно, что проблема именно в несбалансированности. В том, что одного из классов сильно больше, чем другого. Чтобы бороться с этой проблемой, имеет смысл измерять долю объектов самого крупного класса в данной выборке. Обозначим это через q₀. В нашем случае самый крупный класс — это −1, и доля объектов этого класса равняется как раз 95 %. Это означает, что доля правильных ответов для разумных классификаторов будет лежать в интервале от q₀ до 1, от 0,95 до 1, а не от 1/2 до 1, как мы могли бы ожидать в случае с бинарной классификацией. Еще раз совет на случай, если вы настроили некоторый классификатор и получили большую долю верных ответов — посмотрите на баланс классов. Возможно, дело не в том, что вы построили хороший классификатор, а в том, что просто одного из классов сильно больше, чем другого, и из-за этого легко получить высокую долю верных ответов. Вторая проблема, которая имеется в доле верных ответов — это то, что она никак не учитывает разные цены разных типов ошибок, тогда как цены действительно могут быть разными. Давайте разберем простой пример. Рассмотрим задачу кредитного скоринга, в которой нужно для клиента банка, который просит кредит, понять, выдавать ему кредит или не выдавать, вернет он этот кредит или не вернет. И представим, что у нас есть две модели. Первая модель говорит, что нужно выдать кредит ста клиентам. При этом если мы их выдадим, то из них 80 вернут деньги, а 20 не вернут. Вторая модель более консервативная. Она говорит, что нужно выдать кредит всего 50 клиентам, и если мы это сделаем, то из них 48 вернут кредит и всего 2 не вернут. Непонятно, какая из этих моделей лучше. Вторая модель более консервативная. Если мы воспользуемся ей, то практически все клиенты вернут кредиты, но при этом многим мы кредиты не дадим, хотя они вернули бы деньги. Мы не заработаем. Первая модель рискует сильнее, она выдает кредиты большему количеству человек, мы заработаем больше, но при этом и будут некоторые потери, связанные с тем, что 20 клиентов кредит не вернут. И в зависимости от того, каковы потери от невозврата кредита, можно отдать предпочтение либо одной модели, либо другой. Таким образом, нужны какие-то дополнительные метрики качества, которые позволяют учесть цену той или иной ошибки. Об этом будем говорить в следующем видео. Итак, мы поговорили про основную метрику качества классификации, долю верных ответов, и обсудили, что у нее есть две проблемы. Первая связана с неадекватными значениями в случае с несбалансированными выборками, а вторая — с тем, что данная метрика качества не умеет учитывать цены ошибок. А в следующем видео мы поговорим о том, как можно учитывать разные цены ошибок при разных типах ошибок классификации.

В этом видео мы поговорим о точности и полноте, метриках качества классификации, которые позволяют учитывать разные цены ошибок. В прошлом видео мы выяснили, что цены ошибок действительно могут быть разные. Например, в случае с кредитным скорингом непонятно, что лучше: выдать кредит плохому клиенту, который не вернёт кредит, или не выдать кредит хорошему клиенту, который мог бы вернуть этот кредит. То, какая ошибка лучше или хуже, какая важнее, какая нет, зависит от конкретной стратегии банка. Цена этой ошибки может варьироваться. Доля верных ответов неспособна учитывать цены разных ошибок. Чтобы рассуждать о том, у какой ошибки какая цены, удобно ввести матрицу ошибок, которая производит некоторую классификацию типов ошибок. Она состоит из двух строк и двух столбцов. Строка зависит от того, какой ответ выдаёт наш алгоритм, наша модель. Первая строка соответствует объектам, которых наша модель относит к классу +1. Вторая строка соответствует объектам, которых наша модель относит к классу -1. Столбец зависит от того, к какому классу на самом деле относится объект. Если объект относится к классу 1, он попадает в первый столбец. Если объект относится к классу -1, он попадает во второй столбец. Когда алгоритм относит объект к классу +1, будем говорить, что алгоритм срабатывает, он делает срабатывание. Итак, если алгоритм сработал, отнёс объект к классу +1, и объект действительно относился к классу +1, это верное срабатывание или True Positive. Если алгоритм сработал, но объект не относился к первому классу, на самом деле он из класса -1, то это ложное срабатывание или False Positive. Если алгоритм выдаёт ответ -1, будем говорить, что он пропускает объект. Итак, если имеет место пропуск, но при этом объект относится к классу 1, то это ложный пропуск или False Negative. Если же алгоритм пропускает объект, и, действительно, этот объект относится к классу -1, то это верный пропуск или True Negative. Таким образом, у нас есть два вида ошибок: ложные срабатывания и ложные пропуски. И для каждой из них нужна своя метрика качества, чтобы как-то измерить, какое количество таких ошибок мы допускаем. Давайте будем разбирать наши метрики на двух примерах, на примере двух моделей. Будем считать, что у нас выборка состоит из двухсот объектов, из которых сто относится к классу 1, и сто относится к классу -1, при этом первая модель относит к классу 1 сто объектов, из которых 80 — это верное срабатывание и 20 — это ложное срабатывание. Вторая модель срабатывает на пятидесяти объектах. Из них 48 — это верное срабатывание, а 2 — это ложное срабатывание. Первая метрика, о которой мы поговорим — это точность или precision. Она показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. В случае, если он относит объект к первому классу. Формально точно задаётся как отношение числа верных срабатываний к общему числу срабатываний, то есть число верных срабатываний плюс число ложных срабатываний. True Positive плюс False Positive. Давайте посчитаем точность в нашем примере. В случае с первой моделью, она срабатывает на ста объектах, и из них 80 действительно относятся к первом классу. Значит, нам нужно 80 поделить на сто. Получаем 0.8. Точность первого алгоритма = 0.8 или 80 процентам. Вторая модель срабатывает на пятидесяти объектах, и из них 48 — это верные срабатывания. Её точность равняется 48 поделить на 50 или 0.96. Её точность гораздо выше, она равняется 96 %. Если вторая модель срабатывает, то мы можем быть с большой долей вероятности уверены, что это срабатывание верное. Вторая метрика — это полнота или recall. Она показывает, как много истинных объектов первого класса алгоритм выделяет, на скольки из них он срабатывает. Формально она задаётся как отношение числа верных срабатываний к общему числу объектов первого класса выборки, то есть число верных срабатываний плюс число ложных пропусков. Посчитаем полноту для наших двух моделей. К первому классу относится сто объектов. И первая модель срабатывает на 80 из них, значит её полнота равна 0.8 или 80 %. Вторая модель срабатывает лишь на 48 положительных объектах. Таким образом, её полнота равняется 48 поделить на сто или 0.48. Вторая модель очень точная, но из-за этого страдает её полнота, она выделяет далеко не все объекты первого класса. Давайте разберём два примера того, как можно пользоваться точностью и полнотой в совокупности. Первый пример про кредитный скоринг. Представьте, что руководство банка решило, что, если среди всех выданных кредитов не более 5 % будут ошибочными, то есть лишь 5 % из них не вернут, то такая схема не будет убыточной. Эти невозвращённые кредиты не дадут нам слишком много убытков. Таким образом, мы получаем ограничение на точность в 0.95. Точность должна быть ≥, чем 0.95. И при таком ограничении мы будем максимизировать полноту, то есть стараться выдать кредиты как можно большему количеству хороших заёмщиков. Второй пример про медицинскую диагностику. Представьте, что мы сделали модель, хотим сделать модель, которая определяет: есть или нет то или иное заболевание у пациента. При этом наш заказчик требует, чтобы среди всех протестированных пациентов мы выделили как минимум 80 % тех, которые действительно имеют это заболевание. Таким образом, мы получаем ограничение, что полнота должна быть не меньше, чем 80 %. И при этом ограничении мы будет максимизировать точность, то есть пытаться сделать как можно меньше число ложных срабатываний. Наконец, обратите внимание, как точность и полнота работают на несбалансированных выборках. Представьте, что у нас есть выборка, в которой сто объектов первого класса и более десяти тысяч объектов отрицательного класса, -1 класса. При этом у нас 10 верных срабатываний, 20 ложных срабатываний и 90 ложных пропусков. Доля верных ответов на данной выборке равняется 99 %. Скорее всего, это число ни о чём не говорит. Чтобы понять, что плохого с данным алгоритмом, нужно померить точность и полноту. Давайте измерим точность. Всего алгоритм срабатывает на тридцати объектах, и из них лишь 10 — это верные срабатывания, значит точность равна 33 %. Видно, что алгоритм делает слишком много ложных срабатываний — 66 %. Далее полнота. Всего в выборке сто объектов первого класса, из их них лишь на 10 алгоритм срабатывает. Таким образом, полнота равняется 10 %. Видно, что у него также много ложных пропусков. Он пропускает 90 % объектов первого класса. Благодаря точности и полноте мы можем видеть, что не так с этим алгоритмом и что можно пытаться улучшить. Итак, мы с вами ввели матрицу ошибок и на её основе определили две метрики качества: точность и полноту. Точность измеряет, как много у нас ложных срабатываний, а полнота — как много ложных пропусков. И можно отдавать предпочтение одной или другой в зависимости от специфики задачи. Также мы выяснили, что точность и полнота могут быть очень полезными в случаях со сбалансированными выборками. В следующем видео мы поговорим о том, как можно объединить точность и полноту в одну метрику качества.

 В этом видео мы поговорим о том, как объединить точность и полноту в одну метрику качества классификации. В прошлый раз мы выяснили, что точность показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. То есть в случае, если он относит объект к первому классу. Полнота же измеряет, как много объектов первого класса наш классификатор выделил, на скольки из них он сработал. При этом есть задачи, где имеет место ограничение на одну из этих метрик, например, точность должна быть не меньше 95 %. И при этом мы будем оптимизировать другую метрику, например, полноту. Но при этом, точность и полнота хороши сами по себе, например, тем, что они более выразительны на несбалансированных выборках. И у нас может просто возникнуть желание максимизировать и точность, и полноту одновременно, но, при этом максимизировать две метрики, это не очень удобно. Лучше сначала объединить их в одну. Давайте выясним, как это правильно сделать. Первый подход, который мы обсудим, это арифметическое среднее. Просто сложим точность и полноту и поделим на 2. Чтобы визуализировать данный подход к их усреднению, мы будем рисовать линии уровня. По оси x мы будем откладывать точность, по оси y — полноту, и рисовать линии уровня, то есть линии, на которых арифметическое среднее принимает одно и то же значение. Давайте разберём простой пример. Представьте, что у нас есть алгоритм, у которого точность равна 10 %, а полнота — 100 %. На самом деле, это может быть выборка, в которой всего 10 % положительных объектов и алгоритм, который абсолютно на всех объектах выдаёт ответ +1, константный алгоритм. Понятно, что он бесполезен. Среднее арифметическое точности и полноты в этом случае = 55 %. А вот другой алгоритм. У него точность и полнота = 55 %. Этот алгоритм гораздо лучше предыдущего, но при этом среднее арифметическое снова = 55 %. Эти два алгоритма лежат на одной линии уровня. Это очень плохо. Константный и разумный алгоритмы получают один и тот же показатель. Чтобы устранить эту проблему, приходит в голову следующая идея. Раз мы хотим одновременно максимизировать и точность, и полноту, давайте максимизировать минимум из них. В этом случае линии уровня будут выглядеть как-то так. Видно, что они сильнее концентрируются в правом верхнем углу, то есть там, где находится алгоритм с точностью и полнотой, = 1. Данный подход с взятием минимума из точности и полноты решает проблему, которую мы обсуждали чуть раньше. Если взять алгоритм с точностью 5 % и полнотой 100 %, то минимум будет = 5 %. При этом есть другой нюанс. Рассмотрим два алгоритма, оба из которых имеют точность 40 %, но при этом полнота первого = 50 %, а полнота второго = 90 %. Понятно, что второй алгоритм лучше. При такой же точности он даёт более высокую полноту, но при этом и минимум и там, и там = 40 %. Они снова лежат на одной линии уровня, хотя этого не должно быть. Чтобы устранить проблему, давайте попробуем сгладить минимум. Это можно сделать с помощью гармонического среднего или F-меры. Чтобы её посчитать, нужно вычислить дробь, в числителе которой стоит произведение точности и полноты, умноженное на 2, а в знаменателе сумма точности и полноты. Если мы рассматриваем два алгоритма, оба из которых имеют точность 40 %, и при этом первый имеет полноту 50 %, а второй — 90 %, то у первого F-мера = 44 %, а у второго — 55 %. Второй оказывается на линии уровня, которая ближе к правому верхнему углу, ближе к идеальному классификатору. При этом, если вы хотите отдать предпочтение либо точности, либо полноте, можно воспользоваться расширенной версией F-меры, который имеет параметр β. Она вычисляется по такой страшной формуле. При этом, если вы возьмёте β = 0.5, то важнее окажется полнота. Дело в том, что если вы зафиксируете полноту и будете менять точность, то данная F-мера будет меняться довольно гладко. Если же вы зафиксируете точность и будете менять полноту, изменения будут очень резкие. Таким образом, полнота важнее в этом случае. Если же взять β = 2, то ситуация поменяется. Важнее окажется точность. Поскольку при фиксированной полноте изменение точности будет гораздо сильнее приводить к перемене F-меры. Итак, мы обсудили, что лучший способ объединения точности и полноты в одну метрику, это F-мера, которая представляет собой сглаженную версию минимума из точности и полноты. При этом, если вы хотите отдать предпочтение либо точности, либо полноте при усреднении, можно воспользоваться параметром β в F-мере. В следующем видео мы поговорим о том, как измерять качество оценок принадлежности тому или иному классу.

 В этом видео мы поговорим о том, как измерять качество оценок принадлежности к классу. И давайте начнем с того, что разберемся, что это за оценки принадлежности. Дело в том, что многие алгоритмы классификации устроены следующим образом: на самом деле, сначала вычисляется некоторое вещественное число b(x), и далее оно сравнивается с некоторым порогом t. Если оно больше порога, то относим объект к положительному классу, если меньше порога — то к отрицательному классу. Таким образом, b(x) выступает как некоторая оценка уверенности классификатора в том, что объект относится к единичному классу — классу +1. Примером может служить линейный классификатор. В нем мы вычисляем скалярное произведение вектора весов на вектор признаков и дальше сравниваем его, например, с нулем. Если оно больше нуля, то относим объект к одному классу, если меньше нуля — то к другому классу. Здесь в качестве оценки принадлежности выступает скалярное произведение. И, действительно, мы обсуждали, что если есть два объекта, у обоих скалярное произведение больше нуля, но при этом на первом оно больше, чем на втором, это означает, что в принадлежности первого к этому классу алгоритм уверен больше. Итак, зачастую нужно измерить качество именно оценки принадлежности b(x), потому что порог будет выбран заказчиком позже. Например, мы оцениваем вероятность возврата кредита всеми клиентами банка, и дальше банк уже будет выбирать порог, в зависимости от своего желания рискнуть или, наоборот, желания делать консервативную выдачу кредитов. Вот еще одна причина, по которой может понадобиться измерять качество именно оценки принадлежности. Представьте, что мы занимаемся кредитным скорингом и построили некоторую функцию b(x), которая оценивает вероятность того, что клиент x вернет кредит. Далее мы построили классификатор следующим образом: взяли данную вероятность, и если она больше 1 / 2, то будем выдавать клиенту кредит, если меньше 1 / 2, то не будем выдавать ему кредит. И при этом получилось, что точность = 10 %, полнота = 70 %. Это очень плохой алгоритм. Точность в 10 % означает, что 90 % клиентов, которым мы выдадим кредит, не вернут его. Банк такое явно не примет. При этом не понятно, в чем дело: в том, что мы плохо выбрали порог, и нужно было взять его, например, не 1 / 2, а, скажем, 9 / 10, или же в том, что сама оценка b(x) — плохая, и как бы мы ни старались с порогом, невозможно с ее помощью построить классификатор, который будет давать высокую точность. Именно для этого и нужно измерять качество самих оценок b(x). Мы разберем два способа, и первый из них основан на кривой точности-полноты. По оси y будем откладывать... по оси x будем откладывать полноту, по оси y — точность. И точка в этих осях будет соответствовать конкретному классификатору, то есть выбору конкретного порога, по которому мы отсекаем оценку принадлежности b(x). Давайте на примере разберем, как строится кривая точности и полноты. Пусть у нас есть выборка, в которой шесть объектов, из них три относятся к классу 1, три — к классу 0. И они имеют вот такие оценки принадлежности к классу 1. Сначала возьмем порог, при котором ни один объект не будет отнесен к классу 1. В этом случае и точность, и полнота, будем считать, что они равны нулю. Ставим точку (0, 0). Далее чуть-чуть уменьшаем порог так, чтобы ровно один объект с максимальной оценкой был отнесен к классу 1. В этом случае точность будет равна 100 %, полнота будет равна 1 / 3, поскольку мы выделяем один из трех положительных объектов. Ставим следующую точку. При дальнейшем уменьшении порога мы два объекта отнесем к первому классу, и оба будут верными срабатываниями — точность все еще равна 100 %, полнота увеличивается до 2 / 3. Далее, когда мы три объекта отнесем к первому классу, то точность уменьшится, поскольку третий относится к негативному классу, на самом деле, — точность станет равна 2 / 3, — полнота останется такой же. Уменьшаем порог еще сильнее — точность уменьшается, полнота остается такой же. Когда мы отнесем пять объектов к первому классу, точность окажется равной 3 / 5, а полнота будет 100 %, поскольку мы уже выделили все объекты первого класса. Наконец, когда мы все объекты отнесем к классу... классу 1, то получим, что точность равняется 1 / 2, полнота равняется 100 %. Получается вот такая кривая. В реальных задачах, где объектов тысячи и десятки тысяч, кривая точности-полноты выглядит как-то так. Заметим, что стартует она всегда из точки (0, 0). Финальная точка этой кривой находится по координатам 1 и r, полнота равняется 100 %, а точность равняется доли объектов первого класса во всей выборке, которую мы обозначаем как r. Если у нас имеется идеальный классификатор, то и существует такой порог, при котором и точность, и полнота — 100%, то кривая пройдет через точку (1, 1). Чем ближе к этой точке она пройдет, тем лучше наши оценки. Таким образом, площадь под этой кривой может быть хорошей мерой качества оценок принадлежности к классу 1. Введем эту метрику. Будем называть ее AUC — PRC, или площадь под precision-recall-кривой. Второй способ измерить качество — это ROC-кривая, она строится немножко в других осях. По оси x откладывается доля ложных срабатываний, или False Positive Rate. Она считается как отношение числа ложных срабатываний к общему размеру отрицательного класса, то есть False Positives + True Negatives. По оси y будем откладывать долю верных срабатываний, или True Positive Rate. В числителе стоит количество верных срабатываний, в знаменателе — размер первого класса, то есть True Positive + False Negative. Разберем на том же примере, как строится ROC-кривая. Сначала выбираем порог, при котором ни один объект не относится к первому классу. Получаем точку (0, 0) — число... доля верных срабатываний, доля ложных срабатываний равны 0. Далее, когда мы один объект отнесем к классу 1, доля верных срабатываний увеличится на 1 / 3, доля ложных срабатываний останется нулевой. При дальнейшем уменьшении порога доля верных срабатываний увеличится до 2 / 3, доля ложных срабатываний — все еще 0. Отнесем три объекта к классу 1. В этом случае доля верных срабатываний все еще равна 2 / 3, доля ложных срабатываний — 1 / 3. Уменьшаем еще сильнее — доля верных срабатываний остается такой же, доля ложных срабатываний увеличивается до 2 / 3. Далее, доля верных срабатываний увеличивается до 1, доля ложных срабатываний останется 2 / 3. И, наконец, когда все объекты отнесем к классу 1, доля и верных, и ложных срабатываний будет равна 1. В случае с большой выборкой ROC-кривая выглядит как-то так. Она стартует из точки (0, 0) и приходит в точку (1, 1), при этом если есть идеальный классификатор, то его доля верных ответов будет равна 1, доля ложных срабатываний будет равна 0, то есть кривая пройдет через точку (0, 1). Опять же, чем ближе кривая к этой точке, тем лучше наши оценки, и площадь по этой кривой будет характеризовать качество оценок принадлежности к первому классу. Эта метрика называется AUC — ROC, или площадь под ROC-кривой. Давайте разберемся, в чем особенности площади под ROC-кривой и площади под кривой точности-полноты. Начнем с ROC-кривой. Вспомним, что она измеряет долю верных срабатываний и долю ложных срабатываний. При этом доля ложных срабатываний делится на размер негативного класса, доля верных срабатываний делится на размер положительного класса. За счет того, что эти величины делятся на объемы классов, площадь под ROC-кривой не зависит от баланса классов. Если свойства объектов выборки останутся такими же, но лишь изменится соотношение классов, площадь под ROC-кривой не изменится. Площадь под ROC-кривой для идеального алгоритма равна 1, площадь под ROC-кривой для худшего алгоритма, то есть того, который выдает случайные ответы, находится в районе 1 / 2. При этом у площади под ROC-кривой есть много интересных интерпретаций, которые помогают объяснять ее другим людям. Например, она равняется вероятности того, что если вы выберете случайный положительный и случайный отрицательный объект из выборки, то положительный объект получит оценку принадлежности выше, чем отрицательный объект. Перейдем теперь к площади под precision-recall-кривой, она зависит от точности и полноты. При этом в точности нормировка производится не на размер положительного класса, а на число срабатываний алгоритма. Таким образом, если соотношение классов изменится, то изменится и точность, значит и площадь под precision-recall-кривой зависит от соотношения классов. При этом площадь под precision-recall-кривой проще интерпретировать, если выборка сильно несбалансированная. Давайте разберем это на примере. Представьте, что мы построили такие оценки принадлежности, что максимальные оценки — у 50 тысяч объектов отрицательного класса. Далее идут 100 объектов положительного класса. И далее — 950 тысяч объектов отрицательного класса. У нас очень большой отрицательный класс — миллион объектов, и маленький положительный — 100 объектов. И при этом, при такой сортировке, при таком упорядочивании, 100 объектов положительного класса оказались довольно далеко от верха — сначала идет 50 тысяч отрицательных объектов. Понятно, что такая сортировка нас не устраивает — положительные объекты находятся слишком далеко. При этом площадь под ROC-кривой равняется 95 %, площадь под precision-recall-кривой — 0,1 %. Почему-то площадь под ROC-кривой получилась большой, это может ввести в заблуждение. Давайте разберемся, почему так вышло. Чтобы понять, давайте рассмотрим одну точку в пространстве ROC-кривой. Возьмем порог, при котором к первому классу будут отнесены 50 тысяч объектов негативного класса и 95 объектов позитивного класса. Понятно, что это не очень хороший классификатор — у него слишком много ложных срабатываний. Их будет 50 тысяч, при этом верных срабатываний — 95. Доля верных срабатываний равна 95 %, доля ложных срабатываний равна всего 5 %, поскольку в ней нормировка производится на размер всего отрицательного класса. А 50 тысяч — это очень мало, по сравнению с миллионом объектов во всем отрицательном классе. Понятно, что эта точка лежит близко к точке с координатами (0, 1), и поэтому ROC-кривая очень похожа на идеальную — площадь под ней близка к 1. При этом точность и полнота этого алгоритма гораздо лучше отражают ситуацию. Полнота равняется 95 %, а точность — меньше 1 %, поскольку слишком много ложных срабатываний. Таким образом, площадь под кривой точности-полноты гораздо лучше отражает ситуацию в данном примере с несбалансированными выборками. Итак, мы обсудили, что зачастую в машинном обучении нужно измерять качество модели еще до того, как мы выбрали порог, нужно измерять качество оценок принадлежности к первому классу. Для этого подходят такие метрики, как площадь под кривой точности и полноты и площадь под ROC-кривой. При этом площадь под ROC-кривой не зависит от баланса классов и гораздо лучше интерпретируется. А площадь под кривой точности и полноты гораздо выразительнее в случае дисбаланса классов. На этом мы заканчиваем урок, посвященный метрикам качества, а дальше продолжим говорить о линейных моделях.

Метрики качества
4.1. Метрики качества в задачах регрессии
4.1.1. Применение метрик качества в машинном обучении
Метрики качества могут использоваться:
• Для задания функционала ошибки (используется при обучении).
• Для подбора гиперпараметров (используется при измерении качества на кросс-валидации). В том числе
можно использовать другую метрику, которая отличается от метрики, с помощью которой построен
функционал ошибки.
• Для оценивания итоговой модели: пригодна ли модель для решения задачи.
Далее мы рассмотрим, какие метрики можно использовать в задачах регрессии.
4.1.2. Среднеквадратичная ошибка
Первая метрика, о которой уже шла речь — среднеквадратичная ошибка:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
Такой функционал легко оптимизировать, используя, например, метод градиентного спуска.
Этот функционал сильно штрафует за большие ошибки, так как отклонения возводятся в квадрат. Это
приводит к тому, что штраф на выбросе будет очень сильным, и алгоритм будет настраиваться на выбросы.
Другими словами, алгоритм будет настраиваться на такие объекты, на которые не имеет смысл настраиваться.
4.1.3. Средняя абсолютная ошибка
Похожий на предыдущий функционал качества — средняя абсолютная ошибка:
MAE(a, X) = 1
`
X
`
i=1
|a(xi) − yi
| .
Этот функционал сложнее минимизировать, так как у модуля производная не существует в нуле. Но у такого
функционала больше устойчивость к выбросам, так как штраф за сильное отклонение гораздо меньше.
4.1.4. Коэффициент детерминации
Коэффициент детерминации R2
(a, X):
R
2
(a, X) = 1 −
P`
i=1
a(xi) − yi
2
P`
i=1(yi − y¯)
, y¯ =
1
`
X
`
i=1
yi
,

позволяет интерпретировать значение среднеквадратичной ошибки. Этот коэффициент показывает, какую
долю дисперсии (разнообразия ответов) во всем целевом векторе y модель смогла объяснить.
Для разумных моделей коэффициент детерминации лежит в следующих пределах:
0 ≤ R
2 ≤ 1,
причем случай R2 = 1 соответствует случаю идеальной модели, R2 = 0 — модели на уровне оптимальной
«константной», а R2 < 0 — модели хуже «константной» (такие алгоритмы никогда не нужно рассматривать).
Оптимальным константым алгоритмом называется такой алгоритм, который возвращает всегда среднее значение ответов y¯ для объектов обучающей выборки.
4.1.5. Несимметричные потери
До этого рассматривались симметричные модели, то есть такие, которые штрафуют как за недопрогноз, так
и за перепрогноз. Но существуют такие задачи, в которых эти ошибки имеют разную цену.
Пусть, например, требуется оценить спрос на ноутбуки. В этом случае заниженный прогноз приведет к
потере лояльности покупателей и потенциальной прибыли (будет закуплено недостаточное количество ноутбуков), а завышенный — только к не очень большим дополнительным расходам на хранение непроданных
ноутбуков. Чтобы учесть это, функция потерь должна быть несимметричной и сильнее штрафовать за недопрогноз, чем за перепрогноз.
4.1.6. Квантильная ошибка
В таких случаях хорошо подходит квантильная ошибка или квантильная функция потерь:
ρτ (a, X) = 1
`
X
`
i=1

(τ − 1)
yi < a(xi)

+ τ

yi ≥ a(xi)


(yi − a(xi)).
τ − 1
τ
Рис. 4.1: График квантильной функции потерь
Параметр τ ∈ [0, 1] определяет то, за что нужно штрафовать сильнее — за недопрогноз или перепрогноз.
Если τ ближе к 1, штраф будет больше за недопрогноз, а если, наоборот, ближе к 0 — за перепрогноз.
4.1.7. Вероятностный смысл квантильной ошибки
Чтобы разобраться, почему такая функция потерь называется квантильной, нужно разобраться с ее вероятностным смыслом. Пусть один и тот же объект x с одним и тем же признаковым описанием повторяется в
выборке n раз, но на каждом из повторов — свой ответ y1, ..., yn.
Такое может возникнуть при измерении роста человека. Измерения роста одного и того же человека могут
отличаться ввиду ошибки прибора, а также зависеть от самого человека (может сгорбиться или выпрямиться).
При этом алгоритм должен для одного и того же признакового описания возвращать одинаковый прогноз.
Другими словами, необходимо решить, какой прогноз оптимален для x с точки зрения различных функционалов ошибки.
Оказывается, что если используется квадратичный функционал ошибки, то наиболее оптимальным прогнозом будет средний ответ на объектах, если абсолютный, то медиана ответов. Если же будет использоваться
квантильная функция потерь, наиболее оптимальным прогнозом, будет τ -квантиль. В этом и состоит вероятностный смысл квантильной ошибки.
2
4.2. Метрика качества классификации
В этом блоке речь пойдет о том, как измерять качество в задачах классификации.
4.2.1. Доля правильных ответов
Как меру качества в задачах классификации естественно использовать долю неправильных ответов:
1
`
X
`
i=1
[a(xi) 6= yi
]
Однако в задачах классификации принято выбирать метрики таким образом, чтобы их нужно было максимизировать, тогда как в задачах регрессии — так, чтобы их нужно было минимизировать. Поэтому определяют:
accuracy(a, X) = 1
`
X
`
i=1
[a(xi) = yi
] .
Эта метрика качества проста и широко используется, однако имеет несколько существенных недостатков.
4.2.2. Несбалансированные выборки
Первая проблема связана с несбалансированными выборками. Показателен следующий пример. Пусть в выборке 1000 объектов, из которых 950 относятся к классу −1 и 50 — к классу +1. Рассматривается бесполезный
(поскольку не восстанавливает никаких закономерностей в данных) константный классификатор, который
на всех объектах возвращает ответ −1. Но доля правильных ответов на этих данных будет равна 0.95, что
несколько много для бесполезного классификатора.
Чтобы «бороться» с этой проблемой, используется следующий факт. Пусть q0 — доля объектов самого
крупного класса, тогда доля правильных ответов для разумных алгоритмов accuracy ∈ [q0, 1], а не [1/2, 1],
как это можно было бы ожидать. Поэтому, если получается высокий процент правильных ответов, это может
быть связано не с тем, что построен хороший классификатор, а с тем, что какого-то класса сильно больше,
чем остальных.
4.2.3. Цены ошибок
Вторая проблема с долей верных ответов состоит в том, что она никак не учитывает разные цены разных
типов ошибок. Тогда как цены действительно могут быть разными.
Например, в задаче кредитного скоринга, то есть в задаче принятия решения относительно выдачи кредита, сравниваются две модели. При использовании первой модели кредит будет выдан 100 клиентам, 80 из
которых его вернут. Во второй модели, более консервативной, кредит был выдан только 50 клиентам, причем
вернули его в 48 случаях. То, какая из двух моделей лучше, зависит от того, цена какой из ошибок выше:
не дать кредит клиенту, который мог бы его вернуть, или выдать кредит клиенту, который его не вернет.
Таким образом, нужны дополнительные метрики качества, которые учитывают цены той или иной ошибки.
4.3. Точность и полнота
4.3.1. Цены ошибок
В этом разделе пойдет речь о метриках качества классификации, которые позволяют учитывать разные цены ошибок. В конце предыдущего разделе уже было сказано, что цены ошибок действительно могут быть
разными. Так, в задаче банковского скоринга необходимо принять решение, что хуже: выдать кредит «плохому» клиенту или не выдать кредит «хорошему» клиенту. Доля верных ответов не способна учитывать цены
разных ошибок и поэтому не может дать ответа на этот вопрос.
3
4.3.2. Матрица ошибок
Удобно классифицировать различные случаи, как соотносятся между собой результат работы алгоритма и
истинный ответ, с помощью так называемой матрицы ошибок.
y = 1 y = −1
a(x) = 1 True Positive (TP) False Positive (FP)
a(x) = −1 False Negative (FN) True Negative (TN)
Когда алгоритм относит объект к классу +1, говорят, что алгоритм срабатывает. Если алгоритм сработал
и объект действительно относится к классу +1, имеет место верное срабатывание (true positive), а если объект
на самом деле относится к классу −1, имеет место ложное срабатывание (false positive).
Если алгоритм дает ответ −1, говорят, что он пропускает объект. Если имеет место пропуск объекта
класса +1, то это ложный пропуск (false negative). Если же алгоритм пропускает объект класса −1, имеет
место истинный пропуск (true negative).
Таким образом, существуют два вида ошибок: ложные срабатывания и ложные пропуски. Для каждого
из них нужна своя метрика качества, чтобы измерить, какое количество ошибок какого типа совершается.
4.3.3. Точность и полнота
Пусть для примера рассматриваются две модели a1(x) и a2(x). Выборка состоит из 200 объектов, из которых
100 относятся к классу 1 и 100 — к классу −1. Матрицы ошибок имеют вид:
y = 1 y = −1
a1(x) = 1 80 20
a1(x) = −1 20 80
y = 1 y = −1
a2(x) = 1 48 2
a2(x) = −1 52 98
Введем две метрики. Первая метрика, точность (precision), показывает, насколько можно доверять классификатору в случае срабатывания:
precision(a, X) = T P
T P + F P
.
Вторая метрика, полнота (recall), показывает, на какой доле истинных объектов первого класса алгоритм
срабатывает:
recall(a, X) = T P
T P + F N
.
В примере выше точность и полнота первого алгоритма оказываются равными:
precision(a1, X) = 0.8, precision(a2, X) = 0.96
recall(a1, X) = 0.8, recall(a2, X) = 0.48
Вторая модель является очень точной, но в ущерб полноте.
4.3.4. Примеры использования точности и полноты
Первый пример — использование в задаче кредитного скоринга. Пусть в задаче кредитного скоринга ставится условие, что неудачных кредитов должно быть не больше 5%. В таком случае задача является задачей
максимизации полноты при условии precision(a, X) ≥ 0.95.
Второй пример — использование в медицинской диагностике. Необходимо построить модель, которая определяет, есть или нет определенное заболевание у пациента. При этом требуется, чтобы были выявлены как
минимум 80% пациентов, которые действительно имеют данное заболевание. Тогда ставят задачу максимизации точности при условии recall(a, X) ≥ 0.8.
Следует особо обратить внимание на то, как точность и полнота работают в случае несбалансированных
выборок. Пусть рассматривается выборка со следующей матрицей ошибок:
y = 1 y = −1
a(x) = 1 10 20
a(x) = −1 90 10000
4
Доля верных ответов (accuracy), точность(precision) и полнота(recall) для данного случая:
accuracy(a, X) = 0.99, precision(a, X) = 0.33, recall(a, X) = 0.1.
То, что доля верных ответов равняется 0.99, ни о чем не говорит: алгоритм все равно делает 66% ложных
срабатываний и выявляет только 10% положительных случаев. Благодаря введению точности и полноты
становится понятно, что алгоритм нужно улучшать.
4.4. Объединение точности и полноты
В этом разделе пойдет речь о том, как соединить точность и полноту в одну метрику качества классификации.
4.4.1. Точность и полнота (напоминание)
Точность показывает, насколько можно доверять классификатору в случае срабатывания:
precision(a, X) = T P
T P + F P
.
Полнота показывает, на какой доле истинных объектов первого класса алгоритм срабатывает:
recall(a, X) = T P
T P + F N
.
В некоторых задачах есть ограничения на одну из этих метрик, тогда как по второй метрике будет производиться оптимизация. Но в некоторых случаях хочется максимизировать и точность, и полноту одновременно.
Встает вопрос об объединении этих двух метрик.
4.4.2. Арифметическое среднее
Единая метрика может быть получена как арифметическое среднее точности и полноты:
A =
1
2
(precision + recall)
Пусть есть алгоритм, точность которого равна 10%, а полнота — 100%:
precision = 0.1 recall = 1.
Это может быть случай, когда в выборке всего 10% объектов класса +1, а алгоритм является константным
и всегда возвращает +1. Очевидно, что этот алгоритм плохой, но введенная выше метрика для него равна
A = 0.55. В свою очередь другой, гораздо более лучший алгоритм, с precision = 0.55 и recall = 55 также
характеризуется A = 0.55.
Ситуация, когда константный и разумный алгоритмы могут лежать на одной линии, является недопустимой, поэтому следует искать другой способ построения единой метрики.
5
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.2: Линии A =
1
2
(precision + recall) = const в координатах precision–recall
4.4.3. Минимум
Чтобы констрантный и разумный алгоритмы не лежали на одной линии уровня, можно рассматривать:
M = min(precision, recall).
Данный подход решает вышеупомянутую проблему, например:
precision = 0.05, recall = 1 =⇒ M = 0.05.
Но есть другой нюанс: два алгоритма, для которых точности одинаковы, но отличаются значения полноты,
будут лежать на одной линии уровня M:
precision = 0.4, recall = 0.5 =⇒ M = 0.4,
precision = 0.4, recall = 0.9 =⇒ M = 0.4.
Такое тоже недопустимо, так как второй алгоритм существенно лучше первого. recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.3: Линии M = min(precision, recall) = const в координатах precision–recall
6
4.4.4. F-мера
«Сгладить» минимум можно с помощью гармонического среднего, или F-меры:
F =
2 · precision · recall
precision + recall .
Для двух упомянутых выше алгоритма значения F-меры, в отличие от M, будут отличаться:
precision = 0.4, recall = 0.5 =⇒ F = 0.44,
precision = 0.4, recall = 0.9 =⇒ F = 0.55.
Если необходимо отдать предпочтение точности или полноте, следует использовать расширенную F-меру, в
которой есть параметр β:
F = (1 + β
2
)
precision · recall
β
2 · precision + recall.
Например, при β = 0.5 важнее оказывается полнота, а в случае β = 2, наоборот, важнее оказывается точность. recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.4: Линии F = const в координатах precision–recall при значениях β = 1, β = 0.5 и β = 2 соответственно
4.5. Качество оценок принадлежности классу
4.5.1. Оценка принадлежности
Многие алгоритмы бинарной классификации устроены следующим образом: сначала вычисляется некоторое
вещественное число b(x), которое сравнивается с порогом t.
a(x) = [b(x) > t],
где b(x) — оценка принадлежности классу +1. Другими словами, b(x) выступает в роли некоторой оценки
уверенности, что x принадлежит классу +1.
В случае линейного классификатора a(x) = [hw, xi > t] оценка принадлежности классу +1 имеет вид
b(x) = hw, xi.
Часто бывает необходимо оценить качество именно оценки принадлежности, а порог выбирается позже из
соображений на точность или полноту.
4.5.2. Оценка принадлежности в задаче кредитного скоринга
Пусть рассматривается задачного кредитного скоринга и была построена некоторая функция b(x), которая
оценивает вероятность возврата кредита клиентом x. Далее классификатор строится следующим образом:
a(x) = [b(x) > 0.5]
При этом получилось, что точность (precision) равна 10%, а полнота (recall) — 70%. Это очень плохой алгоритм, так как 90% клиентов, которым будет выдан кредит, не вернут его.
При этом не понятно, в чем дело: был плохо выбран порог или алгоритм не подходит для решения данной
задачи. Именно для этого необходимо измерять качество самих оценок b(x).
7
4.5.3. PR-кривая
Первый способ оценки принадлежности классу основан на использовании кривой точности-полноты. По оси
X откладывается полнота, а по оси Y — точность. Каждой точке на этой кривой будет соответствовать
классификатор с некоторым значением порога. precision
recall
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.5: Кривая полноты–точности
Для примера будет приведено построение PR-кривой для выборки из 6 объектов, три из которых относятся
к классу 1 и 3 — к классу 0. Соответствующий ей график изображен выше.
b(x) 0.14 0.23 0.39 0.54 0.73 0.90
y 0 1 0 0 1 1
1. При достаточно большом пороге ни один объект не будет отнесен к классу 1. В этом случае и точность
и полнота равны 0.
2. При таком пороге, что ровно один объект отнесен к классу 1, точность будет 100% (поскольку этот
объект действительно из 1 класса), а полнота — 1/3 (поскольку всего 3 объекта 1 класса).
3. При дальнейшем уменьшении порога уже два объекта отнесены к классу 1, точность также остается
100%, а полнота становится равной 2/3.
4. При таком пороге, что уже три объекта будут отнесены к классу 1, точность становится равной 2/3, а
полнота остается такой же.
5. При таком пороге, что четыре объекта отнесены к классу 1, точность уменьшится до 0.5, а полнота
опять не изменится.
6. При дальнейшем уменьшении порога уже 5 объектов будут отнесены к 1 классу, полнота станет равной
100%, а точность — 3/5.
В реальных задачах с числом объектов порядка нескольких тысяч или десятков тысяч, кривая точностиполноты выглядит примерно следующим образом.
8
Рис. 4.6: Кривая точности-полноты в реальных задачах с десятками тысяч объектов
Следует отметить, что начинается PR-кривая всегда из точки (0, 0), а заканчивается точной (1, r), где r
— доля объектов класса 1.
В случае идеального классификатора, то есть если существует такой порог, что и точность, и полнота равны 100%, кривая будет проходить через точку (1, 1). Таким образом, чем ближе кривая пройдет к этой точке,
тем лучше оценки. Площадь под этой кривой может быть хорошей мерой качества оценок принадлежности
к классу 1. Такая метрика называется AUC–PRC, или площадь под PR-кривой.
4.5.4. ROC-кривая
Второй способ измерить качество оценок принадлежности к классу 1 — ROC-кривая, которая строится в осях
False Positive Rate (ось X) и True Positive Rate (ось Y ):
F P R =
F P
F P + T N
, T P R =
T P
T P + F N
.
ROC-кривая строится аналогично PR-кривой: постепенно рассматриваются случаи различных значений порогов и отмечаются точки на графике. Для упомянутой выше выборки ROC-кривая имеет следующий вид: TPR
FPR
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.7: ROC–кривая
9
В случае с большой выборкой ROC-кривая выглядит следующим образом:
Рис. 4.8: Кривая ROC в реальных задачах с десятками тысяч объектов
Кривая стартует с точки (0, 0) и приходит в точку (1, 1). При этом, если существует идеальный классификатор, кривая должна пройти через точку (0, 1). Чем ближе кривая к этой точке, тем лучше будут оценки,
а площадь под кривой будет характеризовать качество оценок принадлежности к первому классу. Такая
метрика называется AUC–ROC,или площадь под ROC-кривой.
4.5.5. Особенности AUC-ROC
Как было написано выше, ROC-кривая строится в осях F P R и T P R, которые нормируются на размеры
классов:
F P R =
F P
F P + T N
, T P R =
T P
T P + F N
.
Следовательно, при изменении баланса классов величина AUC-ROC и неизменных свойствах объектов выборки площадь под ROC-кривой не изменится. В случае идеального алгоритма AUC − ROC = 1, а в случае
худшего AUC − ROC =
1
2
.
Значение AUC−ROC имеет смысл вероятности того, что если были выбраны случайный положительный и
случайный отрицаельный объекты выборки, положительный объект получит оценку принадлежности выше,
чем отрицательный объект.
4.5.6. Особенности AUC-PRC
PR-кривая строится в осях precision и recall:
precision =
T P
T P + F P
, recall =
T P
T P + F N
,
а следовательно изменяется при изменении баланса классов.
Линейные модели: статистический взгляд

Привет! С вами Евгений. В этом уроке мы с вами поговорим о задаче регрессии, обсудим некоторые ее важные свойства, как она решается, почему она решается именно так и как интерпретировать то, что получается в результате. Если подумать, термин регрессия довольно странный. Кажется, что в нем есть что-то негативное. Впервые этот термин появился в конце XIX века в работе Френсиса Гальтона, которая называлась «Регрессия к середине в наследственности роста». В этой работе Френсис Гальтон исследовал зависимость между средним ростом детей и средним ростом их родителей и обнаружил, что отклонение роста детей от среднего составляет примерно две трети отклонения роста родителей от среднего. Этот результат контринтуитивен. Кажется, он означает, что с течением времени люди должны рождаться все ближе и ближе к среднему росту. На самом деле, естественно, этого не происходит. Чтобы лучше понять эффект регрессии к среднему, давайте посмотрим на другое творение Френсиса Гальтона, которое называется машина, или доска, Гальтона. Это механическая машина, в которой сверху в центральной части находятся шарики. Когда открывается заслонка, шарики начинают постепенно сыпаться вниз, ударяясь о штырьки, которые расположены на одинаковом расстоянии друг от друга. При каждом соударении шарика со штырьком вероятность того, что он упадет налево и направо от штырька, одинакова. Постепенно шарики начинают собираться в секциях внизу в до боли знакомую нам фигуру — в гауссиану, или плотность нормального распределения. Чтобы понять эффект регрессии к среднему, давайте мысленно подставим к машине Гальтона снизу еще одну такую же машину. Если теперь мы уберем перегородку, которая удерживает шарики в верхней половине, они начнут постепенно осыпаться вниз и сформируют внизу еще одну такую же гауссиану. Давайте теперь зафиксируем какой-то конкретный шарик, который в нижней половине находится в одной из ячеек близко к краю, и попытаемся понять, откуда сверху он мог в эту ячейку попасть. Оказывается, что с достаточно большой вероятностью этот шарик пришел не из ячейки, которая находится в верхней половине прямо над ячейкой, в которой он оказался внизу, а от ячейки ближе к середине. Это происходит просто потому, что в середине шариков больше. Эффект регрессии к среднему проявляется во многих практических задачах. Например, если вы дадите какой-то достаточно сложный тест группе студентов, то большую роль в том, насколько хорошо они его пройдут, будут играть не только их знания по предмету, но и то, насколько им повезло, то есть случайный фактор. Поэтому если вы изолируете, например, 10 % студентов, которые прошли тест лучше всех (набрали больше всего баллов) и дадите им еще одну версию этого теста и заставите их пройти его снова, средний балл в этой группе скорее всего упадет. Просто потому что люди, которым повезло в первый раз, скорее всего уже не будут так удачливы во второй. Это эффект регрессии к середине. Френсис Гальтон был достаточно плодовитым ученым. Он был основоположником дактилоскопии, исследовал явление синестезии, внес существенный вклад в метеорологию, впервые описав циклоны и антициклоны, а также, например, изобрел ультразвуковой свисток для собак. Но именно регрессия и по сей день остается одним из наиболее важнейших инструментов, к которому он приложил руку. Давайте начнем его изучение. Чаще всего под регрессией понимают минимизацию среднеквадратичной ошибки: квадратов отклонений откликов y от их предсказанных значений a(x). Поскольку минимизируется сумма квадратов отклонений, этот метод называется методом наименьших квадратов (сокращенно МНК). Для линейной регрессии, в которой мы приближаем отклик линейной комбинации наших факторов x с весами w, эта задача имеет аналитическое решение. Именно этим частично объясняется популярность среднеквадратичной ошибки. В XIX веке, когда эта задача впервые возникла, никакого способа ее решения, кроме аналитического, быть не могло. Сейчас мы можем минимизировать не только среднеквадратичную ошибку, но и, например, среднюю абсолютную, то есть сумму модулей отклонений нашей модели от отклика. Такая задача является частным случаем класса задач квантильной регрессии, о которых мы будем говорить подробно в следующих видео. Далее в этом уроке вас ждет знакомство с методом максимального правдоподобия, подробное изучение свойств регрессии, регуляризации, а также задача логистической регрессии. 

Прежде чем дальше изучать задачи регрессии, в этом видео мы познакомимся с методом максимизации правдоподобия — одним из мощнейших методов математической статистики. Представьте, что у вас есть некая случайная величина x и ее функция распределения F(x) зависит от неизвестного вам параметра θ. Пусть у вас есть выборка из этой случайной величины, то есть совокупность независимых, одинаково распределенных ее реализаций. Как по выборке лучше всего оценить неизвестный параметр θ? Чтобы понять метод максимального правдоподобия, давайте рассмотрим еще один исторический пример. Эти данные собраны в конце XIX века. В Генеральный штаб прусской армии ежегодно в течение 20 лет от десяти кавалерийских корпусов поступали данные о количестве смертей кавалеристов в результате гибели под ними коня. Эти данные — перед вами в таблице. Как видно, в большей части отчетов никто не умер, однако в 65-и отчетах умер один человек, в 22-х отчетах умерло два человека и так далее. Поскольку эта случайная величина — количество умерших кавалеристов — явно счетчик, логично попробовать моделировать ее распределением Пуассона. Но как выбрать неизвестный параметр λ для этого распределения? Давайте запишем функцию вероятности для распределения Пуассона. Вероятность того, что случайная величина из распределения Пуассона с параметром λ примет значение k, определяется вот такой величиной. Теперь вероятность получения значения, равного i-тому элементу выборки, записывается той же формулой. Поскольку наша выборка состоит из независимых, одинаково распределенных случайных величин, мы можем записать суммарную вероятность выборки, вероятность получения именно такой выборки, и она будет являться произведением вероятности каждого элемента этой выборки. Эта функция является функцией неизвестного параметра λ, обозначается за L, и называется правдоподобием выборки, то есть вероятностью получения именно такой выборки. Если теперь мы, в качестве нашей оценки λ, возьмем значение, которое максимизирует функцию правдоподобия, мы получим оценку, которая называется оценкой максимального правдоподобия. Логично оценивать λ именно таким способом, поскольку, выбирая именно такое λ, мы максимизируем вероятность получения именно таких данных, которые у нас есть. В рассматриваемой задаче несложно показать, что оценка максимального правдоподобия для параметра λ совпадает с выборочным средним. Чтобы это показать, нужно всего лишь взять логарифм от функции правдоподобия — логарифмирование не влияет на положение максимума этой функции, но превращает произведение вероятностей в сумму, с которой легче оперировать. После чего от этого логарифма нужно взять производную, приравнять ее к нулю, и таким образом найти точку максимума. Вы можете без труда проделать это упражнение. В данном случае выборочное среднее равно 0,61, то есть данные, которые мы рассматриваем, лучше всего моделировать случайной величиной с распределением Пуассона и параметром 0,61. Вот так в общем виде выглядит метод максимума правдоподобия. Трюк с логарифмированием, который я вам только что описал, используется достаточно часто, потому что оперировать с логарифмом правдоподобия действительно проще, чем с самим правдоподобием. Если вы имеете дело со случайной величиной из непрерывного распределения, метод максимального правдоподобия работает точно так же, за исключением того, что функция вероятности нашей случайной величины заменяется на ее плотность. Метод максимального правдоподобия обладает рядом очень полезных свойств. Во-первых, получаемые с его помощью оценки являются состоятельными, то есть при увеличении объема выборки они начинают стремиться к истинным значениям параметра θ. Во-вторых, они являются асимптотически нормальными, то есть опять же, с ростом объема выборки, оценки максимального правдоподобия все лучше описываются нормальным распределением с средним, равным истинному значению θ и дисперсией, равной величине, обратной к информации Фишера. Что это такое, совершенно не важно. Важно только, что эта величина также с успехом может быть оценена по выборке. Итак, в этом видео мы познакомились с методом максимизации правдоподобия — крайне мощным и полезным методом оценки неизвестных параметров распределения. Из следующего видео вы узнаете, при чем тут регрессия.

Теперь, когда вы знаете, что такое правдоподобие и зачем его максимизировать, давайте вернемся к задаче регрессии. Попробуем разобраться, что именно получается в результате минимизации среднеквадратичной ошибки. Строя регрессию, мы пытаемся значение отклика y приблизить нашей модельной функции a от факторов x. Это можно представить следующим образом. Значение отклика y представляет собой сумму регрессионной функции a(x) и компоненты ε, которая описывает некоторый случайный шум. Если этот случайный шум имеет нормальное распределение с нулевым средним и какой-то дисперсией σ², оказывается, что задача минимизации среднеквадратичной ошибки дает оценку максимального правдоподобия для регрессионной функции a(x). Казалось бы, какое это имеет значение? Дело в том, что опираясь на этот факт, мы можем использовать свойства метода максимального правдоподобия, в частности асимптотическую нормальность. Используя эту асимптотическую нормальность, мы можем определять значимость признаков xʲ в нашей модели и делать отбор этих признаков, а также мы можем строить доверительные интервалы для значения отклика на новых объектах, которых в нашей обучающей выборке нет. Распределение шума не обязательно должно быть нормальным, может быть каким-то другим. Например, можно попытаться описать его распределением Лапласа с нулевым средним. Формула для функции плотности вероятности такого распределения перед вами. Вот так выглядит ее график. По сравнению с нормальным распределением, распределение Лапласа имеет более тяжелые хвосты, то есть для него более вероятны большие значения ε. Если мы моделируем шум распределением Лапласа, мы разрешаем наблюдениям сильнее отклоняться от нашей модели, и за счет этого мы получаем решение, которое более устойчиво к выбросам. Оказывается, что если шум действительно описывается распределением Лапласа, то к оценке максимального правдоподобия приводит минимизация средних абсолютных отклонений. Итак, из этого видео вы узнали, что регрессия методом наименьших квадратов дает оценку максимального правдоподобия в случае нормального шума, а регрессия со средней абсолютной ошибкой дает оценку максимального правдоподобия для нашей регрессионной функции, если шум лапласовский. В следующем видео вы узнаете, как регрессию можно интерпретировать как оценку среднего.

Продолжим разбираться с тем, что же такое получается в качестве ответа в задаче регрессии. Начнем снова с метода наименьших квадратов. Разберемся со среднеквадратичной ошибкой. Чтобы разбираться было проще, давайте сделаем некоторые упрощающие предположения. Пусть для начала у нас нет никаких признаков x, а a — это просто константа. Пусть кроме того у нас есть бесконечная выборка из y, то есть фактически и не выборка вовсе, а полностью известно распределение случайной величины y. Пусть оно задается плотностью f (t). В таком случае среднеквадратичная ошибка принимает следующий вид. Нетрудно показать, раскрыв квадрат под знаком интеграла и продифференцировав полученное выражение, что минимум такому функционалу доставляет математическое ожидание y. То есть наилучшая константа, которая аппроксимирует значение y в смысле среднеквадратичной ошибки — это математическое ожидание. Пусть теперь a — это не константа, а некоторая произвольная функция от наших признаков x. Можно показать, что в этом случае минимумом среднеквадратичной ошибки является условное математическое ожидание y по x. То есть среднее значение y при таких x. Теперь, если мы имеем дело с конечной выборкой, получается, оценка, которую мы получаем, минимизируя среднеквадратичную ошибку — это наша лучшая аппроксимация условного математического ожидания. Если регрессия линейная, то есть отклик y моделируется линейной комбинацией наших признаков x с весами w, то w*, минимизирующее среднеквадратичную ошибку, задает наилучшую линейную аппроксимацию условного математического ожидания. В каком-то смысле этот результат интуитивно понятен. Пусть, например, y = 2. Поскольку среднеквадратичная ошибка будет симметрична относительно 2, мы будем одинаково штрафовать наши модельные предсказания a (x) за большие отклонения от 2 как в большую, так и в меньшую сторону. Неудивительно, что минимизируя симметричную функцию потерь, мы получаем в ответе какое-то среднее. Однако оказывается, что условное математическое ожидание доставляет минимум не только среднеквадратичной ошибке, но и более широкому классу функций потери, которые называются дивергенциями Брегмана. Дивергенции Брегмана порождаются любой непрерывной дифференцируемой выпуклой функцией φ. Среднеквадратичная ошибка является ее частным случаем. Таким образом, минимизируя любую дивергенцию Брегмана, мы получаем какую-то оценку для условного математического ожидания. И вот это уже довольно странно, потому что в семействе дивергенций Брегмана можно найти функции, которые относительно y несимметричны. Они могут выглядеть вот так или так или так, то есть они сильнее штрафуют за отклонение нашей модели от y в какую-то из сторон. Тем не менее, наилучшей оценкой является все еще условное математическое ожидание. Этот результат достаточно контринтуитивен, и получен он был не так давно. А вот средняя абсолютная ошибка в семейство дивергенций Брегмана не входит. Минимизируя вот эту среднюю абсолютную ошибку, график которой представляет собой такой треугольник, мы получаем тоже оценку какого-то среднего, но другого. Это уже оценка не условного математического ожидания, а условной медианы y|x. Треугольник, описывающий среднюю абсолютную ошибку, можно попробовать наклонить в какую-то из сторон на угол τ. Минимизируя такой функционал, мы получаем оценку для условного квантиля y|x порядка τ. τ, естественно, меняется от 0 до 1, поскольку это квантиль. Итак, в этом видео мы узнали, что решение задачи регрессии наименьших квадратов представляет собой наилучшую возможную по выборке оценку условного матожидания y при условии x. Решение задачи квантильной регрессии дает оценку условного квантиля y|x. А при использовании средней абсолютной ошибки мы получаем оценку условной медианы med (y|x). Далее в программе: регуляризация.

В этом видео мы поговорим о регуляризации линейных регрессионных моделей. Как вы видели ранее в этом курсе, регрессионные модели имеют свойство переобучаться. Если вы взяли слишком сложную модель и у вас недостаточно данных для того, чтобы точно определить ее параметры, вы легко можете получить какую-то модель, которая будет очень хорошо описывать вашу обучающую выборку, но при этом очень плохо обобщаться на тестовую. Бороться с этим можно разными способами. Можно попробовать взять больше данных. Имея много данных, вы сможете точнее оценить вашу модель и уменьшить переобучение. Очень часто это решения недоступно, поскольку дополнительные данные стоят дополнительных денег. Даже в задачах, когда, казалось бы, у вас есть терабайты данных, например в задачах веб-поиска, эффективный объем выборки зачастую часто оказывается очень маленьким, если, например, мы хотим показывать для каждого пользователя его персонализированные результаты. Мы вынуждены использовать только его историю. Еще один способ борьбы с переобучением — это упрощение модели. В частности, можно, например, взять просто меньше признаков. Какие-то из признаков просто выбросить. Для этого нужно перебрать большое количество подмножеств наших признаков xj-тое, и общее количество подмножеств, которые нужно перебрать, очень быстро растет с ростом размерности задачи. Полный перебор часто оказывается недоступен. Кроме того, если признаков действительно много и они сильно зашумлены, может оказаться, что в выборке находится какая-то пара признаков, которые на обучении очень похожи. В этом случае совершенно непонятно, какой из этих признаков следует взять в модель. Наконец, еще один способ борьбы с переобучением линейной модели — это ограничение весов у признаков. Вы видели ранее в курсе, что когда линейная модель переобучается, веса у признаков становятся большими по модулю и разными по знаку. Ограничивая значение этих весов по модулю, можно с переобучением до какой-то степени побороться. Мы рассматривали два способа регуляризации: L2-регуляризатор добавляет к функционалу потерь слагаемое, равное сумме квадратов весов нашей линейной модели с множителем λ; L1-регуляризатор использует вместо суммы квадратов сумму модулей весов. Регрессия с L2-регуляризатором называется ридж-регрессией или гребневой регрессией, а с L1-регуляризатором — лассо. Очень важно, что константное слагаемое в регуляризатор входить не должно. Штрафуя за большое значение константы, переобучение мы не уменьшим, а вот качество моделей и на обучающей, и на тестовой выборке упадет очень сильно. Чтобы понять, чем отличаются L1 и L2-регуляризаторы давайте рассмотрим простой модельный пример. Пусть матрица «объекты-признаки» X — квадратная, диагональная и единичная, то есть на ее диагонали стоят единицы, а вся остальная часть заполнена нулями. В этом случае решение метода наименьших квадратов дает вектор весов w со звездочкой, j-тая компонента которого равна yj-тому. Если мы делаем гребневую регрессию, то j-тая компонента w уменьшается в (1 + λ) раз. Если мы делаем лассо, формула для j-той компоненты вектора весов более сложная. Давайте посмотрим на графики. На графиках показана зависимость j-той компоненты оптимального вектора весов w со звездочкой от yj-того. Если мы минимизируем среднеквадратичную ошибку, не используя регуляризаторы, то эта зависимость единичная, то есть wj-тое и yj-тое всегда одинаковые. На графиках — это пунктирная диагональная линия. Если мы использует регуляризацию L2, зависимость wj-тое со звездочкой все еще линейная, но веса прижаты к нулю. Лассо делает кое-что более интересное. Оптимальные веса лассо также прижимаются к нулю, однако в середине на этом графике появляется интервал размером λ, в котором веса обращаются в ноль в точности. То есть если у нас значению отклика маленькое, то вес получается нулевым. Именно поэтому лассо отбирает признаки. Если у признаков низкая предсказательная способность, в лассо они получают нулевой вес и таким образом из модели исключаются. С другой стороны, посмотреть на регуляризацию можно, если рассмотреть, как устроена ошибка регрессии. Давайте посмотрим на матожидание квадрата этой ошибки. Оно представляет собой сумму трех компонент. Первая компонента — это квадрат смещения, то есть квадрат разности между математическим ожиданием регрессионной модели, оцениваемой по выборке, и истинной неизвестной нам регрессионной модели. Вторая компонента — это дисперсия нашей выборочной оценки. А третья — это дисперсия шума, на который повлиять мы никак не можем. Метод наименьших квадратов дает оценки, которые имеют нулевое смещение. Однако, используя регуляризацию, мы можем получить оценки, у которых матожидание квадрата ошибки меньше за счет того, что дисперсия у них может быть меньше, несмотря а то, что эти оценки смещенные. Чтобы лучше понять баланс между смещением и дисперсией, представьте, что вы стреляете по мишеням. Среднее количество очков, которое вы при этом набираете, определяется двумя величинами: во-первых, средним облака точек, которое образуют результаты ваших выстрелов; во-вторых, разбросом выстрелов относительно этого среднего, то есть дисперсией. Естественно, больше всего очков вы получите, если вы будете стрелять точно и в цель. В этом случае у вас может быть какое-то небольшое смещение и маленькая дисперсия. Переобучение в линейных моделях приводит к тому, что вы стреляете с цель, но не точно. Смещения у вас нет, но дисперсия очень большая. Часто оказывается, что можно набрать больше очков, если вы будете стрелять не совсем в цель, но более точно. Именно это позволяет сделать использование регуляризации в линейных моделях. В байесовской статистике гребневая регрессия соответствует заданию нормального априорного распределения на коэффициенты линейной модели, а метод лассо — заданию Лапласовского априорного распределения на коэффициенты. Подробнее о байесовской статистике вы узнаете из гостевого видео, которое вас ждет в конце этого урока. Задача гребневой регрессии имеет аналитическое решение. К матрице X транспонированное X, которая обращается в методе наименьших квадратов, вы добавляете диагональную матрицу, у которой на диагонали стоят значения λ — веса при регуляризаторе. Для решения задачи лассо аналитического решения не существует. Однако есть очень эффективный численный способ получения решения, поэтому методом лассо тоже можно прекрасно пользоваться. Итак, в этом видео мы поговорили про регуляризацию как один из способов борьбы с переобучением линейных регрессионных моделей. Регуляризация приводит к тому, что вы получаете смещенные оценки коэффициентов модели, но суммарная ошибка таких моделей может быть меньше за счет того, что оценки коэффициентов имеют меньшую дисперсию. Это справедливо и для L1, и L2-регуляризации, однако про L1-регуляризацию мы еще выяснили, что она отбирает признаки, обнуляя веса у некоторых коэффициентов, и разобрались в том, почему так происходит. В следующем видео мы поговорим про логистическую регрессию.

Из этого видео вы узнаете, что такое логистическая регрессия, для чего она нужна и как работает. Логистическая регрессия – это метод обучения с учителем. Имея обучающую выборку по признаковому описанию объектов, вы пытаетесь предсказать значение отклика. Единственное отличие от задач линейной регрессии, которые мы рассматривали до этого, в том, что значение отклика у нас бинарное, то есть y принимает значение 0 и 1. На первый взгляд кажется, что это задача бинарной классификации, ее можно решать своими методами, которые мы рассматривали до этого в этом курсе. Однако оказывается, что линейная регрессия в этой задаче тоже может быть полезна. Если мы будем просто минимизировать среднеквадратичную ошибку между откликом y и линейной комбинацией факторов x, мы получим вектор весов w*, и можем мы его использовать следующим образом: если значение линейной комбинации факторов на объекте больше, чем 1/2, мы будем предсказывать, что наш объект будет относиться к классу 1; если меньше 1/2, то он будет относиться к классу 0. Этот метод называется методом линейного дискриминанта Фишера, и это один из самых старых методов классификации. На самом деле, мы можем хотеть предсказывать не просто метки классов на наших объектах, а вероятности того, что объекты относятся к одному из классов. Обозначим условную вероятность того, что y = 1 при условии x, за π(x). Вот эту функцию π(x) мы и хотим как-то оценить. Можно попробовать делать это с помощью обычной линейной регрессии. На первый взгляд кажется, что эта идея не самая плохая. Дело в том, что π(x), поскольку y – величина бинарная, совпадает с условным матожиданием, y при условии x. Это внушает нам надежду, что обычная минимизация методом наименьших квадратов может дать какую-то хорошую оценку. Проблема здесь заключается в том, что получаемая линейная комбинация факторов не обязательно лежит на отрезке от 0 до 1. Представьте, что вы предсказываете вероятность невозврата платежа по кредитной карте в зависимости от размера задолженности. Если на такие данные вы настроите линейную регрессию, вы получите, что при задолженности в 2000 долларов вероятность того, что клиент просрочит платеж по кредиту, составляет примерно 0,2. С другой стороны, вероятность того, что клиент просрочит платеж по кредиту при задолженности в 500 долларов, равна нулю. Это немного странно. Еще более странно, если задолженность составляет меньше 500 долларов, вероятность просрочки отрицательная. Если клиент должен больше 10000 долларов, вероятность больше 1. Это очень странный результат, совершенно непонятно, как его интерпретировать. Решить эту проблему можно следующим образом. Давайте возьмем какую-то функцию g, которая переводит интервал от 0 до 1 на множество всех действительных чисел, и построим оценку не для условного матожидания, как мы привыкли в линейной регрессии, а для функции g от этого условного матожидания, или, что то же самое, условное матожидание мы будем приближать обратной функцией к g, к g в минус первой, от нашей линейной комбинации факторов. Такое семейство моделей в статистике называется обобщенными линейными моделями. В задаче бинарной классификации в качестве функции g в минус первой берется функция, которая выглядит следующим образом: это сигмоида. Для одномерного случая значение w0, константа, определяет положение центра сигмоиды на числовой оси, а w1, вес при единственном факторе, определяет форму этой сигмоиды. Если вес w1 положительный, то сигмоида возрастающая, если отрицательный, то убывающая. Чем больше по модулю значение w1, тем круче наклон сигмоиды в области ее середины. Если мы возьмем сигмоиду и построим логистическую регрессию в задаче с вероятностью невозврата кредита, мы получим что-то более вменяемое. Наша вероятность будет принимать значение от 0 до 1, как мы и хотели. Кроме того, полезное свойство заключается в том, что изменение на краях диапазона значений признака x приводит к меньшим изменениям вероятности, которую мы моделируем. Это логично, изменение в плюс-минус 100 долларов при размере задолженности около 2000 приводит к большим изменениям вероятности просрочки платежа по кредитной карте, а изменение в плюс-минус 100 долларов при размере задолженности около 500 – к небольшим изменениям. Чтобы получить саму функцию g обобщенной линейной модели, мы произведем несложные арифметические преобразования выражения для π(x), которое мы записали до этого, и получим следующую функцию. Дробь, которая стоит здесь под логарифмом, представляет собой отношение вероятности того, что y = 1, к вероятности того, что y = 0, вероятности эти условные по x. Это отношение называется риском. Вместе с логарифмом это выражение называется логит. Именно поэтому метод называется логистической регрессии, потому что мы приближаем логит линейной комбинации наших факторов. Как эту модель можно настраивать? Давайте будем делать это методом максимизации правдоподобия. Запишем выражение для правдоподобия обучающей выборки и сразу для удобства возьмем от правдоподобия логарифм. Если мы поставим перед логарифмом знак минус, то получившуюся функцию мы будем не максимизировать, а минимизировать. Это немного более привычно, поскольку мы привыкли минимизировать функции потери в задачах регрессии. Такой функционал называется еще log-loss, или кросс-энтропия, у него много названий. Если мы переобозначим нулевой класс за минус первый, то путем несложных преобразований можно получить логистическую функцию потерь, которую вы уже встречали до этого. Задача максимизации правдоподобия в логистической регрессии очень хорошо решается числами, поскольку эта функция выпуклая, она имеет единственный глобальный максимум. Кроме того, мы можем очень хорошо оценивать ее градиент и гессиан. Проблемы возникают, только если наши объекты разных классов линейно разделимы в пространстве признаков. Представьте, например, что в вашей обучающей выборке все клиенты, задолженность которых составляет меньше 1300 долларов, платеж вовремя вернули, а все клиенты, задолженность которых больше 1400, платеж не вернули. В этом случае максимизация правдоподобия приводит к тому, что значение веса w1 при нашем признаке уходит в бесконечность. Вместо сигмоиды мы получаем вот такую ступеньку. Это плохо, поскольку мы переобучаемся на нашу обучающую выборку. Чтобы решить эту проблему, можно использовать методы регуляризации, о которых мы говорили до этого: можно использовать как l1, так и l2 регуляризацию. Вероятности, которые дает логистическая регрессия, можно использовать для классификации, для предсказания итоговых меток классов. Для этого нужно на вероятность, которую мы оцениваем, в каком-то месте поставить порог p0, и при значении вероятности выше порога предсказывать метку y = 1, а ниже порога – y = 0. Интуитивно кажется, что лучше всего выбирать порог = 1/2. На самом деле этот порог p0 можно подбирать для каждой задачи отдельно так, чтобы обеспечить оптимальный баланс между точностью и полнотой классификатора. Итак, в этом видео мы поговорили о логистической регрессии, мы узнали, что это регрессионный метод, позволяющий предсказывать вероятность того, что y = 1, по каким-то факторам x. В логистической регрессии используется линейная модель для логита, для логарифма отношения вероятностей y = 1 при условии x и y = 0 при условии x. Оценка параметров логистической регрессии делается методом максимального правдоподобия. Вот и все. Далее в программе вас ждет знакомство с некоторыми важными техническими трюками, которые часто используются при настройке линейных моделей.

Линейные модели: статистический
взгляд
5.1. Задача регрессии
5.1.1. История термина
Впервые термин регрессия появился в конце XIX века в работе Френсиса Гальтона:
В этой работе «Регрессия к середине в наследственности роста» Френсис Гальтон исследовал зависимость
между средним ростом детей и средним ростом их родителей и обнаружил, что отклонение роста детей от
среднего составляет примерно 2/3 отклонения роста родителей от среднего. Казалось бы, со временем люди
должны рождаться все ближе и ближе к среднему росту. На самом деле, естественно, этого не происходит.
1
Лучше понять эффект регрессии к среднему позволяет другое творение
Френсиса Гальтона, которое называется машина, или доска, Гальтона.
Это механическая машина, в которой сверху в центральной части находятся шарики. Когда открывается заслонка, шарики начинают постепенно
сыпаться вниз, ударяясь о штырьки, которые расположены на одинаковом
расстоянии друг от друга. При каждом соударении шарика со штырьком вероятности того, что он упадет налево и направо от штырька, равны. Постепенно шарики начинают собираться в секциях внизу в гауссиану, или плотность нормального распределения.
Чтобы понять эффект регрессии к среднему, давайте мысленно подставим к машине Гальтона снизу еще
одну такую же машину. Если теперь убрать перегородку, которая удерживает шарики в верхней половине, они
начнут постепенно осыпаться вниз и сформируют внизу еще одну такую же гауссиану. Если зафиксировать
какой-то конкретный шарик в нижней половине ближе к краю, то откажется, что с достаточно большой
вероятностью этот шарик пришел не из ячейки, которая находится в верхней половине прямо над ячейкой,
в которой он оказался внизу, а от ячейки ближе к середине. Это происходит просто потому, что в середине
шариков больше.
Эффект регрессии к среднему проявляется во многих практических задачах. Например, если дать студентам очень сложный тест, большую роль в том, насколько хорошо они его пройдут, будут играть не только
их знания по предмету, но и везение, то есть случайный фактор. Поэтому, если изолировать 10% студентов,
которые прошли тест лучше всех (набрали больше всего баллов) и дать им еще один вариант теста, то средний балл в этой группе скорее всего упадет. Просто потому что люди, которым повезло в первый раз, скорее
всего уже не будут так удачливы во второй — в этом и состоит эффект регрессии к середине.
Френсис Гальтон был основоположником дактилоскопии, исследовал явление синестезии, внес существенный вклад в метеорологию, впервые описав циклоны и антициклоны, а также, например, изобрел ультразвуковой свисток для собак. Но именно регрессия и по сей день остается одним из наиболее важнейших
инструментов, к которому он приложил руку.
5.1.2. Регрессия
Чаще всего под регрессией понимают минимизацию среднеквадратичной ошибки: квадратов отклонений откликов y от их предсказанных значений a(x).
Q(w, X) = 1
`
X
`
i=1
(hw, xii − yi)
2
−1.5 −1 −0.5 0 0.5 1 1.5
0
0.5
1
1.5
2
2.5
a(xi) − yi
Q(a, x)
Поскольку минимизируется сумма квадратов отклонений, этот метод называется методом наименьших
квадратов (сокращенно МНК). Для линейной регрессии задача имеет аналитическое решение.
w∗(x) = argminw Q(w, X) = (XT X)
−1XT
y.
2
Именно этим частично объясняется популярность среднеквадратичной ошибки.
В XIX веке, когда эта задача впервые возникла, никакого способа ее решения, кроме аналитического, быть
не могло. Сейчас можно численно минимизировать не только среднеквадратичную ошибку, но и, например,
среднюю абсолютную, то есть сумму модулей отклонений нашей модели от отклика:
Q(a, X) = 1
`
X
`
i=1
|a(xi) − yi
| , a∗(x) = argmina Q(a, X).
−1.5 −1 −0.5 0 0.5 1 1.5
0
0.5
1
1.5
a(xi) − yi
Q(a, x)
Такая задача является частным случаем класса задач квантильной регрессии.
5.2. Метод максимизации правдоподобия
Пусть x — некоторая случайная величина с функцией распределения F(x, θ), которая зависит от неизвестного
параметра θ, а Xn = (X1, ..., Xn) — выборка размера n, сгенерированная из распределения F(x, θ). Необходимо
оценить по данной выборке неизвестный параметр.
5.2.1. Метод максимизации правдоподобия: пример
Чтобы понять метод максимального правдоподобия, можно рассмотреть еще один исторический пример. Эти
данные собраны в конце XIX века. В Генеральный штаб прусской армии ежегодно в течение 20 лет от десяти
кавалерийских корпусов поступали данные о количестве смертей кавалеристов в результате гибели под ними
коня.
Кол-во погибших 0 1 2 3 4 5 Всего
Кол-во донесений 109 65 22 3 1 0 200
Поскольку данная случайная величина — счетчик, ее необходимо моделировать распределением Пуассона,
функция вероятности которого имеет вид:
P(X = k) = λ
k
e
−λ
k!
Поскольку выборка состоит из независимых, одинаково распределенных случайных величин, вероятность
получения строго определенной выборки равна произведению вероятностей получения каждого из элементов
этой выборки:
P(Xn
, λ) = Yn
i=1
λ
Xi e
−λ
Xi
!
≡ L(Xn
, λ).
3
Функция L зависит от неизвестного параметра λ и называется правдоподобием выборки. В качестве оценки
для λ можно взять такое значение, которое максимизирует функцию правдоподобия:
λˆ
ОМП = argmaxλ L(XN , λ)
Эта оценка называется оценкой максимального правдоподобия.
Несложно показать, что в рассматриваемой задаче оценка максимального правдоподобия для параметра
λ совпадает с выборочным средним:
λˆ
ОМП = X¯
n = 0.61
Чтобы это сделать, можно взять производную от логарифма функции правдоподобия и приравнять ее к нулю.
Здесь используется тот факт, что логарифмирование L не меняет точку максимума функции.
5.2.2. Метод максимизации правдоподобия: общий вид
В общем виде метод максимума правдоподобия записывается следующим образом. Пусть некоторая случайная величина x имеет распределение F(x, θ), Xn — выборка размера n:
X ∼ F(x, θ), Xn = (X1, ..., Xn),
Тогда функция правдоподобия имеет вид:
L(Xn
, λ) = Yn
i=1
P(X = Xi
, θ).
Поскольку при логарифмировании не меняются положения максимумов функции, удобно работать не с самим
правдоподобием, а с логарифмом правдоподобия:
lnL(Xn
, λ) = Xn
i=1
ln P(X = Xi
, θ).
Оценкой максимального правдоподобия называется величина:
λˆ
ОМП = argmaxλ
lnL(XN , λ)
В случае непрерывной случайной величины метод максимального правдоподобия записывается аналогично:
X ∼ F(x, θ), L(Xn
, λ) = Yn
i=1
f(X = Xi
, θ), λˆ
ОМП = argmaxλ L(XN , λ).
5.2.3. Свойства метода максимального правдоподобия
Метод максимального правдоподобия обладает рядом очень полезных свойств:
• Состоятельность, то есть получаемые оценки при увеличении объема выборки начинают стремиться к
истинным значениям:
λˆ
ОМП → θ при n → ∞.
• Асимптотическая нормальность, то есть с ростом объема выборки, оценки максимального правдоподобия все лучше описываются нормальным распределением с средним, равным истинному значению θ, и
дисперсией, равной величине, обратной к информации Фишера:
λˆ
ОМП ∼ N

θ, I−1
(θ)

при n → ∞.

5.3. Регрессия как максимизация правдоподобия
5.3.1. Модель шума: нормальное распределение
При решении задачи регрессии значение отклика приближается в виде
y = a(x) + ε,
где a(x) — регрессионная функция, а компонента ε описывает случайный шум.
Если этот случайный шум имеет нормальное распределение с нулевым средним и дисперсией σ
2
, оказывается, что задача минимизации среднеквадратичной ошибки
a∗ = argmina
1
`
X
`
i=1
(a(xi) − yi)
2
дает оценку максимального правдоподобия для регрессионной функции a(x).
Этот факт позволяет использовать в задаче с регрессии свойства метода максимального правдоподобия.
Например, используя асимптотическую нормальность, можно определять значимость признаков x
j в модели
и делать их отбор. Также можно строить доверительные интервалы для значения отклика на новых объектах,
которых нет в обучающей выборке.
5.3.2. Модель шума: распределение Лапласа
Распределение шума не обязательно должно быть нормальным и может быть каким-то другим. Например,
можно попытаться описать его распределением Лапласа с нулевым средним. Формула для функции плотности
вероятности такого распределения:
f(x) = α
2
e
−α|x|
.
−4 −2 2 4
0.1
0.2
0.3
0.4
0.5
x
f(x)
Нормальное
Лапласа
Рис. 5.1: График функции Лапласа с нулевым средним и нормального распределения.
По сравнению с нормальным распределением, распределение Лапласа имеет более тяжелые хвосты, то
есть для него более вероятны большие значения ε. Другими словами, если моделировать шум распределением
Лапласа, то наблюдения могут сильнее отклоняться от выбранной модели. За счет этого получается решение,
которое более устойчивое к выбросам. Оказывается, что если шум действительно описывается распределением
Лапласа, то к оценке максимального правдоподобия приводит минимизация средних абсолютных отклонений:
a∗ = argmina
1
`
X
`
i=1
|a(xi) − yi
|.
5
5.4. Регрессия как оценка среднего
5.4.1. Среднеквадратичная ошибка
Пусть для начала a — константа (что соответствует ситуации, когда отсутствуют признаки), а y является
случайной функцией с плотностью распределения f(t). В таком случае среднеквадратичная ошибка имеет
вид:
Q(a) = Z
t
(a − t)
2
f(t)dt.
Нетрудно показать, что:
a∗ = argmina Q(a) = Ey,
то есть наилучшая константа, которая аппроксимирует значение y в смысле среднеквадратичной ошибки —
это математическое ожидание.
Если a(x) — произвольная функция признаков x, функционал среднеквадратичной ошибки имеет вид:
Q(a, X) = Z
t
(a(x) − t)
2
f(t)dt,
а его минимум будет доставлять условное математическое ожидание:
a∗(x) = argmina Q

a(x)

= E(y|x).
Таким образом, в случае с конечной выборкой:
Q(a(x), X) = 1
`
X
`
i=1
(a(xi) − yi)
2
,
оценка, получаемая при минимизации среднеквадратичной ошибки:
a∗(x) = argmina Q(a, X)
является лучше аппроксимацией условного математического ожидания E(y|x). В случае линейной регрессии,
то есть когда отклик моделируется линейной комбинацией hw, xii:
Q(w, X) = 1
`
X
`
i=1
(hw, xii − yi)
2
, w∗ = argminw Q(w, X),
выражение hw∗, xii является наилучшей линейной аппроксимацией условного математического ожидания E(y|x).
Полученный результат согласуется с интуитивными представлениями. Действительно, пусть yi = 2, график зависимости ошибки на этом объекте в зависимости от предсказания алгоритма a(x) выглядит следующим образом.
1 2 3 4
a(xi)
0
yi = 2
Рис. 5.2: Зависимость ошибки от предсказания алгоритма в случае среднеквадратичной ошибки.
По графику видно, что одинаково штрафуются отклонения предсказания как в большую, так и в меньшую сторону от истинного значения yi
. Поэтому не удивительно, что функция, которая доставляет минимум
функции, представляет собой какое-то среднее.

5.4.2. Дивергенции Брегмана
Однако оказывается, что условное математическое ожидание доставляет минимум не только среднеквадратичной ошибки, но и более широкого класса функций потерь, которые называются дивергенциями Брегмана.
Дивергенции Брегмана порождаются любой непрерывной дифференцируемой выпуклой функцией ϕ:
Q(a, X) = ϕ(y) − ϕ(a(X)) − ϕ
0
(a(X))(y − a(X)).
Среднеквадратичная ошибка является частным случаем дивергенции Брегмана. Минимизируя любую дивергенцию Брегмана, мы получаем оценку для условного математического ожидания:
a∗ = argmina Q(a, X) — лучшая аппроксимация E(y|x).
1 2 3 4
a(xi)
0
yi = 2
1 2 3 4
a(xi)
0
yi = 2
Рис. 5.3: Несколько функции потерь из класса дивергенций Брегмана.
Этот результат уже является несколько странным, поскольку в семействе дивергенций Брегмана можно найти, в том числе, несимметричные относительно y функции. Такие функции больше штрафуют за отклонение
модели в большую или меньшую сторону. Это результат может быть несколько контринтуитивным и получен
не так давно.
5.4.3. Средняя абсолютная ошибка и несимметричная абсолютная ошибка
Средняя абсолютная ошибка:
Q(a, X) = 1
`
X
`
i=1
|a(xi) − yi
|
не входит в семейство дивергенций Брегмана. При ее минимизации получается оценка не условного математического ожидания, а оценка условной медианы:
a∗ = argmina Q(a, X) — лучшая аппроксимация med(y|x).
1 2 3 4
a(xi)
0
yi = 2
1 2 3 4
a(xi)
0
yi = 2
Рис. 5.4: Графики симметричной средней абсолютной и несимметричной абсолютной функций ошибок.
7
Несимметричная абсолютная функция ошибки («несимметричность» определяется параметром τ ):
Q(a, X) = 1
`
X
`
i=1

(τ − 1)
yi < a(xi)

+ τ

yi ≥ a(xi)
 (yi − a(xi))
имеет в некотором смысле наклоненный график по сравнению с графиком симметричной абсолютной ошибки.
При минимизации такого функционала получается лучшая оценка для соответствующего условного квантиля:
a∗ = argmina Q(a, X) — лучшая аппроксимация y|x порядка τ.
5.5. Регуляризация
5.5.1. Переобучение регрессионных моделей
Если используется слишком сложная модель, а данных недостаточно, чтобы точно определить ее параметры,
эта модель легко может получиться переобученной, то есть хорошо описывать обучающую выборку и плохо
— тестовую. Бороться с этим можно различными способами:
• Взять больше данных. Такой вариант обычно недоступен, поскольку дополнительные данные стоят
дополнительных денег, а также иногда недоступны совсем. Например, в задачах веб-поиска, несмотря на наличие терабайтов данных, эффективный объем выборки, описывающей персонализированные
данные, существенно ограничен: в этом случае можно использовать только историю посещений данного
пользователя.
• Выбрать более простую модель или упростить модель, например исключив из рассмотрения некоторые признаки. Процесс отбора признаков представляет собой нетривиальную задачу. В частности, не
понятно, какой из двух похожих признаков следует оставлять, если признаки сильно зашумлены.
• Использовать регуляризацию. Ранее было показано, что у переобученной линейной модели значения
весов в модели становятся огромными и разными по знаку. Если ограничить значения весов модели, то
с переобучением можно до какой-то степени побороться.
5.5.2. L1-регуляризация и L2-регуляризация
Есть несколько способов провести регуляризацию:
• L2-регуляризатор (ridge-регрессия или гребневая регрессия):
w∗ = argminw


1
`
X
`
i=1
(hw, xii − yi)
2 + λ
X
d
j=1
w
2
j

 .
• L1-регуляризатор (lasso-регрессия или лассо-регрессия):
w∗ = argminw


1
`
X
`
i=1
(hw, xii − yi)
2 + λ
X
d
j=1
|wj |

 .
Понять различия между L1 и L2 регулязаторами можно на модельном примере. Пусть матрица «объекты–
признаки» X является единичной матрицей размера ` × `:
X =


1 0 ... 0
0 1 ... 0
.
.
.
.
.
.
.
.
.
.
.
.
1 1 ... 1


.
Тогда при решении задачи линейной регрессии использование метода наименьших квадратов без регуляризации:
w∗ = argminw
X
`
i=1
(wi − yi)
2
,

дает следующий вектор весов:
w∗j = yj
При использовании гребневой регуляризации (L2–регуляризация) компоненты вектора весов имеют вид:
w∗j =
yj
1 + λ
,
а при использовании L1–регуляризатора (lasso):
w∗j =



yj − λ/2, yj > λ/2
yj + λ/2, yj < −λ/2
0, |yj | ≤ λ/2.
При использовании только МНК без регуляризации w∗j = yj . Соответствующая линия изображена пунктиром на обоих графиках. При использовании L2 регуляризации зависимость w∗j от yj все еще линейная,
компоненты вектора весов ближе расположены к нулю.
yj
w∗j
L2–регуляризация
yj
w∗j
L1–регуляризация
Рис. 5.5: Зависимость w∗j от значения отклика yj при использовании различных регуляризаторов.
В случае L1 регуляризации график выглядит несколько иначе: существует область (размера λ) значений
yj , для которых wj = 0. То есть lasso, или L1–регуляризация, позволяет отбирать признаки, а именно: веса
признаков, обладающих низкой предсказательной способностью, оказываются равными нулю.
5.5.3. Смещение и дисперсия
Можно показать, что математическое ожидание квадрата ошибки регрессии представляет собой сумму трех
компонент:
E (a∗(x) − y)
2 = (Ea∗(x) − a(x))2
| {z }
Квадрат смещения
+ Da∗(x)
| {z }
Дисперсия оценки
+ σ
2
|{z}
Шум
.
От выбора модели зависит квадрат смещения и дисперсия оценки, но не шум, который является свойством
данных, а не модели.
Метод наименьших квадратов дает оценки, которые имеют нулевое смещение. Регуляризация позволяет
получить смещенные оценки с меньшим E (a∗(x) − y)
2
за счет того, что у этой оценки будет меньше дисперсия.
Следующая аналогия позволяет лучше понять баланс между смещением и дисперсией. При стрельбе по
мишени среднее число набранных очков зависит от положения средней точки попадания и разбросом относительно этого среднего.
9
небольшая большая
Дисперсия
небольшое большое
Смещение
Рис. 5.6: Дисперсия и смещения при различных характерах стрельбы.
Лучший результат будет, если стрелять без смещения и без разброса. Переобучению линейных моделей
соответствует стрельба без смещения, но с огромным разбросом. И часто оказывается, что можно набрать
больше очков, стреляя не совсем в цель, то есть со смещением, но зато более точно. Именно это и позволяет
добиться регуляризация.
5.5.4. Решение задач гребневой регрессии и лассо
В байесовской статистике гребневая регрессия соответствует заданию нормального априорного распределения
на коэффициенты линейной модели, а метод лассо — заданию Лапласовского априорного распределения.
Подробнее о байесовской статистике написано в соответствующем уроке.
Задача гребневой регрессии имеет аналитическое решение:
w∗ =

XT X + λI−1
XT
y.
Для решения задачи лассо аналитического решения не существует, однако есть очень эффективный численный способ получения решения.
5.6. Логистическая регрессия
5.6.1. Логистическая регрессия
Пусть X — пространство объектов, Y — пространство ответов, X = (xi
, yi)
`
i=1 — обучающая выборка, x =
(x
1
, ..., xd
) — признаковое описание.
Логистическая регрессия – это метод обучения с учителем в задаче бинарной классификации Y = {0, 1}.
1
5.6.2. Метод линейного дискриминанта Фишера
Метод линейного дискриминанта Фишера, один из самых старых методов классификации, заключается в
минимизации среднеквадратичной ошибки:
Q(w, X) = 1
`
X
`
i=1
(hw, xii − yi)
2
.
В результате получается вектор весов:
w∗ = argmina Q(w, X),
причем, если для некоторого объекта hw, xii > 0.5, объект относится к первому классу y = 1, в ином случае
— к нулевому y = 0. На самом деле, хочется предсказывать не просто метки классов, а вероятности того, что
объекты относятся к какому-то из классов:
P(y = 1|x) ≡ π(x).
Хотя π(x) совпадает с условным математическим ожиданием E(y|x):
π(x) = 1 · P(y = 1|x) + 0 · P(y = 0|x) = E(y|x),
использовать для оценки вероятности обычную линейную регрессию
π(x) ≈ hw, xi
не получится: получаемая линейная комбинация факторов не обязательно лежит на отрезке от 0 до 1.
Пусть, например, решается следующая задача. Необходимо предсказать вероятность невозврата платежа
по кредитной карте в зависимости от размера задолженности.
Рис. 5.7: Применение линейной регрессии в задаче оценки вероятности просрочки платежа.
По обучающей выборке была настроена модель линейной регрессии. Получается, что при задолженности
2000$ вероятность просрочить платеж по кредиту равна 0.2, при задолженности 500$ — нулю, а при меньших
значениях и вовсе отрицательная. Также, если задолженность больше 10000$, вероятность просрочки будет
больше 1. Не понятно, как интерпретировать этот результат.
5.6.3. Обобщенные линейные модели
Пусть функция g : (0, 1) 7→ R переводит интервал (0, 1) на множество всех действительных чисел, тогда
можно решать задачу линейой регрессии:
g (E(y|x)) ≈ hw, xi,
в которой строится оценка не для условного матожидания E(y|x), а для g (E(y|x)). Что то же самое:
E(y|x) ≈ g
−1
(hw, xi)
11
В статистике такое семейство моделей называется обобщенными линейными моделями.
В задаче бинарной классификации в качестве g
−1 используется сигмоида:
π(x) ≈
e
hw,xi
1 + e
hw,xi
.
В одномерном случае значение параметр w0 сигмоиды определяет положение её центра на числовой оси, а
w1 — форму это сигмоиды:
• Если w1 > 0, сигмойда возрастающая:
0
0.2
0.4
0.6
0.8
1
x
π(x)
• Если w1 < 0, сигмоида убывающая:
0
0.2
0.4
0.6
0.8
1
x
π(x)
Чем больше по модулю значение w1, тем круче наклон сигмоиды в области ее середины.
5.6.4. Предсказание вероятностей
Если использовать сигмоиду:
π(x) ≈
e
hw,xi
1 + e
hw,xi
в обобщенной линейной модели в задаче логистической регрессии, результат будет более адекватным:
• Вероятность π(x) ∈ [0, 1], как и требуется.
12
• На краях области значений x функция (вероятность) π(x) слабо меняется при небольших изменениях
x, когда как существенно изменяется, если x находится в середине диапазона своих значений.
Рис. 5.8: Применение логистической регрессии в задаче оценки вероятности не вернуть задолженность.
Последнее свойство является весьма полезным. Например, в уже рассмотренной задаче при размере задолженности в районе 2000$ оценка вероятности просрочки платежа сильно изменяется при увеличении или
уменьшении задолженности на 100$. С другой стороны при размере задолженности в 500$ увеличение задолженности на 100$ приводит только к незначительным изменениям требуемой оценки.
5.6.5. Оценка параметров
По функции π(x) можно восстановить функцию g, которая фигурирует в определении обобщенной линейной
модели:
π(x) ≈
e
hw,xi
1 + e
hw,xi ⇐⇒ hw, xi ≈ ln
Риск
z }| {
π(x)
1 − π(x)
| {z }
Логит
.
Отношение, стоящее под логарифмом, называется риском, а весь логарифм называется «логит». Именно
поэтому метод называется логистической регрессией: логит приближается линейной комбинацией факторов.
Настройка модели происходит методом максимизации правдоподобия L(X). Удобнее однако не максимизировать правдоподобие, а минимизировать минус логарифм от правдоподобия:
− lnL(X) = −
X
`
i=1

yi
ln π(xi) + (1 − yi)ln(1 − π(xi))
Такой функционал также имеет названия log-loss, кросс-энтропия и другие.
Если изменить метку нулевого класса на −1, то получится логистическая функция потерь в таком виде,
в котором она встречалась в курсе до этого:
Q(w, X) = X
`
i=1
ln (1 + exp (−yihw, xi))
5.6.6. Решение задачи максимизации правдоподобия
Задача максимизации правдоподобия в логистической регрессии очень хорошо решается численно, поскольку
правдоподобие — выпуклая функция, а следовательно, она имеет единственный глобальный максимум. Кроме
того, ее градиент и гессиан могут быть хорошо оценены.
Если объекты из разных классов линейно разделимы в пространстве признаков, возникает проблема переобучения: сигмоида вырождается в «ступеньку».
13
Рис. 5.9: Проблема переобучения в задаче логистической регрессии.
Например, такая ситуация возникает, если в уже упомянутой задаче оценки вероятности вернуть задолженность обучающая выборка такова, что все клиенты с задолженностью менее 1300$ вернули платеж
вовремя, а все клиенты с задолженностью более 1300$ — нет.
В этом случае максимизация правдоподобия приводит к тому, что kwk → ∞. В таких случаях необходимо
использовать методы регуляризации, например L1 или L2 регуляризатор.
5.6.7. Предсказание отклика
Вероятности, которые дает логистическая регрессия, можно использовать для классификации, то есть для
предсказания итоговых меток классов. Для этого выбирается порог p0 и объект относится к классу 1 только
в случае π(x) > p0. В остальных случаях объект относится к классу 0.
Порог p0 не следует выбирать всегда равным 0.5, как это может показаться из интуитивных соображений. Его необходимо подбирать для каждой задачи отдельно таким образом, чтобы обеспечить оптимальный
баланс между точностью и полнотой классификатора.
Практические рекомендации по линейным моделям

Мы начинаем урок, в котором обсудим различные особенности, с которыми вы можете столкнуться при применении линейных моделей к реальным задачам. И первый аспект, о котором мы поговорим, это масштабирование признаков. Давайте начнем с простого примера, на котором поймём необходимость масштабирования. Представьте, что нам нужно найти минимум простой функции w1²+ w2². В общем-то понятно, что минимум достигается в точке (0, 0), но давайте посмотрим, что будет, если мы воспользуемся градиентным спуском для минимизации этой функции. Её линии уровня выглядят как-то так. Это круги. Поскольку переменные в этой функции симметричны, можно поменять местами w1 и w2, то линии уровня тоже симметричные. Если вы решите запустить градиентный спуск из точки (1, 1), то вектор антиградиента будет смотреть влево и вниз, а его координаты равны (-2, -2). Этот вектор проходит через точку минимума (0, 0). Если вы подберёте правильный размер шага при этом антиградиенте, то уже на первом шаге градиентного спуска попадёте строго в точку минимума этой функции. Градиентный спуск будет хорошо работать на этой функции. Давайте теперь немного её изменим. Добавим перед слагаемым w2² коэффициент 100. В этом случае функционал будет выглядеть вот так. Он уже несимметричный. Перед переменной w2 стоит большой коэффициент. В этом случае линии уровня будут выглядеть вот так. Это уже эллипсы, сильно вытянутые вдоль оси x, поскольку перед второй переменной стоит большой коэффициент, изменение по ней при небольшом изменении w2 гораздо сильнее. Если мы, опять же, запустим градиентный спуск из точки (1, 1), то вектор антиградиента в этой точке будет иметь координаты -2 и -200, он будет смотреть практически строго вниз и проходить мимо точки минимума функции. Если вы сделаете шаг у этого вектора, то промахнётесь, и у вас есть шанс стать ещё дальше от минимума, чем вы были в начальном приближении. Градиентный спуск будет иметь большие проблемы, если вы запустите его на этой функции. Итак. Градиентный спуск работает хорошо, если линии уровня функции похожи на круги, как на этом примере. В этом случае, откуда бы вы ни начали, вектор антиградиента будет смотреть в сторону минимума функции и будет сходиться довольно быстро. Если же линии уровня вот такие, то градиентный спуск будет иметь проблемы. Направление антиградиента будет слабо совпадать с направлением в сторону минимума функции, и градиентный спуск будет делать много лишних шагов. Его сходимость будет медленная. И более того, есть риск расхождения градиентного спуска, если размер шага будет подобран неправильно. Вот ещё один пример. Представьте, что у вас есть некая заявка на грант, и вам нужно предсказать, будет ли выдан грант по этой заявке, будет ли она одобрена. И представьте, что у вас есть два признака. Первый признак говорит, сколько уже успешных заявок было у данного заявителя. Понятно, что если много его предыдущих заявок было одобрено, у него большой опыт, у него хорошо получается писать заявки, и данная, скорее всего, тоже будет одобрена. Второй признак — это год рождения заявителя. Масштабы у этих признаков очень разные. Число одобренных грантов — это, скорее всего, единицы, а год рождения — это тысячи. У них разный масштаб. И из-за этого линии уровня функции будут скорее выглядеть как вытянутые эллипсы, чем как круги. Именно различие в масштабе признаков приводит к тому, что линии уровня не похожи на круги. Чтобы бороться с этой проблемой, чтобы у градиентного спуска не было никаких плохих нюансов при применении к таким выборкам, признаки нужно масштабировать, то есть приводить к одному масштабу. Мы разберём два способа масштабирования. И первый из них называется нормализацией. Итак. Представьте, что мы хотим отмасштабировать j-тый признак. В этом случае нам нужно сначала вычислить две вспомогательные величины: среднее значение этого признака и стандартное отклонение этого признака. Для вычисления среднего мы просто суммируем значение этого признака на всех объектах обучающей выборки, и делим на размер выборки. Чтобы вычислить стандартное отклонение, мы суммируем квадраты отклонений значений этого признака на объектах обучающей выборки от среднего значения μj. И делим на число объектов обучающей выборки, после чего извлекаем корень. После этого нам известны среднее значение μj-тое и стандартное отклонение σj-тое. Теперь, чтобы отмасштабировать признак, мы берём каждое его значение, например на i-том объекте xij-тое, вычитаем из него среднее μj-тое и делим на стандартное отклонение σj-тое. После этих операций мы уберём сдвиги и различия в масштабах у всех признаков, и они будут иметь примерно одинаковый масштаб. Второй подход называется масштабированием на отрезок [0, 1]. В этом случае нам нужно тоже вычислить две вспомогательные величины, но немного другие. Это будут минимальное и максимальное значение данного признака на всей обучающей выборке. Минимальное значение обозначаем буквой mj-тое, максимальное значение буквой Mj-тое. После того, как они найдены, мы берём значение данного признака на конкретном объекте, вычитаем из него минимальное значение данного признака и делим на разность между максимальным и минимальным значением данного признака. После такого преобразования минимальное значение признака будет отображено в ноль, максимальное в единицу. Получается, что данный признак отмасштабирован на отрезок [0, 1]. Итак. Мы с вами обсудили, что различия в масштабах признаков — это очень плохо, применение градиентного спуска к таким выборкам может привести к его очень плохой сходимости или даже к его расхождению. Чтобы бороться с этим признаки нужно масштабировать. Мы обсудили два способа масштабирования признаков. Первый называется нормализацией, в котором мы вычитаем среднее и делим остаток на отклонение признака, второй — это масштабирование на [0, 1]. В следующем видео мы поговорим о том, как использовать в линейных моделях нелинейные признаки.

В этом видео мы поговорим о спрямляющих пространствах, которые позволяют восстанавливать нелинейные зависимости с помощью линейных моделей, и начнем с простого примера. Представьте, что мы решаем задачу регрессии, в которой есть всего один признак, который отложен по оси X, и по этому признаку нужно восстановить целевую переменную y, которая отложена по оси Y. Если мы попробуем применить линейную модель, то она получится вот такой. Видно, что она плохо подходит для решения задачи. Зависимость y от x явно нелинейная. Давайте теперь попробуем немножко модифицировать нашу модель. Добавим к исходному признаку x еще три признака: x², x³ и x⁴. Если мы над этими новыми признаками надстроим линейную модель, в которой будет уже 5 коэффициентов, а не 2, как было раньше, то получим вот такую модель. Видно, что она практически идеально описывает данные. Она очень хорошо решает задачу и при этом не переобучается. Получается, что мы перешли к новому признаковому пространству, в котором 4 признака, а не 1, в нем построили линейную модель, а в исходном пространстве эта модель уже нелинейная, и она очень хорошо описывает данные. А вот другой пример. Задача классификации с двумя признаками, x₁ и x₂, которые отложены по осям. Опять же видно, что разделяющая поверхность здесь вовсе не линейная. Если мы настроим линейный классификатор, он получится вот таким. Все объекты будет относить к красному классу. Это лучшее, что он может сделать, но понятно, что это никуда не годится. Опять же попробуем добавить новых признаков, а именно x₁², x₂² и x₁ * x₂, то есть квадратичные признаки. Если над ними построить линейную модель, то разделяющая поверхность в исходном пространстве будет вот такой. Она будет иметь форму окружности и очень хорошо разделять красные точки и синие точки. Опять же, в новом признаковом пространстве, имеющем большую размерность, мы построили линейную модель, и это соответствует построению нелинейной разделяющей поверхности в исходном двумерном признаковом пространстве. Таким образом, мы приходим к понятию спрямляющего пространства. Это такое признаковое пространство, в котором задача хорошо решается линейной моделью. Давайте разберем несколько примеров, как такое пространство можно отстроить. И первый пример — это добавление квадратичных признаков. Пусть объект описывается признаками x₁, ..., xd. Всего d признаков. Тогда добавим к этим признакам еще несколько, а именно квадраты исходных признаков x₁², ..., xd² и попарные произведения x₁x₂, x₁x₃ и так далее до x(d−1)xd. Заметим, что число признаков увеличится на порядок. Если у вас было не очень много объектов, то есть риск переобучения в таком большом признаковом пространстве. Нужно быть осторожным при использовании спрямляющих пространств. Если же у вас объектов много и вы не боитесь переобучения, но при этом знаете, что зависимости очень нелинейные, можно попробовать полиномиальные признаки более высоких порядков, например признаки третьего порядка. В этом случае помимо квадратичных признаков мы добавим еще кубы исходных признаков, то есть x₁³, x₂³, ..., а также произведение всех троек признаков x i-тое * x j-тое * x k-тое, где i, j и k — это какие-то индексы признаков. Также можно брать другие нелинейные функции. Например представьте, что мы используем признак «стоимость книги в интернет-магазине». Мы уже обсуждали этот пример ранее. Как мы говорили, большинство книг будут иметь стоимость в районе нескольких сотен рублей, но при этом есть очень дорогие книги. Распределение значений этого признака будет иметь тяжелый правый хвост. Это не очень хорошо для линейных моделей. Известно, что они работают гораздо лучше, если распределение признаков близко к нормальному. Чтобы сделать такое распределение тяжелых хвостов более близким к нормальному, нужно его прологарифмировать. Итак, если признак принимает только неотрицательные значения, то мы берем значение данного признака xᵢ, прибавляем к нему единицу, чтобы не взять логарифм от нуля, и берем логарифм от xᵢ + 1. После этого распределение станет более похожим на нормальное. Или же, если признак принимает как положительные, так и отрицательные значения, то можно сначала взять модуль от значения этого признака, а затем уже прибавить единицу и взять логарифм. Можно пробовать и другие нелинейные функции, но не будем об этом говорить сейчас. Итак, мы обсудили, что далеко не все задачи хорошо решаются линейными моделями. Но линейные модели можно применить к восстановлению нелинейных зависимостей, если перейти в спрямляющее пространство, то есть перейти к новым признакам, которые гораздо более сложные, чем исходные. Порождать эти признаки можно самыми разными способами, например достроить квадратичные, или кубические, или полиномиальные признаки более высоких размерностей. Или, скажем, брать логарифмы от исходных признаков. В следующем видео мы поговорим о том, как применять линейные модели к категориальным признакам.

В этом видео мы поговорим о том, как использовать категориальные признаки в линейных или других моделях. Мы уже приводили много примеров категориальных признаков. Это может быть город или цвет или, например, тарифный план у мобильного оператора или марка автомобиля. Особенность категориальных признаков в том, что это элементы некоторого неупорядоченного множества. Мы не можем говорить, что одно значение больше или меньше другого, можем только сравнивать их на равенство. А при этом в линейных моделях нам нужно брать значение признака, умножать его на вес и складывать с какими-то другими числами. Это нельзя делать со значениями категориальных признаков, их нужно как-то преобразовать, чтобы их можно было использовать в линейных моделях. Одним из наиболее популярных подходов к кодированию признаков, категориальных признаков, является бинарное кодирование. Давайте введем несколько обозначений, которые помогут нам понять, в чем оно заключается. Итак, представьте, что j-тый признак задачи категориальный. Значение j-того признака на объекте x будем обозначать, как fj (x). Допустим, он принимает n различных значений. Пронумеруем их. Обозначим эти значения, как c1, c2... cn. Чтобы закодировать данный признак, введем n новых бинарных признаков, которые обозначим, как b1 (x), b2 (x)... до bn (x). Значение i-того бинарного признака равно 1 только в том случае, если на данном объекте категориальный признак принимает значение ci. Если же он принимает какое-то другое значение, то i-тый признак будет равен 0. Таким образом, мы заменяем один категориальный признак на n бинарных, значения которых — это по сути числа, и из этих бинарных признаков единице равен только тот, который соответствует нашему значению категориального признака на этом объекте. Давайте разберем простой пример. Представьте, что j-тый признак — это цвет и он принимает три значения: синий, зеленый и красный. И у нас есть три объекта (x1, x2 и x3), на которых значение категориального признака равно «синий», «красный» и «синий», соответственно. Итак, категориальный признак принимает три значения. Нам понадобится три бинарных признака, чтобы его закодировать. Мы получим вот такую матрицу: первый столбец в ней, первый признак, соответствует значению «синий», второй — значению «зеленый», третий — значению «красный». И у нас есть три объекта, каждый из которых соответствует одной из строк. На первом и третьем объекте категориальный признак принимает значение «синий», значит, единица у них будет стоять в первом столбце. На втором объекте категориальный признак принимает значение «красный». Красный — это третий столбец, значит, единица стоит в третьем столбце. Эта матрица кодирует наш категориальный признак тремя бинарными. При этом вы можете столкнуться с такой проблемой: когда вы будете пытаться построить такое же кодирование для тестовой выборки, там может оказаться объект, на котором категориальный признак принимает новое, (n + 1)-е значение, которое вы не видели раньше на обучающей выборке. В этом случае логичным подходом будет не добавлять новый признак, это очень сложно, просто приравнять 0 все существующие признаки. Поскольку смысл наших бинарных признаков — это принимает ли категориальный признак то или иное значение от c1 до cn, то мы просто выставляем их равными 0, поскольку ни одно из них не получается на данном объекте. Итак, мы обсудили, что категориальные признаки нельзя непосредственно использовать в линейных моделях, и поговорили о том, как использовать бинарное кодирование, то есть кодирование одного категориального признака с помощью n бинарных, чтобы внедрять каким-то образом категориальные признаки в линейные модели. В следующем видео мы поговорим о том, как работать с задачами несбалансированной классификации.

В этом видео мы поговорим о том, что такое несбалансированные выборки, к каким проблемам они могут привести и как бороться с такими проблемами. Итак, представьте, что мы решаем задачу классификации с некоторой выборкой. Эта задача называется несбалансированной, если объектов одного или нескольких классов в этой выборке существенно меньше, чем объектов всех остальных классов. Например, если мы решаем задачу бинарной классификации, то есть класса всего два, то есть такое правило: выборка считается несбалансированной, если объектов одного класса 10 % или меньше от общего числа объектов выборки. Примеров задач с несбалансированными выборками довольно много. Например, представьте, что мы хотим предсказывать, случится ли на следующий день резкий скачок курса доллара. Если определение резкого скачка будет такое, что мы хотим ловить только очень сильные изменения, то примеров таких изменений за всю историю – единицы, но при этом практически каждый день – это отрицательный пример, то есть пример, когда такого скачка не было. Выборка в этом случае будет очень несбалансированной. Примеров может быть очень много: это медицинская диагностика, где больных, как правило, сильно меньше, чем здоровых, это обнаружение мошеннических транзакций по картам в банке, где примеров таких плохих транзакций существенно меньше, чем обычных транзакций, или это может быть классификация текстов, где мы пытаемся находить какие-то очень редкие классы. Основная проблема, связанная с несбалансированными выборками, в том, что практически все классификаторы пытаются минимизировать число ошибок на обучающей выборке. Они никак не учитывают цены ошибок, и может оказаться выгоднее отнести все объекты к наибольшему классу, не пытаясь как-то выделить объекты маленького класса. То есть при работе с несбалансированными выборками классификаторы могут получаться очень плохие с точки зрения точности или полноты. Мы разберем два подхода к работе с несбалансированными выборками, и первый называется undersampling. Его основная идея состоит в том, что нам не нужно много примеров объектов из больших классов, можно выкинуть часть из них. Например, представьте, что у нас есть три класса: первый — очень большой; второй — совсем маленький; и третий имеет средний размер. В этом случае мы выкинем большую часть объектов первого класса и половину объектов третьего класса. В этом случае размеры классов примерно сравняются. При этом то, сколько именно объектов каждого класса мы выбрасываем, это гиперпараметр, который имеет смысл настраивать по отложенной выборке или на кросс-валидации. Второй подход – это oversampling. Он противоположен предыдущему. Мы будем дублировать объекты маленьких классов так, чтобы выравнять соотношение классов. В нашем примере мы пять раз повторим объекты второго класса, а для третьего класса мы возьмем случайную половину объектов и продублируем их. Таким образом третий класс мы увеличим в полтора раза. В этом случае размеры выборок, размеры классов тоже выравняются. То, насколько мы будем увеличивать каждый класс, – это тоже гиперпараметр. Обратим внимание на одну особенность. Если мы решаем задачу на исходной выборке, то, например, среднеквадратичная ошибка будет выглядеть вот так. Это среднее значение квадратичной ошибки по всем объектам. Если же мы делаем oversampling, то есть дублируем какие-то объекты, то это будет означать, что какое-то слагаемое войдет в эту сумму несколько раз. Таким образом, вместо реального дублирования объектов, мы можем просто выставить соответствующие веса при каждом слагаемом. Например, если первый объект мы продублируем три раза, то мы просто выставим вес при нем равным трем, v1 будет равно 3. Обратим внимание на еще одну проблему, с которой можно столкнуться при работе с несбалансированными выборками. Напомню, что когда мы проводим кросс-валидацию, мы разбиваем исходную выборку на k блоков примерно одинаковой длины. При этом если выборка несбалансированная и, например, первого класса очень мало, то при таком разбиении может оказаться, что в некоторые блоки объекты первого класса не попадут вообще. Это будет очень плохо. Например, при обучении на этом блоке мы получим классификатор, который никогда не видел один из классов. Чтобы бороться с этим, нужно делать стратификацию. При стратификации мы строим разбиение на блоки так, чтобы распределение классов в каждом блоке примерно совпадало с распределением классов в исходной выборке. В этом случае будет гарантироваться, что объекты каждого класса будут представлены в каждом из блоков разбиения. Итак, мы обсудили, что несбалансированные выборки – это проблема, с которой можно столкнуться при решении задач классификации. В этом случае константный классификатор может оказаться лучше с точки зрения алгоритма обучения, чем какой-то разумный классификатор, выделяющий объекты маленького класса. Чтобы бороться с такой проблемой, есть несколько подходов, например oversampling и undersampling, в которых мы либо уменьшаем большие классы, либо дублируем объекты маленьких классов, чтобы как-то выравнять пропорции этих классов. Также мы поговорили, что в случае с несбалансированными выборками могут возникнуть проблемы при разбиении данных на кросс-валидацию или на обучающую и отложенную выборку. В этом случае нужно делать стратификацию, то есть стараться сохранить соотношение классов в каждой подвыборке при разбиении. В следующем видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей.

В этом видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей. Итак, как следует из названия, в задачах многоклассовой классификации — K возможных классов. Например, на этой картинке изображена выборка, у которой три класса: синий, красный и зелёный. И нужно как-то научиться отличать каждый класс от всех остальных. В случае с бинарной классификацией наш подход был довольно простой. Мы находили такой вектор весов w, что знак скалярного произведения этого вектора весов на вектор признаков говорил, к какому классу относится тот или иной объект. На самом деле, этот подход можно расширить и применить его же к задаче многоклассовой классификации. Это называется — один против всех. Мы будем строить свой бинарный классификатор для каждого класса. И задачей этого классификатора будет отделение данного класса от всех остальных. Например, на этой картинке мы можем отделить зелёные точки от всех остальных с помощью такого линейного классификатора. А красные точки от всех остальных — с помощью вот такого. Давайте поговорим об этом подходе чуть более формально. Итак, Мы будем решать K задач бинарной классификации. Рассмотрим одну из них. Допустим, мы хотим отделить класс k от всех остальных классов. В этом случае у нас будет несколько специфичная выборка. Объекты x i-тое останутся такими же, а вот ответы будут бинарными. Ответ на i-том объекте будет = 1, если этот объект относится к классу k и — 0, если он относится к какому-то другому классу. Объектов в выборке будет столько же, сколько и в условной задаче — l штук. Мы построим некоторый линейный классификатор, который отделяет k-тый класс от всех остальных. Он будет иметь вид знака скалярного произведения электровесов в w k-тое на вектор признаков x. Как мы говорили раньше, если скалярное произведение больше 0, то классификатор считает, что объект относится к классу 1. В нашем случае это будет класс k. И чем больше значение этого скалярного произведения, тем больше классификатор уверен в этом решении. Таким образом, будет логично отнести объект к тому классу, уверенность в принадлежности к которому больше всего, то есть для которого скалярное произведение w k-тое на x больше всего. Именно так и будет выглядеть итоговый многоклассовый классификатор a(x). Он будет возвращать тот класс k, для которого скалярное произведение w k-того на x больше всего. Удобно смотреть на матрицу ошибок, когда мы пытаемся проанализировать, насколько хорошо работает наш многоклассовый классификатор. Она может выглядеть вот так. Каждая строка соответствует тем объектам, который классификатор отнёс к тому или иному классу, а каждый столбец соответствует объектам, который на самом деле относится к тому или иному классу. Например, на пересечении первой строки второго столбца будет стоять число q12, которое показывает, сколько объектов второго класса наш классификатор отнёс к первому классу. Эта матрица, например, может позволить понять, какие классы мы путаем между собой чаще всего. Можно измерять и знакомые нам метрики качества. Например, долю правильных ответов или accuracy. Формула её вычисления никак не поменяется в зависимости от числа классов — два их, три или сто. Также можно измерять точность и полноту для задачи отделения того или иного класса от всех остальных классов. Если мы вычислим такие точность и полноту для каждого из классов, после этого их можно усреднить, получив такие агрегированные оценки. Или, например, можно вычислить F-меру для сдачи отделения одного класса от всех остальных и потом усреднить этот показатель по всем классам. Итак, мы обсудили, что многоклассовые задачи можно решать путём нахождения нескольких бинарных классификаторов. Этих классификаторов будет столько, сколько у нас классов в исходной задаче. При этом, например, удобно смотреть на матрицу ошибок, которая позволяет понять, какие классы мы путаем между собой чаще всего. Или можно вычислять знакомые нам метрики качества: долю правильных ответов, точность, полноту или F-меру.

Практические рекомендации по
линейным моделям
Этот урок будет посвящен сложностям, с которыми можно столкнуться при применении линейных моделей
к реальным задачам.
6.1. Масштабирование признаков
6.1.1. Пример: необходимость масштабирования
Понять необходимость масштабирования можно на следующем простом примере. Пусть необходимо найти
минимум:
w
2
1 + w
2
2 → min
w
.
Ответ в этом случае очевиден — это точка (0, 0). При поиске этого минимума методом градиентного спуска
с начальной точкой w = (1, 1), вектор антиградиента будет иметь координаты (−2, −2). Это вектор проходит
через точку минимума, а значит при правильно подобранном размере шага, уже на первом шаге градиентного
спуска можно попасть строго в точку минимума. Градиентный спуск будет хорошо работать на этой функции.
Изменим функцию:
w
2
1 + 100w
2
2 → min
w
.
В этом случае линии уровня представляют собой эллипсы, сильно вытянутые вдоль оси x. Если запустить
градиентный спуск из точки w = (1, 1), вектор антиградиента в этой точке будет иметь координаты (−2, −200).
Вектор будет смотреть почти строго вниз и проходить мимо точки минимума функции. Более того, существует
шанс на следующей итерации уйти еще дальше от минимума.
Итак, градиентный спуск работает хорошо, если линии уровня функции похожи на круги. В этом случае,
откуда бы вы не начали, вектор градиента будет всегда смотреть в сторону минимума функции, а итеративный процесс будет сходиться довольно быстро. Если же линии уровня похожи на эллипсы, направление
антиградиента будет слабо совпадать с направлением в сторону минимума функции. Градиентный спуск будет делать много лишних шагов. Сходимость будет медленная, и более того, существует риск расхождения
итеративного процесса, если размер шага будет подобран неправильно.
6.1.2. Масштабирование выборки
Пусть требуется предсказать, будет ли выдан грант по заявке. Заявка характеризуется двумя признаками —
сколько уже успешных заявок было у данного заявителя и год рождения заявителя. Масштабы этих двух
признаков существенно отличаются: количество одобренных грантов обычно меряется единицами, а год рождения — тысячами. Из-за такого различия в масштабе линии уровня функции будут выглядеть скорее как
эллипсы, а не как круги.
1
Рис. 6.1: Если масштабирование не было произведено, при использовании метода градиентного спуска будет
сделано много лишних шагов, а также существует риск расхождения итеративного процесса.
В таком случае, чтобы без проблем пользоваться градиентным спуском, признаки необходимо привести к
одному масштабу, то есть отмасштабировать. Будут рассматриваться два способа масштабирования.
Первый способ называется стандартизацией. Для начала необходимо вычислить вспомогательные величины: средние значения признаков и стандартные отклонения:
µj =
1
`
X
`
i=1
x
j
i
, σj =
vuut
1
`
X
`
i=1
(x
j
i − µj )
2
Чтобы произвести стандартизацию признака, достаточно вычесть из него его среднее значение и разделить
на его стандартное отклонение:
x
j
i
:=
x
j
i − µj
σj
После того, как это будет выполнено для всех признаков, сдвиги и различия в масштабах будут убраны.
Второй подход называется «масштабирование на отрезок [0, 1]». В этом случае также необходимо вычислить вспомогательные величины: максимальное и минимальное значение каждого признака на обучающей
выборке:
mj = min(x
j
1
, ..., x
j
`
), Mj = max(x
j
1
, ..., x
j
`
).
После этого значение каждого признака на конкретном объекте преобразовывается следующим образом:
x
j
i
:=
x
j
i − mj
Mj − mj
.
Тогда минимальное значение признака отображается в ноль, а максимальное — в 1, то есть признаки масштабируются на отрезок [0, 1].
6.2. Нелинейные зависимости
В этом разделе речь пойдет о спрямляющих пространствах, которые позволяют восстанавливать нелинейные
зависимости с помощью линейных моделей. Для начала простой пример.
6.2.1. Нелинейная задача регрессии
Пусть решается задача регрессии с одним признаком, отложенным по оси x. По этому признаку требуется
восстановить целевую переменную y.
2
Рис. 6.2: Линейная модель сама по себе не способна восстанавливать нелинейные зависимости.
Как можно в этом убедиться, непосредственное применение линейной модели не дает желаемых результатов и плохо подходит для решения данной задачи. Зависимость y от x явно нелинейная.
Поэтому, кроме признака x, также рассматриваются признаки x
2
, x
3 и x
4
. Если построить линейную
модель на этих признаках, в ней уже будет 5 коэффициентов.
Рис. 6.3: Описать данные удалось с помощью перехода к другому признаковому пространству.
С помощью этой модели уже можно почти идеально описывать данные: она очень хорошо решает задачу,
а также не переобучается.
Фактически был совершен переход к новому признаковому пространству из четырех признаков вместо
одного, в котором была построена линейная модель. А на исходном пространстве эта модель уже нелинейная
и отлично описывает данные.
6.2.2. Задача классификации с нелинейной границей
Другой пример — решается задача классификации с двумя признаками, которые отложены по осям.
Рис. 6.4: Набор данных для рассматриваемой задачи классификации.
3
Видно, что разделяющая поверхность здесь не является линейной. Применение линейного классификатора
дает следующий результат:
Рис. 6.5: Линейный классификатор не смог решить задачу.
То есть все объекты будут отнесены к красному классу: это лучшее, что он может сделать, но понятно,
что это никуда не годится.
Но если кроме признаков x1 и x2 рассмотреть признаковое пространство, которое также включает в себя
признаки x1x2, x
2
1 и x
2
2
, результат будет совершенно иной: разделяющая поверхность будет иметь форму
окружности и очень хорошо разделять красные и синие точки.
4
Рис. 6.6: Красные и синие точки хорошо разделились.
Здесь также в новом пространстве была построена линейная модель, которая является нелинейной в
исходном признаковом пространстве.
6.2.3. Спрямляющее пространство
Два рассмотренных примера дают представление о спрямляющем пространстве. Спрямляющим пространством признаков называется такое пространство, в котором задача хорошо решается линейной моделью.
Спрямляющее пространство может, в том числе, быть построено:
• Через добавление квадратичных признаков, то есть когда к исходным признакам добавляются их квадраты и попарные произведения:
(x1, ..., xd) → (x1, ..., xd, x2
1
, ..., x2
d
, x1x2, ..., xd−1xd).
Следует особо отметить, что в таком случае число признаков увеличивается на порядок. Если объектов
не слишком много, существует риск переобучения в таком большом признаковом пространстве.
• Через добавление полиномиальных признаков:
(x1, ..., xd) → (x1, ..., xd, ..., xixj , ..., xixjxk, ...).
Этот способ следует использовать только, когда объектов достаточно много, то есть риск переобучения
минимален, а также заранее известно, что зависимости очень нелинейные.
• Через логарифмирование (или любые другие нелинейные функции):
xi → ln(xi + 1), xi → ln(|xi
| + 1).
Ранее приводился пример про стоимость книг в интернет-магазине. В данном случае признаком будет
стоимость книги, значение которого для большинства книг составит несколько сотен рублей. Но существуют и встречаются весьма часто очень дорогие книги, так что распределение этого признака будет
иметь «тяжелый правый хвост». Известно, что линейные модели плохо применимы в таком случае и
работают гораздо лучше, если распределение признаков близко к нормальному. Чтобы распределение
признака «с хвостом» сделать более близким к нормальному, нужно прологарифмировать этот признак.
5
6.3. Работа с категориальными признаками
В этом разделе пойдет речь о том, как использовать категориальные признаки в линейных или других моделях.
Ранее уже было приведено множество примеров категориальных признаков:
• Город
• Цвет
• Тарифный план
• Марка автомобиля
• и так далее...
Особенность категориальных признаков состоит в том, что это элементы некоторого неупорядоченного множества, и нельзя говорить, что какое-то значение больше или меньше другого. Можно только сравнивать их
на равенство. Но в линейных моделях нужно брать значение признака, умножать на вес, а потом складывать с
другими числами, и эту операцию нельзя делать со значениями категориальных признаков. Категориальные
признаки нужно сначала преобразовать, чтобы их можно было использовать в линейных моделях.
6.3.1. Бинарное кодирование
Один из наиболее популярных подходов к кодированию категориальных признаков — бинарное кодирование.
Далее будут использоваться следующие обозначения. Пусть j-ый признак — категориальный и принимает n
возможных значений:
c1, ..., cn.
Пусть также fj (x) — значение этого признака на объекте x. Чтобы закодировать данный признак, вводятся
n новых бинарных признаков:
b1(x), ..., bn(x),
причем значение бинарного признака bi равно единице только в том случае, если на данном объекте x значение
категориального признака fj (x) равно ci
:
bi(x) = [fj (x) = ci
].
В результате один категориальный признак заменяется n бинарными признаками.
6.3.2. Бинарное кодирование (пример)
Пусть в качестве признака рассматривается цвет, причем он может принимать три значения: синий, зеленый
или красный. Дано три объекта x1, x2, x3, на которых значения категориального признака:
fj (x1) = синий, fj (x2) = красный, fj (x3) = синий.
Поскольку категориальный признак принимает 3 значения, потребуется 3 бинарных признака, чтобы его
закодировать. В результате получается следующая матрица (каждому объекту соответствует своя строка, а
каждому столбцу — свое значение признака):


1 0 0
0 0 1
1 0 0


6.3.3. Бинарное кодирование: новые значения
Часто возникает следующая проблема. При кодирования тестовой выборки может встретиться объект, на
котором категориальный признак принимает новое (n + 1)-е значение, которое до этого не встречалось в
обучающей выборке. В этом случае логичным подходом будет не добавлять новый признак (поскольку это
сложно реализуется), а просто приравнять к нулю все существующие признаки. Действительно, по смыслу
бинарных признаков (принимает ли категориальный признак значение ci
, i ∈ {1, 2, ..., n}), каждый из них в
таком случае должен равняться нулю.
6
6.4. Несбалансированные данные
В этом разделе пойдет речь о том, что такое несбалансированные выборки, к каким проблемам они могут
привести, а также как бороться с такими проблемами.
6.4.1. Несбалансированная выборка
Пусть решается задача классификации с несбалансированной выборкой. Задача называется несбалансированной, если объектов одного класса существенно меньше, чем объектов остальных классов. Например, задача
бинарной классификации называется несбалансированной, если объектов одного из двух классов менее 10%.
Примеров задач с несбалансированными выборками довольно много:
• Предсказание резких скачков курса доллара. Если определение резкого скачка подразумевает сильные
изменения, то примеров таких изменений за всю историю — единицы, но при этом практически каждый
день — отрицательный пример, то есть пример, когда такого скачка не было. Выборка в этом случае
будет очень несбалансированной.
• Медицинская диагностика (больных, как правило, сильно меньше, чем здоровых)
• Обнаружение мошеннических транзакций (которых существенно меньше, чем обычных транзакций)
• Классификация текстов и так далее.
Основная проблема, связанная с несбалансированными выборками, состоит в том, что классификаторы минимизируют число неправильных ответов и никак не учитывают цены ошибок. Может возникнуть ситуация,
когда выгоднее отнести все объекты к большему классу, не пытаясь как-то выделить объекты маленького
класса. Другими словами, при работе с несбалансированными выборками классификаторы получаются очень
плохие с точки зрения точности или полноты.
6.4.2. Undersampling
Первый подход к работе с несбалансированными выборками — undersampling. Его основная идея состоит в
том, что часть объектов из большого класса выбрасываются из выборки. Пусть, например, есть три класса:
очень крупный, крупный и небольшой
Рис. 6.7: Несбалансированная выборка
В этом случае необходимо выкинуть большую часть 1го класса и половину объектов 3го класса. Размеры
классов примерно сравняются.
7
Рис. 6.8: Undersampling
При этом то, сколько именно объектов каждого класса выбрасывается — это гиперпараметр, который
имеет смысл настраивать по отложенной выборке или по кросс-валидации.
6.4.3. Oversampling
Второй подход, oversampling, противоположен предыдущему: в данном случае объекты маленьких классов
дублируются, чтобы выравнять соотношение классов.
Рис. 6.9: Oversampling
В предыдущем примере 5 раз необходимо продублировать объекты 2го класса, а также продублировать
случайную половину 3го класса. В этом случае размеры классов тоже выравняются. То, на сколько будет
увеличен каждый класс — тоже гиперпараметр.
Следует обратить внимание на одну особенность. Если задача решается на исходной выборке, то среднеквадратичная ошибка выглядит:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
Но если делается oversampling, то есть дублируются какие-нибудь объекты, некоторые слагаемые будут входить в эту сумму несколько раз. Таким образом, вместо реального дублирования объектов, можно выставить
соответствующие веса νi
:
MSE(a, X) = 1
`
X
`
i=1
νi(a(xi) − yi)
2
.
6.4.4. Стратификация
Еще одна проблема, с которой можно столкнуться при работе с несбалансированными выборками, заключается в том, что при проведении кросс-валидации исходная выборка разбивается на k блоков примерно
одинаковой длины. При этом, если выборка несбалансированная, может получиться ситуация, что в некоторые блоки объекты какого-то класса не попадут вообще. Такая ситуация крайне неприятна: при обучении на
этом блоке получается классификатор, который никогда не видел один из классов.
8
Чтобы с этим бороться необходимо использовать стратификацию, то есть делать так, чтобы распределение
классов в каждом блоке примерно совпадало с распределением классов в исходной выборке. В этом случае
будет гарантироваться, что объекты каждого из классов будут представлены в каждом из блоков разбиения.
6.5. Многоклассовая классификация
В этом разделе рассказывается, как решать задачи многоклассовой классификации с помощью линейных моделей. Как следует из названия, в задачах многоклассовой классификации K возможных классов. Требуется
научиться отличать каждый класс от всех остальных.
Рис. 6.10: Многоклассовая классификация
В случае бинарной классификации подход был простой — нужно было найти такой вектор весов w, что
выражение a(x) = signhw, xi определяло бы, какому классу этот объект относится.
6.5.1. ONE-VS-ALL
Этот метод можно применить к задаче многоклассовой классификации. Такой подход называется «один против всех». Как следует из названия, для каждого класса будет строиться свой бинарный классификатор.
Задачей этого классификатора будет отделение данного класса от всех остальных.
Рис. 6.11: ONE-VS-ALL
Формально говоря, будут решаться K задач бинарной классификации. Для каждой (например k-ой) из
этих задач будет весьма специфичная выборка:
X = (xi
, [yi = k])`
i=1,
9
в которой объекты xi остаются такими же, а ответы становятся бинарными. Будет построен некоторый линейный классификатор, который отделяет k-ый класс от всех остальных:
ak(x) = signhwk, xi.
Ранее уже было сказано, что уверенность классификатора в своем решении определяется значением скалярного произведения. Если знак скалярного произведения положительный, то чем больше его модуль, тем
больше классификатор уверен в том, что данный конкретный объект относится к данному классу. Поэтому
для построения многоклассового классификатора можно использовать следующий алгоритм:
a(x) = argmaxk∈1,...,Khwk, xi,
который будет возвращать тот класс k, для которого уверенность соответствующего классификатора (то есть
значение соответствующего скалярного произведения) больше всего.
6.5.2. Матрица ошибок
Для анализа того, насколько хорошо работает многоклассовый классификатор, удобно использовать матрицу
ошибок. Каждая строка этой матрицы соответствует тем объектам, которые классификатор отнес к тому или
иному классу, а каждый столбец соответствует объектам, которые на самом деле относятся к тому или иному
классу.
Например, на пересечении первой строки и второго столбца стоит число q12, которое показывает то, сколько объектов второго класса многоклассовый классификатор отнес к первому. Эта матрица позволяет понять,
какие классы перепутываются чаще всего. Также можно измерять уже известные метрики качества, например:
accuracy =
1
`
X
`
i=1
[a(xi) = yi
].
Кроме того, можно считать точность и полноту (а также F-меру) для задачи отделения того или иного класса
от всех остальных классов. Если точность и полнота будут таким образом вычислены для каждого из классов,
они могут быть позднее усреднены, чтобы получить агрегированные оценки.
Решающие деревья

Мы начинаем урок, посвященный решающим деревьям. Это семейство алгоритмов, которое очень сильно отличается от линейных моделей и в то же время занимает крайне важную роль в машинном обучении. Итак, пока что мы с вами проходили линейные модели. Они легко обучаются. В случае со среднеквадратичной ошибкой для вектора весов даже есть аналитическое решение. Также очень легко применять к линейным моделям градиентный спуск, который быстро сходится, если с признаками все хорошо, и дает нам точное решение. При этом линейные модели могут восстанавливать только очень простые зависимости из-за того, что у них очень мало степеней свободы, очень мало параметров. Их столько, сколько признаков. В то же время линейные модели можно использовать для восстановления нелинейных зависимостей за счет перехода в спрямляющие пространства, что может оказаться довольно сложной операцией. В то же время линейные модели не очень хорошо отражают то, как люди принимают решения. На самом деле, когда человек хочет понять ту или иную вещь, он будет задавать последовательность из простых вопросов, которые в итоге приведут его к какому-то ответу. Давайте разберем простой пример, который слабо относится к жизни, и поэтому не стоит повторять его дома. Итак, медицинская диагностика. Представьте, что пациент приходит к врачу и спрашивает, что с ним случилось. В это время врач очень простой и он может диагностировать только два заболевания: ангину и грипп. Сначала врач спрашивает, какая температура у пациента. Если она меньше 37 градусов, он говорит, что пациент здоров, если больше 37 градусов, он переходит к следующему вопросу, а именно спрашивает, болит ли у пациента горло. Если оно болит, то врач ставит диагноз «ангина», если не болит, врач говорит, что это грипп. В итоге, задав максимум два вопроса, врач приходит к тому или иному ответу. Другой вопрос о том, насколько качественны эти ответы, но в целом они отражают структуру мышления. Или другой пример для известной задачи определения выживет или нет тот или иной пассажир Титаника. Задача очень неплохо решается вот таким решающим деревом. Давайте разберем его. В первую очередь мы смотрим, какой пол у данного пассажира. Если это женщина, то мы сразу говорим, что она выживет, и этот ответ будет правильным в 73 % случаев. Если это мужчина, то мы смотрим, сколько ему лет. Если девять или меньше, то мы перейдем в следующую ветку, а если больше девяти, то сразу говорим, что пассажир погиб. Если меньше девяти лет, то мы смотрим, сколько родственников у этого пассажира было на борту. Если три или больше, то говорим, что он погиб. Если меньше, то говорим, что он выжил. Итак, мы рассмотрели два примера решающих деревьев. В общем случае это некоторое бинарное дерево, у которого в каждой внутренней вершине записано простое условие. В зависимости от того, верное оно или нет, мы будем идти либо вправо, либо влево от этой вершины. В каждом листе решающего дерева записан некоторый прогноз. Таким образом, мы берем некий объект, стартуем из корня и движемся по дереву, проверяя условие в текущей вершине. В зависимости от его выполнения идем либо влево, либо вправо. В конце концов мы попадаем в лист, в котором записан прогноз, который и выдается в качестве ответа модели. Отмечу, что можно строить и более сложные небинарные деревья, но, как правило, используются именно бинарные. Этого достаточно, чтобы решать большинство задач. Условия во внутренних вершинах также используются крайне простые. Наиболее частый вариант — вот такой. Мы проверяем, находится ли значение j-того признака левее, чем некоторый порог. То есть мы берем у объекта j-тый признак, сравниваем с порогом t, и если оно меньше порога, мы идем влево, если больше порога, мы идем вправо. Это опять же очень простое условие, которое зависит всего от одного признака, но его достаточно, чтобы решать многие сложные задачи. Прогноз в листе будет вещественным, если это регрессия, и он будет пытаться как можно лучше приблизить истинный ответ. Если это классификация, то есть два варианта. Дерево может выдавать либо номер класса (тогда в каждом листе будет записан просто тот или иной класс), либо распределение вероятности на классах. В этом случае в каждом листе будет записан некоторый вектор длины k, если k — это число классов, который будет говорить, насколько вероятно, что объект относится к тому или иному классу. Давайте посмотрим, как выглядят зависимости, которые восстанавливают решающие деревья. Рассмотрим задачу классификации с двумя признаками. В ней три класса, и видно, что решающее дерево может очень неплохо отделить каждый класс от всех остальных. Видно, что разделяющая поверхность каждого класса кусочно-постоянная, и при этом каждая сторона разделяющей поверхности параллельна одной из осей координат из-за того, как именно мы выбрали условия. Каждое условие сравнивает значение ровно одного признака, ровно одной координаты с порогом. В то же время решающее дерево может легко переобучиться. Его можно сделать настолько глубоким, что каждый лист решающего дерева будет соответствовать ровно одному объекту обучающей выборки. В этом случае, если мы запишем в каждом листе ответ соответствующего объекта, мы получим нулевую ошибку на обучающей выборке, но в то же время дерево будет явно переобученным. Вот пример такого дерева. Оно идеально отделило синий от красного класса. Но при этом разделяющая поверхность получилась безумно сложной. Видно, что этот алгоритм переобучился, от него не будет никакого толка на тестовой выборке. Посмотрим теперь на задачу регрессии. Пусть у нас есть всего один признак x, и нужно по его значению восстановить значение целевой переменной y. Если построить не очень глубокое дерево, то оно восстановит зависимость примерно так. Опять же, видно, что восстановленная зависимость будет кусочно-постоянной, но в целом качество довольно неплохое. Если же мы увеличим глубину дерева, то получим вот такую функцию. Видно, что дерево подогналось под выбросы, и его качество будет уже не таким хорошим. Дерево переобучилось из-за того, что его глубина слишком большая. Итак, мы с вами узнали, что такое решающее дерево, и поговорили о том, что оно последовательно проверяет простые условия и приходит в тот или иной лист, где записан прогноз. Деревья интерпретируемы, но при этом позволяют восстанавливать очень сложные зависимости. Из-за этого они довольно легко переобучаются под обучающую выборку. В следующем видео мы продолжим разговор о решающих деревьях и обсудим, как именно можно их обучать.

В этом видео мы поговорим о том, как строить решающие деревья, как обучать их на конкретную выборку. Как мы выяснили в прошлый раз, решающие деревья очень легко переобучаются. Легко построить дерево, у которого каждый лист будет соответствовать одному объекту обучающей выборки. Это дерево будет строить вот такую разделяющую поверхность, очень-очень сложную, которая будет давать идеальное качество, но при этом явно будет переобученной. Поскольку дерево может достичь нулевой ошибки на обучающей выборке, нам не подходит любое дерево. В принципе, скорее всего, каждую задачу можно решить деревом, которое будет иметь нулевую ошибку и при этом не быть переобученным, и, скорее всего, это будет минимальное дерево из всех, у которых нулевая ошибка. Минимальным оно может быть, например, в смысле количества листьев, то есть можно поставить задачу построить такое решающее дерево, которое не ошибается на данной выборке и при этом имеет меньше всего листьев. К сожалению, эта задача NP-полная, то есть ее невозможно решить за разумное время, поэтому в машинном обучении пользуются гораздо более простым подходом: строят дерево жадно, последовательно, от корня к листьям, а именно мы начинаем с пустого дерева, дальше выбираем каким-то образом корень, который разбивает нашу выборку на две, дальше разбиваем потомков этого корня и так далее. Ветвим дерево до тех пор, пока не решим, что этого достаточно. Давайте выясним, как именно можно разбивать конкретную вершину на две, на два потомка. Итак, как мы с вами договаривались, мы будем использовать в качестве условия для разбиения очень простую штуку: будем брать один из признаков, j-тый, и сравнивать его с порогом t. Если значение j-того признака меньше порога, отправляем объект в одну сторону, например, влево, если больше порога, то вправо. Допустим, мы сейчас находимся в вершине m, и в нее попало некоторое количество объектов обучающей выборки, например, xm, будем так обозначать это подмножество объектов. Мы будем использовать некоторый критерий ошибки Q, который зависит от того, какие объекты попали в данную вершину, то есть xm, и от параметров разбиения j и t, то есть на основе какого признака мы разбиваем и с каким порогом мы сравниваем значение этого признака. Будем выбирать параметры j и t-разбиения так, чтобы они минимизировали данный критерий ошибки Q. Подбирать параметр j можно перебором, поскольку признаков у нас конечное число, а из всех возможных значений параметра t, порога, можно рассматривать только те, при которых получаются различные разбиения. Можно показать, что этих значений t столько, сколько различных значений признака j на обучающей выборке. Например, можно отсортировать все значения j-того признака и брать пороги между этими значениями. После того как мы выбрали конкретное разбиение, выбрали оптимальные значения параметров j и t, мы разбиваем нашу вершину на две: левую и правую. При этом часть объектов, а именно те, на которых j-тый признак меньше или равен порогу t, отправляются влево, и будем обозначать это подмножество как xl, а часть объектов из xm, те, у которых значение j-того признака больше порога t, отправляются вправо, и это подмножество обозначается как xr. Эту процедуру можно повторить дальше для двух дочерних вершин, тем самым углубляя наше дерево. В какой-то момент нам все же придется остановиться. Как понять, что данную вершину уже разбивать не нужно, что ее можно объявить листом и выдавать прогноз для того объекта, который в нее попал? Критериев останова очень много. Например, можно смотреть, сколько объектов находится в данной вершине. Если там всего один объект обучающей выборки, понятно, что дальше разбивать не имеет смысла; если же больше, можно разбивать дальше. Или, например, можно смотреть, какие объекты попали в эту вершину: если они все относятся к одному классу в задаче классификации, можно прекратить разбиение; если же есть несколько классов, можно разбивать дальше. Или, например, можно следить за глубиной дерева и останавливать разбиение, если глубина превышает некоторый порог, например, 10. Мы будем подробнее говорить о критериях останова в следующих видео этого урока, а сейчас давайте обсудим, как выбирать ответ в листе, если мы решили вершину объявить листом. Итак, в данный лист попала некоторая подвыборка xm, некоторое подмножество объектов обучающей выборки, и нужно выбрать какой-то один прогноз, который будет оптимален для данной подвыборки. В случае с регрессией мы знаем, что если функционал – среднеквадратичная ошибка, то оптимально выдавать средний ответ по этой подвыборке, то есть мы суммируем ответы по всем объектам i, которые попали в данную вершину, и делим на количество объектов в этой вершине. Это и будет оптимальным прогнозом в случае с задачей регрессии среднеквадратичного функционала. Если мы решаем задачу классификации, то наиболее логичным выбором будет возвращать тот класс, который наиболее популярен в выборке xm. То есть мы для каждого класса y считаем, сколько объектов этого класса попало в данную вершину, и возвращаем тот, который максимален, которого больше всего. Если же мы хотим возвращать вероятности классов в данной вершине, это тоже очень легко сделать. Вероятность k-того класса оценивается как доля объектов k-того класса в данной вершине среди всех объектов, впавших в эту вершину, то есть среди всех объектов из xm. У нас остались открытыми два вопроса: как именно разбивать, как задавать критерии разбиения, как оценивать ошибку разбиения в данной вершине и как выбирать критерий останова? О них мы будем говорить в следующих видео этого урока. Мы обсудили, что решающие деревья удобно строить жадно – от корня к листьям, при этом конкретное разбиение в каждой вершине выбирается, исходя из некого критерия ошибки, о котором будем говорить позже. Также нужно задать некоторый критерий останова, который определяет, следует ли данную вершину разбивать дальше или же уже можно сделать ее листом. Также мы обсудили, как именно выбирать прогнозы в листьях, в задачах классификации и регрессии. В следующем видео мы продолжим разговор и поговорим о том, как задавать критерии ошибки.

В этом видео мы поговорим о критериях информативности, с помощью которых можно выбирать оптимальное разбиение при построении решающего дерева. Как мы с вами договорились, решающее дерево будем строить простое, у которого в каждой вершине записано условие, которое берет значение j-го признака, сравнивает его с порогом t, и если значение признака меньше порога t, то объект идет в левое поддерево, если больше, то в правое поддерево. Допустим, у нас есть некоторая вершина с номером m, в которую попала подвыборка обучающей выборки X с индексом m, и мы хотим разбить эту вершину на два поддерева. Мы уже говорили, что будем делать это с помощью критерия ошибки, который показывает, насколько качественно данное условие, данная пара (признак j и порог t) разбивает объект, попавший в эту выборку, на две подвыборки. Этот критерий обозначается буквой Q. После того, как конкретный критерий выбран, мы разбиваем выборку Xm на две части. Xl — это те объекты, у которых значения j-го признака меньше или равно порога t, и Xr — это те объекты, у которого значения j-го признака больше порога t. Выборка Xl отправляется в левое поддерево, выборка Xr отправляется в правое поддерево. После этого можно повторить процедуру для левого и правого листа, который мы породили из данной вершины. Критерий ошибки будем записывать вот в таком сложном виде. Давайте разберемся, что означают его части. Он состоит из двух слагаемых. В первом слагаемом используется функция H, которой на вход передается выборка Xl, то есть та часть объектов, которая пойдет в левое поддерево. Функция H должна измерять качество этого подмножества, то есть насколько сильный разброс ответов имеет место при попадании выборки Xl в левое поддерево. Аналогично второе слагаемое измеряет то же самое для правого поддерева, в нем функцию H передает выборка Xr, и она должна измерить, насколько силен разброс ответов в подмножестве Xr. Обратите внимание, что значение функции H на Xl и Xr нормируется, они домножаются на коэффициенты, которые равны доли объектов, которая идет влево, и доли объектов, которая идет вправо. Зачем это нужно? Представьте, что у нас в вершине m находится 1000 объектов, и из них 990 идут в левое поддерево, и 10 — в правое поддерево. При этом 990 объектов, которые идут влево, оказываются одного класса, то есть это очень хорошее поддерево, а 10 объектов, которые идут вправо, относятся ко всем возможным классам. Распределение классов там равномерное, то есть эта подвыборка получается плохой, но при этом в ней всего 10 объектов, и нам не так страшно, что она получилась плохой, при том, что 990 попали в правильную вершину. Поэтому нам важно домножать значение качества подмножества на размер этого подмножества. Итак, функция H(X) называется критерием информативности, и она должна измерять, насколько силен разброс ответов в выборке X. По сути, эта функция зависит от того, какие ответы имеют объекты из множества X. Ее значение должно быть тем меньше, чем меньше разброс этих ответов. Давайте разберем несколько примеров критерия информативности для задач регрессии и классификации. Начнем с регрессии. Понятно, что в случае с регрессией измерить разброс довольно просто — это просто дисперсия ответов этой выборки. Чтобы ее измерить, сначала вычислим средний ответ выборки X, который обозначается буквой y с верхней чертой. Он вычисляется просто, как среднее значение. А затем вычислим дисперсию выборки, которая вычисляется как среднее значение квадрата отклонения ответа на объекте от среднего ответа по выборке. Перейдем к классификации. В случае с классификацией все немного сложнее. Нам понадобится вспомогательная величина, которая показывает для k-го класса, какова доля объектов класса k в выборке X. Будем обозначать эту величину как pk-тое. И она, собственно, вычисляется по этой формуле, смысл которой как раз таки доля объектов класса k в выборке X. На основе этих чисел pk вводятся критерии информативности для классификации, и первый из них — это критерий Джини. Он вычисляется по такой формуле. В нем стоит суммирование по всем классам, от первого до K, и для каждого класса вычисляется произведение pk на (1 − pk), где pk — это доля объектов k-го класса в вершине. Обратите внимание, что все числа в этой сумме положительные, поэтому критерий Джини всегда не отрицательный, он не меньше нуля. При этом, если в нашей выборке X все объекты относятся к какому-то одному классу, например к первому, то все слагаемые в этой сумме будут нулевыми, значит и сам критерий Джини будет равен 0. Это означает, что его оптимум достигается в том случае, если все объекты в подвыборке относятся к одному классу. У него есть много интерпретаций. И одна из них следующая: критерий Джини равен вероятности ошибки случайного классификатора, где случайный классификатор устроен так, что он выдает случайный класс от 1 до K, при этом вероятность выдать класс (какое-то k) равна pk, то есть равна пропорции этого класса в общей подвыборке X. Еще один пример критерия информативности для классификации, это энтропийный критерий. Он вычисляется по такой формуле. В нем суммируются следующие слагаемые: берется вероятность pk и домножается на логарифм этой вероятности, и все это берется со знаком минус. При этом мы считаем, что если вероятность равна 0, то ноль умножить на логарифм нуля — это то же ноль. Причем это можно доказать по непрерывности, если взять просто предел функции X In X. Для этого критерия выполнено то же самое свойство: если в выборке X находятся объекты ровно одного класса, например первого, то значение энтропийного критерия будет равно 0. И какое бы не было распределение на классах, значение энтропийного критерия не отрицательное. У него так же есть очень интересный физический смысл. По сути, энтропийный критерий — это мера отличия распределения классов от вырожденного. Если распределение вырожденное, то энтропия равна 0, в этом распределении нет ничего неожиданного, мы всегда знаем, что мы будем получать из него. Если же это распределение равномерное, то есть вероятность получить каждый класс в этой выборке одинаковая, то энтропия будет максимальна. У этого распределения максимальный уровень неожиданности. Мы не можем предсказать, что мы получим. Итак, мы выяснили, что критерий ошибки должен минимизировать разброс ответов в обоих поддеревьях после разбиения по какому-то условию. И выражается он через критерий информативности, который измеряет разброс ответов в одном из поддеревьев. В регрессии это просто среднеквадратичная ошибка или дисперсия. В классификации это может быть критерий Джини или энтропийный критерий. В следующем видео мы поговорим о том, как выбирать критерий останова и что такое стрижка деревьев.

В этом видео мы поговорим о способах борьбы с переобучением решающих деревьев, а именно про критерии останова и про стрижку деревьев. Критерий останова показывает, нужно ли останавливать процесс построения дерева. Например, когда мы разбили дерево до какой-то степени и находимся в определенной вершине, мы хотим понять, нужно ли ее разбивать дальше или же стоит оделить ее листом? Критерий останова должен отвечать на этот вопрос. Как мы с вами уже обсуждали, худший случай решающего дерева — это дерево, у которого каждый лист соответствует одному объекту обучающей выборки. В этом случае дерево будет максимально переобученным, оно не будет обобщать информацию, полученную из обучающей выборки. Критерий останова, грамотно подобранный критерий останова — это способ борьбы с таким переобучением. Самый простой критерий останова проверяет, все ли объекты, которые находятся в данной вершине, относятся к одному классу. Понятно, что это работает только для классификации. Это простой и понятный критерий останова, но при этом он будет выполнятся в нетривиальных случаях только на простых выборках. Если выборка и зависимости в ней сложные, то, скорее всего, этот критерий сработает только тогда, когда в каждом листе останется по одному объекту. Гораздо более устойчивый и полезный критерий проверяет, сколько объектов оказалось в данной вершине. Если их больше, чем n, то разбиение продолжается, а если меньше или равно, чем n, то процесс построения останавливается в этой вершине, и n — это некоторый параметр, который нужно подбирать. Если n = 1, мы получаем худший случай с деревом, где в каждом листе по одному объекту. Выбирать n нужно так, чтобы по n объектам, которые попали в вершину, можно было устойчиво построить прогноз, можно было надежно оценить, какой прогноз выдавать на этих объектах. Существует рекомендация, что n нужно брать равным 5, по идее, при 5 точках, если у нас 5 объектов попали в вершину, можно уже более или менее надежно оценить, какой ответ на них нужно выдавать. Еще один критерий, гораздо более грубый — это ограничение на глубину дерева. Если мы видим, что эта вершина находится на 5-м уровне дерева и максимальная глубина равна 5, мы останавливаем построение независимо ни от чего — ни от распределения классов в этой вершине, ни от числа объектов в ней — просто останавливаем построение. Критерий довольно грубый, но при этом он хорошо себя зарекомендовал при построении композиций, то есть когда мы объединяем много решающих деревьев в один сложный алгоритм. Мы об этом будем говорить позже в этом модуле. Существует и другой подход к борьбе с переобучением деревьев, а именно стрижка. Это заключается в следующем: мы строим решающее дерево максимальной сложности, максимальной глубины, никак не ограничивая его, то есть строим его до тех пор, пока в каждой конечной вершине не окажется по одному объекту обучающей выборки. После этого мы начинаем удалять, стричь листья в этом дереве по некоторому критерию. Например, можно стричь их до тех пор, пока улучшается качество на некоторой отложенной выборке. Существует мнение, и это подкреплено многими экспериментами, что стрижка работает гораздо лучше, чем простые критерии, о которых мы говорили раньше. В то же время стрижка — это довольно трудоемкая процедура. Например, она может требовать вычисления качества дерева на некоторой валидационной выборке на каждом шаге, что может быть очень сложно. На самом деле, деревья сами по себе практически не используются на сегодняшний день, они нужны лишь для построения композиции, для объединения большого числа деревьев в один алгоритм. И в случае с композициями такие сложные подходы к борьбе с переобучением уже не нужны, оказывается достаточно простых критериев останова вроде ограничения на глубину или число объектов в каждом листе. Итак, мы с вами обсудили, что деревья сами по себе получаются переобученные и зачастую нужно бороться с их переобучением. К этому есть два подхода. Первый — использование простых критериев останова, таких как: ограничение на глубину дерева или ограничение на число объектов в каждом листе дерева. Также есть подход, который называется стрижкой деревьев, который дает более высокое качество, но при этом гораздо более сложный в применении. В следующем видео мы поговорим о том, как использовать категориальные признаки в решающих деревьях.

В этом видео мы обсудим, как использовать категориальные признаки в решающих деревьях. Напомню, что до этого мы обсуждали вот такие условия, которые используются в каждой вершине решающего дерева. В них берется значение j-го признака и сравнивается с порогом t. Если значение меньше или равно этого порога, то объект отправляется в левое поддерево, если больше этого порога, то в правое поддерево. Понятно, что это работает только для вещественных и бинарных признаков, поскольку их мы можем сравнивать с некоторыми числами. Для категориальных признаков это не так, поскольку они принимают значения из некоторого неупорядоченного множества, значения, которые мы не можем сравнивать между собой. Рассмотрим подход, который позволяет включить категориальные признаки в деревья. Он состоит в том, чтобы строить не бинарные, а n-арные деревья, у которых из каждой вершины может выходить вплоть до n ребер. Итак, допустим, мы находимся в некоторой вершине m и хотим разбить ее по некоторому признаку. Для вещественных и бинарных признаков все еще будем рассматривать простые условия, которые сравнивают значения j-го признака с некоторым порогом t. Что же делать в случае с категориальными признаками? Итак, допустим, есть j-й признак, который категориальный и принимает n возможных значений, которые будем обозначать, как c1, …, cn, в этом случае мы будем разбивать эту вершину не на две вершины, как было раньше, а на n вершин, каждая будет соответствовать своему значению категориального признака. Соответственно, в i-ю вершину будут отправляться те объекты, на которых значения j-го признака равно ci. Итак, допустим, мы построили такое разбиение и разбили вершину m на n частей, в i-ю часть отправляется множество объектов xi — это те объекты, на которых категориальный признак принимает значение ci. Как оценить ошибку такого разбиения? В случае с вещественными или бинарными признаками, мы вычисляли взвешенную сумму критериев информативности. В этом случае поступим так же, только слагаемых будет не 2, а n штук. Каждое слагаемое устроено аналогично. Мы вычисляем долю объектов из вершины m, которые идут в i-е поддерево и умножаем на значение критерия информативности для подвыборки xi — той, которая отправилась в i-е поддерево, в i-ю дочернюю вершину. И находим такой категориальный признак, для которого эта сумма оказывается минимальной, Итак, мы рассматриваем все вещественные, бинарные и категориальные признаки, которые есть в выборке. Для категориальных мы вычисляем значение критерия ошибки так, как только что обсудили, для вещественных и бинарных так, как обсуждали в прошлых видео. И выбираем тот признак и тот порог, при которых значения критерия ошибки получаются минимальным, и именно по этому признаку и порогу строим разбиение данной вершины. Заметим, что в случае с категориальными признаками мы генерируем больше дочерних вершин, скорей всего в них будет достигаться более высокое качество и будет получаться более низкое значение критерия информативности. Поэтому, скорей всего, при таком подходе предпочтения почти всегда будут отдаваться разбиению по категориальным признакам с большим числом возможных значений. В результате получится очень много листьев в дереве, что, почти гарантировано, может привести к переобучению. Однако это не всегда так. Если у нас выборки очень большие и даже при разбиении по категориальному признаку у нас будет оказываться много объектов в каждом поддереве, то такой подход будет работать очень неплохо, поскольку он будет восстанавливать сложные зависимости и при этом не переобучаться, при использовании должного критерия останова. Есть и другой подход, который не требует строить такие сложные деревья и продолжает работать с бинарными деревьями. Итак, допустим, j-й признак категориальный и нам нужно как-то разбить по нему данную вершину. Построим некоторое разбиение множества значений этого признака C на два подмножества, которые не пересекаются: C1 и C2. В объединении они должны давать все множество значений j-го признака C. После того как такое разбиение построено, а как именно мы его строим, мы обсудим чуть позже, так вот, если оно построено, то условие в данной вершине будет выглядеть просто — оно проверяет, в какое из этих двух подмножеств попадает значение j-го признака на данном объекте. Если оно попадает в подмножество C1 — отправляем объект влево, если в C2 — отправляем его вправо, дерево остается бинарным. Итак, главный вопрос: как же именно разбить C на два подмножества? Всего возможных разбиений — 2 в степени n. Это очень много, мы не можем себе позволить устроить такой перебор, но оказывается это и не нужно. Есть одна хитрость, которая позволяет избежать полного перебора. В чем она заключается? Для начала отсортируем все возможные значения категориального признака, а их n штук, по некоторому принципу. Будем обозначать минимальное значение как C с индексом (1), второе по минимальности, как C с индексом (2), и так далее до C индексом (n) — это будет максимальное значение. После этого заменим i-е, по порядку значение категориального признака, на число i, то есть перейдем от категориального признака к вещественному и дальше будем работать именно с этим вещественным признаком. Строить для него разбиение, просто выбирая порог. Понятно, что это гораздо быстрее. Порогов столько, сколько различных значений, в нашем случае n штук. Поговорим о том, как нужно сортировать значения категориального признака. Это делается по вот такому очень сложному принципу. Давайте разберемся, что здесь написано. Итак, в числители дроби записана сумма по всем объектам из подвыборки xm — это объекты, которые попали в данную вершину. Для каждого объекта мы вычисляем индикаторы, которые будут равны 1, если j-й признак, тот который нас интересует, на данном объекте принимает значение c какое-то конкретное, и при этом сам объект относится к первому классу. Мы говорим о задаче бинарной классификации. В знаменателе записано число объектов подвыборки xn, у которых значения категориального признака равняется c. По сути, смысл этой дроби в следующем: она показывает, какая доля объектов, для которых значения категориального признака равно c, относится к первому классу. Как много объектов первого класса среди тех, у которых значение категориального признака равно c. Дальше мы сортируем по значению этой дроби все значения категориального признака. Следственно, чем меньше объектов для данного значения относится к первому классу, тем левее данное значение будет в этой цепочке, тем меньше будет данное значение в нашем порядке. Для регрессии все вычисляется аналогично. Только на этот раз мы вычисляем не долю объектов положительного класса с данным значением категориального признака, а средний ответ по всем объектам, у которых значение категориального признака равно c. И сортируем по этому среднему значению. При этом, чем меньше среднее значение при данном значении категориального признака, тем левее будет оно в этой цепочке. Главная особенность этого подхода состоит в том, что если бы мы перебирали все возможные разбиения множества C на два подмножества и искали оптимальное, с точки зрения, например, критерия Джини, то при таком подходе мы найдем то же самое разбиение. То есть такой подход позволяет перебирать всего n возможных разбиений вместо 2 в степени n, но при этом среди этих n будет самое оптимальное. Таким образом, благодаря этому трюку мы можем сократить перебор с экспоненциального до линейного. При этом это условие выполнено для критерия среднеквадратичной ошибки, для критерия Джини и для энтропийного критерия. Итак, мы обсудили два подхода к использованию категориальных признаков в решающих деревьях. Первый основан на построении n-арных решающих деревьев, в которых бы разбиваем вершину на столько поддеревьев, сколько значений у категориального признака. Второй подход работает с бинарными деревьями, там мы разбиваем множество значений категориального признака на два подмножества и отправляем объект влево или вправо, в зависимости от того, в какое из подмножеств выпадает значение категориального признака на этом объекте. На этом мы заканчиваем урок про решающие деревья, а дальше будем говорить о том, как строить композиции решающих деревьев, как объединить большое количество решающих деревьев в один сильный алгоритм.

Привет. В этом модуле вы уже многое узнали про деревья решений, а значит настало время научиться их строить. В этом видео мы потренируемя строить деревья решений с помощью модуля tree из библиотеки Sklearn. По ссылкам ниже доступна документация этой библиотеки, а также множество примеров. Для начала давайте импортируем нужную функциональность, Здесь используются все привычные вам модули, из новых только модуль trees. Также мы с вами будем строить много графиков, поэтому мы сразу подключим magic pylab. Теперь можно переходить к генерации данных. Давайте решать задачу многоклассовой классификации, создадим с помощью функции make_classification dataset, состоящий из двух признаков: x и y координаты. Нам так удобней будет его отрисовывать. И сделаем задачу многоклассовой классификации с тремя классами. Итак, генерируем данные, теперь давайте сразу же получившийся набор данных отрисуем. Для этого нам понадобится создать Colormap, нам также понадобится еще один Colormap, когда мы будем строить разделяющие поверхности, поэтому давайте сразу объявим целых два. И теперь отрисуем наши объекты на плоскости. Мы их отрисовали в координатах признаков. В данном случае нам важно расположение каждой точки (мы еще будем к этому обращаться), поэтому сразу сделаем их такими большими. Это делается с помощью атрибута s. Так, точки мы получили. Видим, что у нас есть три облака точек, причем некоторые облака накладываются друг на друга, что только усложняет нашу задачу. Теперь давайте разобъем данные на обучение и тест и перейдем к построению модели. Разбивает данные с помощью функции train_test_split. Итак, теперь давайте строить модель. Для того чтобы построить модель, воспользуемся методом DecisionTreeClassifier из модуля tree, который возвращает нам объект classificator decision tree. Для начала мы с вами создаем объект с парамерами по умолчанию, и сразу же давайте наше дерево обучим с помощью метода fit. Итак, обученное дерево готово. Теперь давайте построим предсказания, для этого применим метод predict и передадим ему на вход тестовую выборку, и сразу же оценим качество с помощью метрики accuracy, передав функции accuracy_score на вход 2 аргумента: test_labels — правильные ответы на нашей тестовой выборке и наши предсказания, которые мы сейчас построим. Итак, видим, что с помощью данного алгоритма мы правильно оцениваем приблизительно 70 % объектов. Ну, довольно неплохо. Итак, мы научились строит базовое решающее дерево, а теперь давайте проанализируем, как меняется качество модели, а также вид разделяющей плоскости в зависимости от параметра дерева, например в зависимости от его глубины. Для того чтобы отрисовать разделяющую плоскость нашего алгоритма, нам понадобится реализовать ряд дополнительных функций. Первая вспомогательная функция будет называться get_meshgrid и на вход будет принимать данные шаг и граница. Давайте рассмотрим, что же она делает. Зная наши данные, мы можем легко оценить, как меняются значения каждого признака на наших объектах. В данном случае у нас всего два признака — x и y координата, поэтому по данным мы легко можем понять, в каких границах меняется x и y. Соответственно, зная эти границы, мы можем получить набор точек, находящихся внутри квадрата по x и y в соответствии с нашими данными. Вот давайте все эти точки получим, будем получать точки с некоторым шагом (пусть он будет 0,05) и вернем некоторый объект под называнием meshgrid — набор наших точек. Именно с помощью этого объекта мы будем отрисовывать разделяющую плоскость. Так. Следующая вспомогательная функция называется plot_decision_surface. Именно она отвечает непосредственно за отрисовку наших графиков. Функция принимает на вход целый ряд аргументов: во-первых, это модель, которую мы анализируем; это обучающая и тестовая выборка (как данные, так и метки); и это два объекта colormap: один нужен для того, чтобы отрисовывать объекты в плоскости признаков, другой нужен для того, чтобы отрисовывать разделяющую поверхность. Пусть наша разделяющая поверхность будет несколько светлее, для того чтобы на ней хорошо было видно объекты. Итак, для того чтобы получить разделяющую поверхность, первое, что нужно сделать — это обучить модель. Делаем это с помощью метода fit. Обучаем модель на обучающей выборке. Далее давайте зададим размер нашего рисунка. Так как нам интересно посмотреть и на обучающие объекты, и на объекты из тестовой выборки, то давайте сразу будем строить subplot. Рисунок будет состоять из двух рисунков, поэтому сделаем наш график чуть шире по горизонтали, чем по вертикали. Так, теперь переходим непосредственно к отрисовке разделяющей поверхности. Для начала рисуем график с обучающими объектами. Нам нужно получить наш meshgrid, делаем это с помощью функции, которую мы определили шагом ранее. Теперь как же нам раскрасить все эти точки в правильные цвета, чтобы наглядно увидеть разделяющую поверхность? Ну вот давайте сделаем следующий трюк: представим, что каждая точка является объектом, который подлежит классификации. Фактически что мы можем сделать? Мы можем взять нашу обученную модель и применить ее к каждой точке на плоскости. Так как эти точки находятся внутри границ изменения признаков, то таким образом мы получим квадрат, на котором легко сможем отобразить все наши обучающие объекты. Вот давайте этот объект получим. Далее с помощью метода predict будем классифицировать каждую из этих точек и таким образом получим набор меток. Эти метки мы будем использовать в качестве цветов для построения разделяющей плоскости. Далее с помощью метода pcolormesh давайте отрисуем нашу разделяющую плоскость. Заметьте, что сюда мы передаем сами точки xx, yy. Также мы передаем наши предсказания. Они нужны будут для того, чтобы отрисовать объекты разными цветами, и указываем, какой colormap мы используем. В данном случае мы используем light_colors — светлые цвета. Далее поверх нашей разделяющей поверхности мы можем отрисовать объекты. Делаем это с помощью уже известной нам функции scatter, и здесь используем другой colormap. Ну и дальше давайте зададим нашему графику название, и прямо в названии запишем качество получившейся модели. Оценим качество с помощью метрики accuracy, используем функцию accuracy_score. Аналогично давайте поступим с тестовыми данными. Так как разделяющая поверхность у нас не изменится, не будем заново ее получать, просто отрисуем еще раз готовую разделяющую поверхность и на ней отметим точки из нашей тестовой выборки. Вот ровно это сделает наша функция. Так, функцию мы определили, теперь давайте ее применим. Для начала создадим очень простое решающее дерево глубины 1. Фактически у нас может быть проверено только одно условие, и дальше должны следовать листья, так как глубина всего лишь 1. Вот давайте создадим такую модель, передадим ее на вход нашей функции plot_decision_surface и посмотрим, как будет выглядеть разделяющая поверхность. Смотрите, мы получили следующий график. Так как дерево глубины 1, очевидно, что мы не сможем использовать 2 признака для классификации. В данном случае выгоднее было использовать признак, разделяющий наши объекты по вертикали, поэтому мы видим, что мы получили соответствующую картинку. Точность классификации составила 66 % на обучающей выборке и 63 % на тестовой. Вот довольно простая разделяющая поверхность. Что если сделать немного более сложную модель, то есть построить дерево глубины 2? Вот давайте посмотрим, как изменится картинка. Создаем соответствующий объект и передаем его нашей функции. Видим, что картинка несколько усложнилась. Теперь мы делим объекты не только по горизонтали, но и по вертикали. Видим, что это больше соответствует нашим данным, и качество действительно растет. Растет качество как на обучении, так и на тесте. Отсюда можно сделать предположение, что глубина деревьев положительно сказывается на качестве, и чем глубже получается наше дерево, тем лучше мы обучаем модель. Ну что ж, давайте, исходя из этого предположения, продолжим увеличивать глубину деревьев. Построим дерево глубины 3. Видим, что качество на обучении продолжает расти, и при этом качество на тесте не падает. Возможно, имеет смысл еще сильнее увеличить глубину дерева? Давайте попробуем. Давайте вообще не будем ничем ограничивать глубину дерева. Будем его строить настолько глубоким, насколько это возможно, так чтобы на обучении не произошло ни одной ошибки. Тогда не будем ее никак ограничивать и посмотрим, что мы получили. Мы видим, что мы получили довольно сложную разделяющую поверхность, там очень много областей нескольких цветов, и качество на обучении равняется 1. Мы не ошиблись ни разу, видим, что все наши объекты находятся в области своего цвета, в правильной области. Теперь смотрим на тестовые данные. Что мы видим? Мы видим, что для тестовых данных такая разделяющая поверхность является неоптимальной, то есть многие точки находятся в чужой области. Как такое могло получиться? Получается, что мы с вами чрезмерно подстроились под обучающие данные, то есть фактически произошло переобучение. Чтобы бороться с проблемой переобучения, мы можем не только ограничивать дерево по глубине, но также накладывать ограничения на другие параметры. Например, давайте поступим следующим образом: ограничим количество объектов, которые необходимы для того, чтобы продолжать ветвление из некоторой вершины. То есть создадим параметр min_samples_leaf = 3. Это означает, что минимальное количество объектов в листе должно быть 3. По умолчанию этот параметр был равен 1. Вот давайте сделаем такое ограничение и посмотрим, как изменится вид нашей разделяющей поверхности. Ну да, видим, что разделяющая поверхность стала несколько проще, чем была на предыдущем графике. Это хорошо. С одной стороны, у нас немножко уменьшилось качество на обучении, но, с другой стороны, выросло качество на тесте, что и говорит о том, что мы построили более хорошую модель. На этом мы с вами заканчиваем урок по решающим деревьям. Мы научились строить этот алгоритм и проанализировали, как параметры дерева влияют на его качество и на вид разделяющей поверхности. На этом мы заканчиваем изучение решающих деревьев, и уже в следующем уроке вы познакомитесь с таким понятием как случайный лес.

Решающие деревья
7.1. Решающие деревья
Решающие деревья — это семейство алгоритмов, которое очень сильно отличается от линейных моделей, но
в то же время играет важную роль в машинном обучении.
7.1.1. Линейные модели (обзор)
До этого момента изучались линейные модели. К особенностям линейных моделей относится следующее:
• Линейные модели быстро учатся. В случае со среднеквадратичной ошибкой для вектора весов даже
есть аналитическое решение. Также легко применять для линейных моделей градиентный спуск.
• При этом линейные модели могут восстанавливать только простые зависимости из-за ограниченного
количества параметров (степеней свободы).
• В то же время линейные модели можно использовать для восстановления нелинейных зависимостей за
счет перехода к спрямляющему пространству, что является довольно сложной операцией.
Отдельно стоит отметить, что линейные модели не отражают особенности процесса принятия решений у
людей. На самом деле, когда человек хочет понять ту или иную вещь, он будет задавать последовательность
из простых вопросов, которые в итоге приведут его к какому-нибудь ответу.
7.1.2. Решающие деревья (пример 1)
Чтобы понять принцип работы решающих деревьев, полезно рассмотреть следующий сильно упрощенный
пример.
Рис. 7.1
Необходимо провести медицинскую диагностику. Врач, который проводит эту диагностику, знает только
2 заболевания — ангина и грипп. Поэтому сначала он спрашивает, какая температура у пациента. Если она
меньше 37 градусов, он заключает, что пациент здоров, в ином случае — переходит к следующему вопросу, а
1
именно, спрашивает, болит ли у пациента горло. Если оно болит, врач ставит диагноз ангина, в ином случае
— грипп.
Создатели курса не рекомендуют серьезно относиться к предложенному методу диагностики заболеваний.
7.1.3. Решающие деревья (пример 2)
Другой пример — для известной задачи определения того, выживет или не выживет тот или иной пассажир
Титаника. Задача очень неплохо решается следующим решающим деревом:
Рис. 7.2
В первую очередь спрашивается пол пассажира. Если это женщина, то решающее дерево сразу заявляет,
что она выживает, и этот ответ верен в 73% случаев, и так далее.
7.1.4. Решающие деревья
Итак, были рассмотрены два примера решающих деревьев, которые представляли собой бинарные деревья,
в каждой внутренней вершине записано условие, а в каждом листе дерева — прогноз. Строго говоря, не
обязательно решающее дерево должно быть бинарным, но как правило используются именно бинарные.
Условия во внутренних вершинах выбираются крайне простыми. Наиболее частый вариант — проверить,
лежит ли значение некоторого признака x
j левее, чем заданный порог t:
[x
j ≤ t].
Это очень простое условие, которое зависит всего от одного признака, но его достаточно, чтобы решать многие
сложные задачи.
Прогноз в листе является вещественным числом, если решается задача регрессии. Если же решается задача
классификации, то в качестве прогноза выступает или класс, или распределение вероятностей классов.
7.1.5. Решающие деревья в задаче классификации
Пусть решается задача классификации с двумя признаками и тремя классами.
2
Рис. 7.3: Использование решающих деревьев в задачах классификации
Видно, что решающее дерево может очень неплохо отделить каждый класс от всех остальных. Видно,
что разделяющая поверхность каждого класса кусочно-постоянная, и при этом каждая сторона поверхности
параллельна оси координат, так как каждое условие сравнивает значение равно одного признака с порогом.
В то же время решающее дерево вполне может переобучиться: его можно сделать настолько глубоким, что
каждый лист решающего дерева будет соответствовать ровно одному объекту обучающей выборки. В этом
случае, если записать в каждом листе ответ соответствующего объекта, на обучающей выборке получается
нулевая ошибка. Дерево получается явно переобученным. Вот пример такого дерева:
3
Рис. 7.4: Переобученное решающее дерево
Это дерево идеально отделило синий от красного класса, но разделяющая поверхность получилась безумно
сложной — видно, что этот алгоритм переобучился и от него не будет никакой пользы на тестовой выборке.
7.1.6. Решающие деревья в задаче регрессии
Пусть решается задача регрессии с одним признаком, по которому нужно восстановить значение целевой
переменной. Не очень глубокое дерево восстанавливает зависимость примерно так:
Рис. 7.5: Использование решающих деревьев в задачах регрессии
Восстановленная зависимость будет кусочно-постоянной, но в целом будет иметь неплохое качество.
При увеличении глубины дерева получившаяся функция будет иметь следующий вид:
4
Рис. 7.6: Переобученное решающее дерево
Видно, что дерево подогналось под выбросы и его качество уже будет не таким хорошим. Дерево переобучилось из-за того, что его глубина слишком большая.
7.2. Обучение решающих деревьев
В данном разделе будет рассмотрен вопрос, как строить решающие деревья и как обучать их по конкретной
выборке.
7.2.1. Переобучение деревьев
В предыдущем разделе было показано, что решающие деревья очень легко переобучаются. В том числе можно
построить дерево, у которого каждый лист будет соответствовать одному объекту обучающей выборки.
Рис. 7.7: Переобученное решающее дерево
Это дерево строит очень-очень сложную разделяющую поверхность и, очевидно, переобучено.
5
Поскольку всегда можно построить такое дерево, которое не ошибается на обучающей выборке и будет
переобученным, имеет смысл искать минимальное (например, с минимальным числом листьев) дерево из имеющих нулевую ошибку. Но, к сожалению, задача отыскания такого дерева – NP-полная, то есть ее невозможно
решить за разумное время.
7.2.2. Жадный способ построения
В машинном обучении применяется жадный способ построения решающего дерева от корня к листьям. Сначала выбирается корень, который разбивает выборку на две. Затем разбивается каждый из потомков этого
корня и так далее. Дерево ветвится до тех пор, пока этого не будет достаточно.
Остается уточнить способ разбиения каждого потомка. Как было сказано ранее, в качестве условия в
каждой вершине строящегося дерева будет использоваться простейшее условие: значение одного из признаков
будет сравниваться с некоторым порогом.
Пусть в вершину m попало множество Xm объектов из обучающей выборки. Параметры в условии [x
j ≤ t]
будут выбраны так, чтобы минимизировать данный критерий ошибки Q(Xm, j, t), зависящий от этих параметров:
Q(Xm, j, t) → min
j,t
.
Параметры j и t можно подбирать перебором. Действительно, признаков конечное число, а из всех возможных
значений порога t можно рассматривать только те, при которых получаются различные разбиения. Можно
показать, что таких значений параметра t столько, сколько различных значений признака x
j на обучающей
выборке.
После того, как параметры были выбраны, множество Xm объектов из обучающей выборки разбивается
на два множества
X` =

x ∈ Xm|[x
j ≤ t]
	
, Xr =

x ∈ Xm|[x
j > t]
	
,
каждое из которых соответствует своей дочерней вершине.
Предложенную процедуру можно продолжить для каждой из дочерних вершин: в этом случае дерево
будет все больше и больше углубляться. Такой процесс рано или поздно должен остановиться, и очередная
дочерняя вершина будет объявлена листком, а не разделена пополам. Этот момент определяется критерием
остановки. Существует много различных вариантов критерия остановки:
• Если в вершину попал только один объект обучающей выборки или все объекты принадлежат одному
классу (в задачах классификации), дальше разбивать не имеет смысла.
• Можно также останавливать разбиение, если глубина дерева достигла определенного значения.
Возможные критерии останова будут обсуждаться позднее в этом уроке.
Если какая-то вершина не была поделена, а была объявлена листом, нужно определить прогноз, который будет содержаться в данном листе. В этот лист попала некоторая подвыборка Xm исходной обучающей
выборки и требуется выбрать такой прогноз, который будет оптимален для данной подвыборки.
В задаче регрессии, если функционал — среднеквадратичная ошибка, оптимально давать средний ответ
по этой подвыборке:
am =
1
|Xm|
X
i∈Xm
yi
.
В задаче классификации оптимально возвращать тот класс, который наиболее популярен среди объектов в
Xm:
am = argmaxy∈Y
X
i∈Xm
[yi = y].
Если требуется указать вероятности классов, их можно указать как долю объектов разных классов в Xm:
amk =
1
|Xm|
X
i∈Xm
[yi = k].
7.3. Критерии информативности
В этом разделе речь пойдет о критериях информативности, с помощью которых можно выбирать оптимальное
разбиение при построении решающего дерева.
6
7.3.1. Выбор критерия ошибки
Критерий ошибки записывается следующим образом:
Q(Xm, j, t) = |X`|
|Xm|
H(X`) + |Xr|
|Xm|
H(Xr)
и состоит из двух слагаемых, каждое из которых соответствует своему листу.
Функция H(X) называется критерием информативности: ее значение должно быть тем меньше, чем меньше разброс ответов в X.
В случае регрессии разброс ответов — это дисперсия, поэтому критерий информативности в задачах регрессии записывается следующим образом:
H(X) = 1
|X|
X
i∈X
(yi − y¯(X))2
, y¯ =
1
|X|
X
i∈X
yi
.
7.3.2. Критерий информативности Джини
Сформулировать критерий информативности для задачи классификации несколько сложнее. Пусть pk — доля
объектов класса k в выборке X:
pk =
1
X
X
i∈X
[yi = k].
Критерий информативности Джини формулируется в терминах pk:
H(X) = X
K
k=1
pk(1 − pk).
Все слагаемые в сумме неотрицательные, поэтому критерий Джини также неотрицателен. Его оптимум достигается только в том случае, когда все объекты в X относятся к одному классу.
Одна из интерпретаций критерий Джини — это вероятность ошибки случайного классификатора. Классификатор устроен таким образом, что вероятность выдать класс k равна pk.
7.3.3. Энтропийный критерий информативности
Еще один критерий информативности — энтропийный критерий:
H(X) = −
X
K
k=1
pk ln pk.
В этом выражении полагается, что 0 ln 0 = 0.
Энтропийный критерий, как и критерий Джини, неотрицателен, а его оптимум также достигается только
в том случае, когда все объекты в X относятся к одному классу.
Энтропийный критерий имеет интересный физический смысл. Он заключается в том, что показывает,
насколько распределение классов в X отличается от вырожденного. Энтропия в случае вырожденного распределения равна 0: такое распределение характеризуется минимальной возможной степенью неожиданности.
Напротив, равномерное распределение самое неожиданное, и ему соответствует максимальная энтропия.
7.4. Критерий останова и стрижка деревьев
В этом разделе речь пойдет о способах борьбы с переобучением деревьев, а именно о критериях останова и
стрижке деревьев.
7
7.4.1. Критерий останова
Критерий останова используется, чтобы принять решение: разбивать вершину дальше или сделать листовой.
Худший случай решающего дерева — такое, в котором каждый лист соответствует своему объекту обучающей выборки. В этом случае дерево будет максимально переобученным и не будет обобщать информацию,
полученную из обучающей выборки. Грамотно подобранный критерия останова позволяет бороться с переобучением.
Самый простой критерий останова проверяет, все ли объекты в вершине относятся к одному классу.
Однако такой критерий останова может быть использован только в случае простых выборок, так как для
сложных он остановится только тогда, когда в каждом листе останется примерно по одному объекту.
Гораздо более устойчивый и полезный критерий проверяет, сколько объектов оказалось в вершине, и
разбиение продолжается, если это число больше, чем некоторое выбранное n. Соответственно, если в вершину
попало ≤ n объектов, она становится листовой. Параметр n нужно подбирать.
Случай n = 1 является худшим случаем, описанным выше. При этом выбирать n нужно так, чтобы по n
объектам, которые попали в вершину, можно было устойчиво построить прогноз. Существует рекомендация,
что n нужно брать равным 5.
Еще один критерий, гораздо более грубый, заключается в ограничении на глубину дерева. Этот критерий
хорошо себя зарекомендовал при построении композиций, когда много решающих деревьев объединяют в
один сложный алгоритм. Об этом пойдет речь позже.
7.4.2. Стрижка деревьев
Существует и другой подход к борьбе с переобучением деревьев — стрижка. Он заключается в том, что
сначала строится решающее дерево максимальной сложности и глубины, до тех пор, пока в каждой вершине
не окажется по 1 объекту обучающей выборки.
После этого начинается «стрижка», то есть удаление листьев в этом дереве по определенному критерию.
Например, можно стричь до тех пор, пока улучшается качество некоторой отложенной выборки.
Существует мнение, и это подкреплено многими экспериментами, что стрижка работает гораздо лучше,
чем простые критерии, о которых говорилось раньше. Но стрижка — очень ресурсоёмкая процедура, так
как, например, может потребоваться вычисление качества дерева на некоторой валидационной выборке на
каждом шаге.
На самом деле, сами по себе деревья на сегодняшний день почти не используются, они бывают нужны
только для построения композиции и объединения большого числа деревьев в один алгоритм. В случае с
композициями такие сложные подходы к борьбе с переобучением уже не нужны, так как достаточно простых
критериев останова, ограничения на глубину дерева или на число объектов в листе.
7.5. Решающие деревья и категориальные признаки
В этом разделе будет рассказано, как использовать категориальные признаки в решающих деревьях.
До этого момента использовалось следующее условие в вершине каждого дерева:
[x
j ≤ t].
Очевидно, что такое условие можно записывать только для вещественных или бинарных признаков.
7.5.1. N-арные деревья
Подход, который позволяет включить категориальные признаки в деревья, состоит в том, чтобы строить nарные деревья, то есть такие деревья, что из каждой вершины могут выходить до n ребер. Пусть необходимо
разбить некоторую вершину по некоторому признаку. Если этот признак — вещественный или бинарный,
то все еще можно использовать простое условие с порогом t, поэтому интерес представляет именно случай
категориального признака.
Если x
j — категориальный признак, который может принимать значения
{c1, ..., cn},
8
можно разбить вершину на n вершин таким образом, что в i-ую дочернюю вершину идут объекты с x
j =
ci
. Критерий ошибки такого разбиения строится по аналогии со случаем бинарного дерева. Поскольку Xn
разбивается на n частей, а не на две, в выражении будет n слагаемых:
Q(Xm, j) = Xn
i=1
|Xi
|
|Xm|
H(Xi) → min
j
.
Таким образом, если вершину m нужно разбить, рассматриваются все возможные вещественные, бинарные
и категориальные признаки. Для вещественных и бинарных признаков считается Q(Xm, j, t), а для n-арных
— так, как написано выше. Разбиение вершины будет происходить по тому признаку, для которого значение
критерия ошибки будет минимальным.
Важное замечание состоит в том, что при делении вершины по категориальному признаку получается
больше дочерних вершин, на которых, очень вероятно, будет достигаться более высокое качество и более
низкое значение критерия информативности, поэтому, скорее всего, при таком подходе предпочтение почти
всегда будет отдаваться разбиению по категориальным признакам с большим числом возможных значений.
В результате получается много листьев в дереве, что почти гарантированно может привести к переобучению.
Однако это не всегда так. Если выборки настолько большие, что даже после разбиения по категориальному
признаку в каждом поддереве будет оставаться много объектов, то такое дерево будет неплохо работать,
поскольку оно будет восстанавливать сложные зависимости, и при этом не переобучаться при использовании
должного критерия останова.
7.5.2. Бинарные деревья с разбиением множества значений
Другой подход позволяет не переходить к n-арным деревьям и продолжать работать с бинарными деревьями.
Пусть также необходимо сделать разбиение вершины m, а категориальный признак x
j может принимать
значения C = {c1, ..., cn}.
Для этого сначала необходимо разбить множество значений категориального признака на два не пересекающихся подмножества:
C = C1 ∪ C2, C1 ∩ C2 = ∅.
После того, как такое разбиение построено, условие в данной вершине будет выглядеть просто:
[x
j ∈ C1]
Это условие проверяет, в какое из подмножеств попадает значение признака в данный момент на данном
объекте. Главным вопросом остается то, как именно нужно разбивать множество C.
Полное количество возможных разбиений множества на два подмножества — 2
n. К счастью, есть хитрость,
которая позволяет избежать полного перебора и, более того, работать с категориальным признаком как с
вещественным. Для этого возможные значения категориального признака сортируются специальным образом
c(1), ..., c(n) и заменяются на натуральные числа 1,...,n. После этого с данными признаком следует уже работать
как с вещественным, а значение порога t будет определять разделение множества C на два подмножества.
Сортировать значения категориального признака в случае задачи бинарной классификации нужно по
следующему принципу:
P
i∈Xm
[x
j
i = c(1)][yi = +1]
P
i∈Xm
[x
j
i = c(1)]
≤ ... ≤
P
i∈Xm
[x
j
i = c(n)
][yi = +1]
P
i∈Xm
[x
j
i = c(n)
]
Фактически, значения категориального признака сортируются по возрастанию доли объектов +1 класса среди
объектов выборки Xn с соответствующим значением этого признака.
Для задачи регрессии сортировка происходит похожим образом, но вычисляется не доля объектов положительного класса, а средний ответ по всем объектам, у которых значение категориального признака равно c:
P
i∈Xm
[x
j
i = c(1)]yi
P
i∈Xm
[x
j
i = c(1)]
≤ ... ≤
P
i∈Xm
[x
j
i = c(n)
]yi
P
i∈Xm
[x
j
i = c(n)
]
.
Главная особенность такого подхода состоит в том, что полученный результат полностью эквивалентен результату, который можно было бы получить в результате полного перебора. Это условие работает для критерия
Джини, MSE и энтропийного критерия.


Случайные леса

В прошлом уроке мы с вами узнали, что такое решающие деревья, и выяснили, что они могут восстанавливать очень сложные закономерности, из-за чего они склонны к переобучению. Решающее дерево слишком легко подгоняется под обучающую выборку и получается непригодным для построения прогнозов. Бороться с переобучением довольно сложно. Надо либо использовать критерии остановок, которые слишком простые и не всегда помогают, либо делать стрижку деревьев, которая, наоборот, слишком сложная. Зачем же мы тогда тратили на них время? Оказывается решающие деревья очень хорошо подходят для объединения в композиции, для построения одного непереобученного алгоритма на основе большого количества решающих деревьев. В этом и следующем уроке мы будем говорить, как именно объединять их в такие композиции, а пока давайте еще раз вспомним проблемы решающих деревьев. Представьте, что у нас есть вот такая выборка, и мы обучили на ней решающее дерево до конца, то есть до тех пор, пока в каждом листе не оказалось по одному объекту. Разделяющая поверхность будет очень плохой. Она очень разрезанная. Даже если есть объект, который попадает в гущу другого класса, например синяя точка внизу, разделяющая поверхность пытается уловить этот объект, выдать на нем правильный синий ответ. Из-за этого поверхность получается очень переобученная. Если мы немного изменим обучающую выборку, например выкинем пару объектов и обучим решающее дерево на том, что осталось, разделяющая поверхность будет все еще очень изрезанной и переобученной, но совершенно другой. Она очень неустойчива к изменениям в выборке. Итак, у решающих деревьев есть два недостатка. Первый — они очень сильно переобучаются, а второй — они очень неустойчивы, они очень сильно меняются даже при небольших изменениях в выборке. И на самом деле второй пункт можно обратить в их достоинство с помощью композиции, но об этом чуть позже. А пока давайте поговорим в целом о том, что такое композиция алгоритмов. Итак, композиция — это объединение n алгоритмов в один. Представьте, что мы каким-то образом нашли N большое алгоритмов b1, ..., bn. Пока не важно, откуда мы их взяли. Просто представьте, что мы их как-то обучили. Чтобы объединить их в композицию, мы усредняем их ответы, то есть суммируем ответы всех этих алгоритмов b1, ..., bn на объекте x, и делим на N большое, то есть на количество этих алгоритмов. Если мы решаем задачу классификации, то далее мы берем знак от этого среднего; если регрессии, то просто возвращаем это среднее как ответ. Алгоритм a(x), который возвращает знак среднего или просто среднее и называется композицией n алгоритмов. А алгоритмы b1, ..., bn, которые мы объединяем в композицию, называются базовыми алгоритмами. Рассмотрим простой пример. Представьте, что в нашей композиции 6 базовых алгоритмов, и есть некоторый объект x, на котором наши базовые алгоритмы выдали вот такие ответы: −1, −1, 1, −1, 1 и −1. Это задача классификации с двумя классами. Какие-то алгоритмы отнесли наш объект к классу +1, какие-то — к классу −1. Усредним ответы. Получим при этом −2/6 или −1/3. Знак этой дроби — это −1, значит ответ композиции — это −1. Мы отнесли объект к классу −1, поскольку именно за этот вариант проголосовало большинство базовых алгоритмов. Итак, для того чтобы строить композицию, нужно обучить n базовых алгоритмов. При этом понятно, что нельзя их обучать на всей обучающей выборке. Они получатся одинаковыми, и в их усреднении не будет никакого смысла. Нужно делать их немного различными. Как этого достичь? Например, с помощью рандомизации, то есть обучать их по разным подвыборкам обучающей выборки. Поскольку решающие деревья очень сильно меняются даже при небольших изменениях обучающей выборки, такая рандомизация с помощью подвыборок будет очень хорошо влиять на их различность. Один из популярных подходов по построению подвыборок — это бутстрап. В чем он заключается? Представьте, что у нас есть полная обучающая выборка, состоящая из l объектов. Мы генерируем из нее l объектов с возвращением, то есть мы берем из нее некоторый случайный объект, записываем его в новую выборку и возвращаем обратно. То есть в какой-то момент мы можем снова его вытянуть и снова поместить в обучающую выборку. При этом новая выборка будет тоже иметь размер l, но при этом какие-то объекты будут в ней повторяться, а какие-то объекты исходной обучающей выборки не встретятся ни разу. Можно показать, что количество различных объектов в бутстрапированной выборке будет равняться 0,632 * l, то есть примерно 63 % объектов исходной выборки будет содержаться в бутстрапированной. Есть и другой подход к рандомизации. Это просто генерация случайного подмножества обучающей выборки. Например, мы берем случайные 50 % объектов и на них обучаем базовый алгоритм. Этот подход чуть хуже, потому что в нем появляется гиперпараметр — размер подвыборки. В нашем примере это было 50 %. В случае же с бутстрапом никаких параметром нет. Он без какой-либо настройки выдает нам подвыборку, что гораздо удобнее. Если мы построим с помощью бутстрапа 100 базовых решающих деревьев и объединим их в композицию, то мы получим вот такую разделяющую поверхность в нашем примере, который мы разбирали в начале. Видно, что поверхность все еще довольно сложная, но при этом гораздо менее переобученная. Она уже не пытается подгоняться под большинство объектов, которые залезают в гущу другого класса. Она более или менее угадывает разделяющую поверхность между двумя классами. Да, все еще есть некоторые погрешности, но и их можно было бы устранить, если построить еще больше базовых алгоритмов. Итак, мы с вами вспомнили, что решающие деревья являются очень сильно переобученными алгоритмами и так же неустойчивы к любым изменениям в обучающей выборке. При этом усреднение ответов нескольких базовых алгоритмов, базовых решающих деревьев повышает качество композиции, дает более высокое качество и менее переобученную разделяющую поверхность, чем отдельные базовые алгоритмы. При этом строить отдельные базовые решающие деревья или базовые алгоритмы можно разными способами, например с помощью бутстрапа или генерации случайных подвыборок. В следующем видео мы продолжим разговор о композициях и разберемся, почему же усреднение улучшает качество базовых алгоритмов.

 В этом видео мы поговорим о разложении ошибки на смещение и разброс — технике, которая позволяет понять, почему усреднение алгоритмов позволяет повысить их качество. Итак, ы прошлом видео мы выяснили, что усреднение решающих деревьев в задаче классификации делает разделяющую поверхность менее переобученной, позволяет повысить качество. Почему это происходит? В целом подход с усреднением довольно известный, например, в физике довольно распространенный подход — сделать несколько измерений одной величины и усреднить. И это уменьшает ошибку измерений. Но давайте попробуем понять, почему это работает хорошо именно в машинном обучении. Для этого нам пригодится разложение ошибки на смещение и разброс, о котором вы уже узнали в прошлом модуле. Итак, идея состоит в том, что ошибка алгоритма на новых тестовых данных складывается из трех компонент: шума, смещения и разброса. При этом все они характеризуют разные аспекты данных и модели, с помощью которой вы решаете задачу на этих данных. Начнем с шума. Шум показывает, какова ошибка лучшей из всех возможных в мире моделей на данной задаче. Поскольку данные могут быть зашумленные, и на них в принципе невозможно получить нулевую ошибку, идеальная модель тоже может ошибаться, и шум показывает, насколько сильно будет ошибаться идеальная модель на этой задаче. Шум никак нельзя улучшить, это характеристика ваших данных, с этим приходится жить. Вторая компонента разложения — это смещение. Чтобы понять ее, давайте проведем некоторый умственный эксперимент. Педставьте, что обучающая выборка — это некоторая случайная величина, ее можно генерировать из некоторого распределения. Генерируя ее снова и снова, будем получать немного разные обучающие выборки из одного и того же распределения. Итак, допустим, мы сгенерировали много обучающих выборок из этого распределения. На каждой мы обучили нашу модель, например решающее дерево. Смещение показывает, насколько сильно отклоняется средний прогноз по всем обученным моделям от прогноза идеальной модели. По сути, смещение говорит, насколько мы можем аппроксимировать идеальную модель, насколько наше семейство алгоритмов сложное и позволяет восстанавливать сложные закономерности. Если это избразить с помощью диаграммы, то процесс вычисления смещения выглядит примерно так. Мы генерируем много обучающих выборок x1, ..., xn. На каждой обучаем свой алгоритм b1(x), b2(x), ..., до bn(x) и усредняем их ответы на объекте x. После чего сравниваем средний ответ с ответом идеального алгоритма y(x). Наконец, разброс — третья компонента разложения. Разброс вычисляется по похожей схеме. Мы генерируем много обучающих выборок, на каждой обучаем нашу модель, например решающее дерево, и дальше смотрим на дисперсию ответов всех этих моделей. Диаграмма получается примерно такой же: мы генерируем много выборок x1, ..., xn, обучаем на них базовые алгоритмы и дальше смотрим на дисперсию выборки b1(x), b2(x), ..., bn(x) на каких то объектах. Чем больше эта дисперсия, чем выше разброс, тем сильней алгоритм зависит от небольших изменений обучающей выборки. Например, решающие деревья обладают этим свойством. Если чуть-чуть поменять обучающую выборку, дерево меняется очень сильно. На этой картинке можно увидеть иллюстрацию смещения и разброса. Зеленая кривая — это истинная зависимость. Будем генерировать из нее 10 случайных точек, добавлять к ней небольшой шум и считать это обучающей выборкой, и будем обучать на этом полином третьего порядка. На левой картинке красными кривыми изображены полиномы, которые получаются при немножко разных обучающих выборках, сгенерированных таким образом. Видно, что средний полином, который изображен справа красной кривой, идеально угадывает истинную зависимость — зеленую кривую. Но при этом отдельные полиномы могут отличаться от этой зависимости, разброс довольно большой в каждой точке. Итак, мы здесь получили семейство алгоритмов, которые имеют низкое смещение и довольно большой разброс. Вернемся к линейным моделям. Вспомним, что их смещение может быть довольно большим. Линейные модели могут восстанавливать только линейные зависимости, но при этом в большинстве задач зависимости нелинейные, из за чего смещение большое и линейная модель в принципе не может восстановить сложные зависимости. При этом разброс маленький. У линейной модели параметров столько, сколько признаков. Это очень мало. Вряд ли они сильно изменятся, если чуть-чуть поменять обучающую выборку. Итак, у линейных моделей большое смещение и низкий разброс. Решающие деревья — это полная противоположность. У них низкое смещение. Они могут восстанавливать очень сложные закономерности, но при этом разброс очень большой, поскольку деревья очень сильно меняются даже при небольших изменениях обучающей выборки. Поговорим теперь про усреднение базовых алгоритмов. Оказывается, что если мы усредняем много базовых алгоритмов, например построенных по бутстрапированным подвыборкам, то мы не меняем их смещение. Смещение композиции, смещение среднего алгоритма совпадает со смещением отдельного базового алгоритма. Таким образом, если мы усредняем деревья, а у деревьев низкое смещение, то и у их композиции тоже будет низкое смещение. Композиции будут в состоянии восстанавливать сложные закономерности, а вот разброс меняется. Разброс композиций состоит из двух слагаемых. Первое — это разброс одного базового алгоритма, который делится на N большое — на число базовых алгоритмов. Второе слагаемое — это корреляции между двумя базовыми алгоритмами. Обратите внимание, что если базовые алгоритмы независимы, если их прогнозы не коррелируют между собой, то разброс композиции — это всего лишь разброс одного базового алгоритма, деленный на N. Это прекрасно. Если алгоритмы базовые не коррелированы и это решающие деревья, то композиция будет иметь низкое смещение, поскольку у базовых алгоритмов низкое смещение, и низкий разброс, если мы возьмем большое N. У деревьев большой разброс, мы поделим его на большое число и получим низкий разброс композиции. Итак, если базовые алгоритмы не коррелированы, то композиция может дать нам идеальный алгоритм. Но, к сожалению, это не всегда так. Базовые алгоритмы обучаются на одной и той же выборке или на подвыборках одной и той же выборки, из за чего они оказываются зависимыми, их ответы коррелированы, и очень сложно сделать их полностью независимыми. Но при этом можно попытаться хотя бы уменьшить корреляцию, и к этому есть два подхода. Первый — это то, о чем мы уже говорили: бэггинг — обучение отдельных базовых алгоритмов на случайных подвыборках объектов. За счет этого базовые алгоритмы получаются немножко разные, и при этом, наверное, чем меньше мы будем брать обучающую выборку для одного базового алгоритма, тем более независимые они будут. Но при этом не стоит здесь увлекаться. Если обучающая выборка будет слишком маленькой, то с переобучением решающих деревьев уже ничего нельзя будет поделать. Но при этом давайте вспомним, что у обучающей выборки есть два измерения: это объекты и признаки этих объектов. Если рассматривать матрицу «объекты–признаки», то по строкам записаны объекты, по столбцам — признаки, и бэггинг делает рандомизацию по строкам, то есть он выбирает случайное подмножество строк и обучает на этом подмножестве один базовый алгоритм. Но при этом можно можно брать и случайное подмножество столбцов. Это называется методом случайных подпространств. В этом случае мы сэмплируем — мы выбираем случайное подмножество признаков (столбцов) и только на этих признаках обучаем очередной базовый алгоритм. При этом два данных подхода — бэггинг и метод случайных подпространств — можно объединять. Можно сэмплировать как столбцы, так и строки матрицы «объекты–признаки» и обучать на такой подматрице каждый базовый алгоритм. При этом обратите внимание, что у метода случайных подпространств есть гиперпараметр — какую долю признаков мы выбираем? Можно от него избавиться, если тоже делать бутстрап, но это будет довольно странно. У матрицы «объекты–признаки» будут одинаковые столбцы — коррелирующие признаки, что довольно плохо. Итак, мы с вами обсудили, что такое разложение ошибки на смещение и разброс. Смещение характеризует, насколько сложно у нас семейство алгоритмов, насколько оно может восстанавливать сложные закономерности, а разброс говорит, насколько чувствительны алгоритмы к небольшим изменениям выборки. При этом мы выяснили, что усреднение алгоритмов, объединение их в такую композицию не меняет смещение и при этом уменьшает разброс. При этом чем менее коррелированы базовые алгоритмы, тем сильнее уменьшение разброса. И обсудили два подхода к уменьшению корреляции между базовыми алгоритмами: бэггинг и метод случайных подпространств. А в следующем видео мы поговорим о еще одном способе рандомизации случайных деревьев, в котором мы углубляемся и пытаемся рандомизировать сам процесс построения дерева.

В этом видео мы поговорим о случайных лесах, которые являются одним из лучших способов объединения деревьев в композиции. В прошлый раз мы выяснили, что ошибка любого алгоритма на контрольной выборке складывается из шума смещения и разброса, при этом на шум мы никак повлиять не можем. Усреднение базовых алгоритмов не меняет смещение, то есть если базовые алгоритмы были сильные, то и композиция будет довольно сильной, способной восстанавливать сложные закономерности, а вот разброс усреднение уменьшает, и при этом чем менее коррелированы базовые алгоритмы, тем сильнее будет уменьшение разброса при усреднении. Мы обсудили два способа понижения корреляции между базовыми алгоритмами, а именно бэггинг, когда мы обучаем каждый базовый алгоритм в случайном подмножестве объектов, и метод случайных подпространств, когда мы обучаем каждый базовый алгоритм на случайном подмножестве признаков. Их можно объединять, использовать одновременно и тот, и другой. Но их оказывается мало, и чтобы добиться еще более маленькой корреляции между базовыми алгоритмами, имеет смысл сделать более случайным процесс построения этих базовых алгоритмов. Давайте подумаем, как можно сделать рандомизированным процесс построения решающих деревьев. Для этого вспомним, как он устроен. Итак, решающее дерево строится жадно. Мы начинаем с одной вершины, разбиваем ее на две и далее производим ветвление уже этих двух поддеревьев, этих двух вершин до тех пор, пока не будет выполнен некоторый критерий останова. При этом разбиение мы осуществляем следующим образом. Нам нужно найти такое условие разбиения, а условия у нас очень простые, они проверяют j-тый признак и сравнивают его значение с некоторым порогом t. Если значение j-того признака меньше или равно этого порога, то объект идет в левое поддерево, если больше порога, то в правое поддерево. И нам нужно выбрать такие признак j и порог t, при которых будет достигаться минимум некоторого критерия ошибки, который характеризует, насколько хорошо разбивать данную вершину именно по такому условию, именно таким способом. И мы искали лучший признак j и порог t просто перебором, поскольку их – конечное число. Рандомизировать процесс можно следующим образом: будем искать лучший признак j для разбиения не из всех возможных признаков выборки, а из некоторого случайного подмножества признаков, и размер этого подмножества будет равен некоторой константе q. Оказывается, что этот подход действительно позволяет сделать деревья менее коррелированными. На этом графике по оси x отложено q, то есть то, из скольки случайно выбранных признаков мы выбираем лучшие при конкретном разбиении, а по оси y отложена корреляция между двумя базовыми решающими деревьями. Видно, что чем меньше q, чем меньше простор при выборе лучшего разбиения, тем меньше корреляция между решающими деревьями. Разница в корреляции при выборе абсолютно случайного признака, если q = 1, и при выборе из всего множества признаков, достигает несколько раз. Корреляция уменьшается в несколько раз при уменьшении q. Для q есть некоторые рекомендации, которые неплохо работают на практике. Если мы решаем задачу регрессии, то имеет смысл брать q = d/3, то есть 1/3 от общего числа признаков. Если мы решаем задачу классификации, то имеет смысл брать q = √d, корню из числа признаков. Итак, давайте полностью проговорим, как устроен алгоритм построения случайного леса. Мы хотим построить композицию из N решающих деревьев. Что мы делаем для построения каждого из них? Сначала мы генерируем случайную подвыборку X с волной с помощью бутстрапа. После этого мы обучаем на этой выборке X с волной очередное решающее дерево bn(x). И построение обладает двумя особенностями: во-первых, мы строим дерево до тех пор, пока в каждом листе окажется не более некоторого числа объектов n минимальное. Очень часто эту константу берут равной 1, то есть строят деревья до конца, до тех пор, пока в каждом листе не окажется по одному объекту обучающей выборки. В результате мы получим очень сложные, очень переобученные решающие деревья с низким смещением, но это нам и нужно при построении композиции. Также при выборе оптимального разбиения при построении дерева мы ищем лучший признак не из всех признаков выборки, а из случайного подмножества признаков размера q. Обратите внимание, что случайное подмножество размера q выбирается заново при каждом новом разбиении вершины. Этим подход отличается от метода случайных подпространств, где мы выбираем случайное подмножество один раз перед построением базового алгоритма, здесь же оно будет свое в каждой вершине. Далее мы объединяем построенные деревья в композицию. Если это регрессия, то мы просто усредняем их, если это классификация, то мы берем знак от среднего ответа. Одна из особенностей случайных лесов состоит в том, что они не переобучаются при росте числа базовых алгоритмов. На этом графике изображена зависимость качества случайных лесов при разном значении параметра q в зависимости от числа базовых алгоритмов. Видно, что при росте числа базовых алгоритмов ошибка на тесте уменьшается, в какой-то момент выходит на асимптоту и остается на этом уровне, не происходит роста ошибки при росте числа базовых алгоритмов. Итак, мы разобрались, что такое случайный лес. Это композиция решающих деревьев, в которой эти решающие деревья строятся довольно случайно: при каждом разбиении оптимальный признак выбирается из случайного подмножества признаков. За счет этого сильно уменьшается корреляция между деревьями, и поэтому разброс композиции получается довольно низким. Особенность случайного леса состоит в том, что он не переобучается при росте числа базовых алгоритмов. За счет этого случайный лес считается одним из самых универсальных алгоритмов. У него практически нет гиперпараметров. Мы можем брать просто довольно большое число базовых деревьев и при этом будем получать хороший, не переобученный алгоритм. В следующем видео мы поговорим о различных трюках, которые можно делать со случайными лесами.

В этом видео мы поговорим о некоторых трюках, которые случайные леса позволяют выполнять в ряде задач. В прошлый раз мы разобрались, как обучают случайные леса. Это довольно простой алгоритм, который не переобучается при росте числа базовых решающих деревьев. При этом у него есть ряд интересных особенностей, о которых мы сейчас поговорим. Первое состоит в том, что каждое решающее дерево обучается независимо от всех остальных деревьев. При обучении n-ного дерева никак не используется информация о построении остальных базовых решающих деревьев. Это можно использовать при распараллеливании. Можно обучать каждое решающее дерево независимо на своем ядре или на своем компьютере. При этом распараллеливание получается идеальное. Мы получаем линейное уменьшение времени обучения при линейном увеличении числа ядер. Вторая особенность состоит в том, что каждое дерево обучается на бутстрапированной выборке. При этом, как мы уже обсуждали, в бутстрапированной выборке оказывается примерно 63 % от общего числа объектов в обучающей выборке, а остальные никак не используются при обучении данного дерева. Это можно использовать, и подход, который так делает, называется out-of-bag. Итак, представьте, что у нас есть N большое решающих деревьев, при этом каждое из них было обучено на своей бутстрапированной подвыборке. Первое — на подвыборке x1, второе — на подвыборке x2, и так далее. При этом если мы возьмем конкретный объект обучающей выборки xi-тое, то то на нем не обучались примерно 37 % решающих деревьев. Это можно использовать. Если мы построим прогноз для данного объекта только по тем деревьям, которые не обучались на нем, мы получим некоторое предсказание. И оказывается, что оно очень неплохо характеризует обобщающую способность случайного леса. Нам не нужна дополнительная выборка или кросс-валидация, чтобы оценить качество леса, поскольку в обучающей выборке есть объекты, на которых обучались не все деревья. Итак, чуть более формально о том, как оценить качество случайного леса с помощью подхода out-of-bag. Ошибка в данном подходе вычисляется по вот такой формуле. Мы считаем сумму по всем объектам обучающей выборки от 1 до l и для каждого объекта рассчитываем ошибку некоторого хитрым образом вычисленного прогноза по сравнению с идеальным ответом yi-тое. Давайте чуть подробнее посмотрим, как вычисляется этот прогноз. В начале в нем стоит дробь, которая показывает, какая доля объектов в случайном лесе не обучалась на объекте xi-тое. По сути, в знаменателе стоит сумма по всем деревьям индикаторов того, что i-тый объект не входил в обучающую выборку для этого дерева. Итак, перед суммой стоит доля деревьев, которые не обучались на объекте xi-тое. Сумма у нас происходит по всем деревьям от 1 до N большого, и для каждого дерева мы прибавляем 0, если данное дерево обучалось на объекте xi-тое, и прогноз данного дерева на объекте xi-тое, если он не использовался при обучении данного дерева. В итоге прогноз вычисляется, как средний ответ по всем деревьям на данном объекте, которые не обучались на нем. Также с помощью оценки out-of-bag можно оценивать важность признаков. И на самом деле случайные леса очень хорошо позволяют отбирать самые важные признаки, но об этом мы будем говорить уже в следующем курсе нашей специализации. Итак, мы обсудили две особенности случайного леса. Первая состоит в том, что он идеально параллелится. Каждое дерево строится независимо, и поэтому его можно строить на своем ядре или на своем компьютере. Также при обучении каждого отдельного дерева в случайном лесе используется не вся обучающая выборка, а лишь некоторое ее подмножество, а те объекты, которые не использовались при обучении, можно использовать для оценивания качества случайного леса. Этот подход называется out-of-bag, и он позволяет избежать использования дополнительной отложенной выборки или кросс-валидации. И при этом можно показать, что out-of-bag оценка очень неплохо приближает оценку, вычисленную по кросс-валидации. На этом урок про случайные леса окончен. На следующем уроке мы поговорим о другом подходе к построению композиций — о градиентном бустинге.

 Привет! В этом видео мы займемся построением модели «случайный лес» с помощью модуля sklearn.ensemble. Анализировать случайный лес мы будем на очень интересном наборе данных — это данные задачи bioresponse на kaggle. По данным характеристикам молекулы нам требуется предсказать, будет ли дан биологический ответ. Всего нам доступно 1776 характеристик молекулы, при этом матрица признаков нормализована. Для работы мы будем использовать обучающую выборку с сайта kaggle — она также доступна, называется train_csv. Для начала давайте загрузим файл и проанализируем данные. Анализировать данные будем в виде дейтафрейма, загружаем данные в виде... с помощью функции read_csv. Теперь давайте посмотрим, как они выглядят. Получили такую таблицу. В первом столбце мы видим нашу целевую переменную — она принимает значение 1 или 0, в зависимости от того, был ли дан биологический ответ. Все остальные столбцы соответствуют признакам. Давайте посмотрим размер нашей матрицы. Да, мы видим, что нам доступны данные о 3751 молекуле. Итак, давайте выведем названия колонок. Да, видим, что все данные называются большой буквой D и дальше индексом — номером признака. Так, теперь давайте отдельно отрежем целевую переменную — нам так удобней будет анализировать данные, и заодно сразу же посчитаем распределение наших объектов по классам. Ну вот видим, что задача почти сбалансирована. Теперь давайте отдельно отрежем данные, и вся подготовительная работа закончена. Теперь можно переходить непосредственно к построению модели. Построить модель RandomForest с помощью sklearn очень просто — для этого достаточно создать объект класса RandomForestClassifier с нужными параметрами. А также несложно применить и обучить эту модель — для этого нужно воспользоваться уже известными вам методами fit и predict. С другой стороны, анализировать качество модели, а то и параметров, вы тоже уже умеете. Это можно делать с помощью поиска по сетке или случайного поиска. Давайте мы не будем этого делать, а вместо этого решим другую задачу — проанализируем, как зависит качество модели от количества обучающих объектов выборки. Для этого давайте создадим нашу модель. Для начала будем строить случайный лес над 50 деревьями, каждый из которых будет иметь глубину не больше 2. Создаем такой объект. И теперь давайте построим следующий график — нам будет интересно посмотреть, как меняется качество на обучающей и тестовой выборке, в зависимости от того, на скольких объектах мы обучаемся. Для того чтобы получить такие графики, у sklearn есть специальная функция под названием learning_curve. Она позволяет нам сделать следующее — ей можно передать на вход нужный нам алгоритм, передать данные и целевую функцию, а также сказать, в каких пропорциях мы хотим обучаться, то есть на каких долях обучающей выборки мы хотим строить модель. После этого с помощью этого метода будут построены несколько моделей, мы получим оценку качества на каждом объеме обучающей выборки, и нам будут возвращены размер обучающей выборки, оценки качества на «трейне» и оценка качества на тесте. Имея такие данные, мы легко сможем проанализировать, как качество на обучении и тесте меняется от объема обучающей выборки. Вот давайте сделаем такую вещь. Мы передаем в функцию наш классификатор, который мы создали ранее. Далее передаем туда данные, которые мы также подготовили на предварительном шаге. И говорим, что мы будем обучать модель на следующих данных: сначала мы возьмем 0,1 от обучающей выборки и далее будем двигаться с шагом 0,2 до 1. Оценивать качество будем с помощью уже знакомой нам метрики accuracy и будем делать кросс-валидацию на 3 фолда. Давайте запустим. Процесс занимает некоторое время, потому что обучаются довольно много моделей. И теперь давайте посмотрим, как выглядит вывод нашей функции. Ну для начала мы видим, что train_sizes — размер обучающей выборки — был преобразован из долей в конкретное количество объектов, на которых мы обучались. То есть мы видим, что минимальное количество обучающих объектов в рамках нашего эксперимента составляет 250, максимальное — 2250. Также нам доступны оценки качества на обучении и оценки качества на тесте. Так как у нас проводилась кросс-валидация, я сразу же сделала усреднение по всем фолдам — это делается с помощью команды mean. Аргумент axis = 1 означает, что мы будем усреднять по строчкам. Вот в данном случае каждая строка — это результат измерения кросс-валидации, поэтому нам это подходит. Теперь давайте построим график. Сразу добавим на график сетку и будем строить две кривые — качество обучения на обучающей выборке и на тестовой выборке. Давайте посмотрим. Так, мы видим, что в начале качество на обучающей выборке падает — приблизительно до отметки 1250 деревьев, и дальше качество меняется очень медленно. С другой стороны, на тестовой выборке качество продолжает расти приблизительно до этой же точки, и дальше оно также перестает меняться. Какой вывод мы можем сделать из этого? Дальнейший рост обучающей выборки вряд ли скажется на качестве нашей модели. Это говорит о том, что модель данной сложности не может многое выиграть за счет того, что мы обогатим данные. Что же делать в такой ситуации? Давайте попробуем увеличить сложность модели — возможно, это приведет к улучшению ее качества. Так как мы с вами обучали модель на деревьях глубины 2, давайте увеличим глубину деревьев — это даст нам дополнительные возможности. Снова создаем классификатор RandomForestClassifier, но в этот раз указываем ему параметр max_depth = 10 — это максимально возможная глубина деревьев. Теперь давайте еще раз запустим команду learning_curve и построим кривую обучения на тесте и на обучении, при этом мы будем делать это по тем же самым точкам, по тем же самым долям обучающей выборки. [ЗВУК НАЖАТИЯ КЛАВИШИ] Итак, наши данные готовы, теперь строим график. Здесь мы видим в некоторой степени противоположную ситуацию — мы видим, что с ростом обучающей выборки, качество на тесте продолжает расти. В конце оно начинает расти несколько медленнее, но тем не менее тренд заметен. То же самое можно сказать про обучение — качество на обучающей выборке продолжает падать не очень быстро. Отсюда мы можем сделать вывод, что модель данной сложности действительно получает некоторые преимущества от того, что мы добавляем объекты в обучение. Таким образом, в данном случае имеет смысл увеличивать объем обучающей выборки. Объем обучающей выборки и сложность модели значительно сказываются на времени построения модели. С этой точки зрения строить кривые обучения очень полезно — вы можете проанализировать, имеет ли смысл добавлять больше данных в обучение. А мы на этом заканчиваем. На этом уроке мы познакомились с RandomForest, научились строить его в sklearn, а также проанализировали кривые обучения для деревьев различной глубины. На этом мы заканчиваем изучение RandomForest, а в следующем модуле вы познакомитесь с алгоритмом градиентного бустинга.

Случайные леса
В прошлом уроке изучались решающие деревья и было установлено, что они способны восстанавливать очень
сложные закономерности, следовательно, склонны к переобучению. Другими словами, деревья слишком легко
подгоняются под обучающую выборку и получаются непригодными для построения прогнозов.
Но оказывается, решающие деревья очень хорошо подходят для объединения в композиции и построения
одного непереобученного алгоритма на основе большого количества решающих деревьев.
8.1. Композиции деревьев
8.1.1. Основные недостатки решающих деревьев
Если взять сложную выборку и обучить на ней решающее дерево до конца, то есть пока в каждом из лепестков
не останется по одному объекту, получившаяся разделяющая поверхность будет очень сложной:
Даже если какой-то объект попадает в «гущу другого класса», разделяющая поверхность пытается «уловить»
его и выдать на нем правильный ответ.
1
Если немного изменить обучающую выборку, например выкинуть пару объектов, то обученное на получившейся выборке дерево все еще будет характеризоваться изрезанной и переобученной разделяющей поверхностью, но совершенно другой:
Разделяющая поверхность крайне неустойчива к изменению выборки. Другими словами, решающее дерево
обладает следующими серьезными недостатками:
• сильно переобучается
• сильно меняется при небольшом изменении выборки
На самом деле, второй пункт можно будет превратить в достоинство с помощью композиции.
8.1.2. Композиция алгоритмов
Композиция — это объединение N алгоритмов b1(x), ..., bN (x) в один. Идея заключается в том, чтобы обучить
алгоритмы b1(x), ..., bN (x), а затем усреднить полученные от них ответы:
a(x) = 1
N
X
N
n=1
bn(x).
Это выражение непосредственно является ответом в задаче регрессии. В задачах классификации нужно будет
взять знак от получившегося выражения:
a(x) = sign 1
N
X
N
n=1
bn(x),
Алгоритм a(x), который возвращает среднее или знак среднего, называется композицией N алгоритмов b1(x), ..., bN (x),
а они сами называются базовыми алгоритмами.
Например, пусть при решении задачи классификации с двумя классами использовались 6 базовых алгоритмов, которые на некотором объекте x выдали следующие ответы:
−1, −1, 1, −1, 1, −1.
Ответ композиции этих 6 алгоритмов будет:
a(x) = sign 
−
2
6

= −1.
2
Попросту говоря, объект был отнесен к классу −1, так как за этот вариант «проголосовало» большинство
базовых алгоритмов.
8.1.3. Рандомизация
Чтобы построить композицию, нужно сначала обучить N базовых алгоритмов, причем их нельзя обучать на
всей обучающей выборке, так как в этом случае они получаются одинаковыми, и в их усреднении не будет
никакого смысла.
Использовать рандомизацию, то есть обучать базовые алгоритмы на разных подвыборках обучающей
выборки, — это один из способов сделать базовые алгоритмы различными. А поскольку решающие деревья сильно меняются даже от небольших изменений обучающей выборки, такая рандомизация значительно
повышает различность базовых алгоритмов.
Так называемый бутстрап — один из популярных подходов к построению подвыборок. Он заключается
в том, что из обучающей выборки длины ` выбирают с возвращением ` объектов. При этом новая выборка
также будет иметь размер `, но некоторые объекты в ней будут повторятся, а некоторые объекты из исходной выборки в нее не попадут. Можно показать, что в бутстрапированной выборке будет содержаться в
среднем 63% различных объектов исходной выборки.
Другой подход к рандомизации — генерация случайного подмножества обучающей выборки. Размер этого
случайного подмножества является гиперпараметром. Например, можно случайно взять половину исходной
выборки и обучить на ней базовый алгоритм. Этот подход несколько проигрывает бутстрапу, так как содержит гиперпараметр, в то время как бутстрап без какой-либо настройки выдает подвыборку.
8.1.4. Композиция деревьев
Если с помощью бутстрапа построить 100 базовых решающих деревьев и объединить их в композицию, разделяющая поверхность будет все еще сложная, но уже гораздо менее переобученная:
Разделяющая поверхность уже не подгоняется под большую часть попавших в гущу чужого класса объектов
и в целом хорошо разделяет два класса. Увеличением количества базовых алгоритмов можно устранить
оставшиеся погрешности.
3
8.2. Смещение и разброс
В этом разделе речь пойдет о разложении ошибки на шум, смещение и разброс. Эта техника позволяет глубже
понять причины, почему усреднение алгоритмов позволяет повысить качество.
8.2.1. Разложение ошибки: шум, смещение и разброс
Ошибка алгоритма на новых тестовых данных складывается из трех компонент: шума, смещения и разброса.
При этом все они характеризуют разные аспекты данных и модели, с помощью которой решается задача на
этих данных:
• Шум — компонента ошибки алгоритма, которая будет проявляться даже на идеальной модели в этой
задаче. Другими словами, шум является характеристикой данных и будет проявляться, какая бы модель
не использовалась.
Пусть обучающая выборка генерируется из некоторого вероятностного распределения. На каждой конкретной
обучающей выборке можно обучить некоторую модель и использовать обученную модель на тестовой выборке.
• Cмещение — отклонение, усредненного по различным обучающим выборкам, прогноза заданной модели от прогноза идеальной модели.
• Разброс — дисперсия ответов моделей, обученных по различным обучающим выборкам. Разброс характеризует то, насколько сильно прогноз алгоритма зависит от конкретной обучающей выборки.
Продемонстрировать разложение ошибки на смещение и разброс можно на следующем примере. Рассматривается задача регрессии: требуется аппроксимировать истинную зависимость (изображена на правом
графике зеленым) полиномом третьего порядка по обучающей выборке. Обучающая выборка представляет
собой 10 случайных точек истинной зависимости, к которым был добавлен случайный шум. На левом графике
изображены полиномы, получающиеся для различных обучающих выборок.
Усредненный полином (изображен красной линией на правом рисунке) практически идеально попадает в
истинную зависимость, но каждый полином по отдельности существенно от нее отличается. Другими словами,
используемое семейство алгоритмов обладает низким смещением, но довольно большим разбросом.
Линейные модели способны восстанавливать только линейные зависимости, а, следовательно, в случае
нелинейных задач, которых подавляющее большинство, смещение при использовании таких алгоритмов будет большим. Разброс, наоборот, будет маленьким из-за малого числа параметров, сравнимого с количеством
признаков. Вряд ли параметры линейной модели сильно поменяются при незначительном изменении обучающей выборки. Решающие деревья — полная противоположность. Они характеризуются низким смещением, то
есть способны восстанавливать сложные закономерности, и большим разбросом: решающие деревья сильно
меняются даже при небольших изменениях обучающей выборки.
8.2.2. Смещение и разброс композиции алгоритмов
При вычислении композиции базовых алгоритмов (с одинаковым смещением) смещение композиции совпадает
со смещением отдельного базового алгоритма. Таким образом, поскольку деревья характеризуются низким
4
смещением, то же самое будет верно и для композиции деревьев. Следовательно, композиции деревьев тоже
способны восстанавливать сложные закономерности.
Разброс композиции уже отличается от разброса одного базового алгоритма:

разброс
композиции
=
1
N

разброс одного
базового алгоритма
+
 корелляция между
базовыми алгоритмами
.
Если базовые алгоритмы независимы, то есть их прогнозы не коррелируют между собой, выражение упрощается:

разброс
композиции
=
1
N

разброс одного
базового алгоритма
.
Фактически, композиция достаточного количества некоррелированных алгоритмов может дать идеальный
алгоритм. Но, к сожалению, базовые алгоритмы всегда получаются в той или иной степени коррелированы,
так как обучаются на подвыборках одной выборки. Таким образом, возникает необходимость уменьшения
корелляции базовых алгоритмов.
8.2.3. Уменьшение корреляции базовых алгоритмов
Существуют следующие два подхода по уменьшению корреляции базовых алгоритмов:
1. Беггинг: Обучение базовых алгоритмов происходит на случайных подвыборках обучающей выборки.
Причем чем меньше размер случайной подвыборки, тем более независимыми получаются базовые алгоритмы.
2. Метод случайных подпространств: выбирается случайное подмножество признаков (столбцов матрицы «объекты–признаки») и очередной базовый алгоритм обучается только на этих признаках. Доля
выбираемых признаков является гиперпараметром этого метода.
Два данных подхода — бэггинг и метод случайных подпространств — можно объединять и использовать
одновременно.
8.3. Случайные леса
В этом разделе речь пойдет о случайных лесах, которые являются одним из лучших способов объединения
деревьев в композиции.
8.3.1. Случайный лес
Ранее были получены следующие результаты:
• Ошибка может быть разложена на смещение и разброс.
• Смещение композиции близко к смещению одного базового алгоритма.
• Разброс при построении композиции уменьшается, причем тем сильнее, чем менее коррелированы базовые алгоритмы.
Рассмотренных в прошлый раз способов понижения корреляции между базовыми алгоритмами (бэггинг и
метод случайных подпространств) оказывается недостаточно. Чтобы базовые алгоритмы были еще менее
скореллированными, имеет смысл сделать случайным их процесс построения.
8.3.2. Рандомизация процесса построения решающих деревьев
Процесс построения решающих деревьев представляет собой жадный алгоритм, работающий до выполнения
критерия останова.
Пусть на некотором шаге алгоритма необходимо разбить вершину m, в которой оказалась выборка Xm,
на две. В качестве условия разбиения используется сравнение j-го признака с порогом t:
[x
j ≤ t].
Параметры j и t выбираются исходя из условия минимизации функции ошибки Q(Xm, j, t):
Q(Xm, j, t) → min
j,t
.
Рандомизировать процесс построения можно, если в задаче поиска оптимальных параметров выбирать j
из случайного подмножества признаков размера q. Оказывается, что этот подход действительно позволяет
сделать деревья менее коррелированными.
Рис. 8.1: Зависимость корреляции между деревьями от параметра q
По графику видно, что чем меньше «простор для выбора лучшего разбиения», то есть чем меньше q, тем
меньше корреляции между получающимися решающими деревьями. Случай q = 1 соответствует абсолютно
случайному выбору признака.
Для q есть некоторые рекомендации, которые неплохо работают на практике:
• В задаче регрессии имеет смысл брать q = d/3, то есть использовать треть от общего числа признаков.
• В задаче классификации имеет смысл брать q =
√
d.
8.3.3. Алгоритм построения случайного леса
Чтобы построить случайный лес из N решающих деревьев, необходимо:
1. Построить с помощью бутстрапа N случайных подвыборок X˜
n, n = 1, ..., N.
2. Каждая получившаяся подвыборка X˜
n используется как обучающая выборка для построения соответствующего решающего дерева bn(x). Причем:
• Дерево строится, пока в каждом листе окажется не более nmin объектов. Очень часто деревья
строят до конца (nmin = 1), чтобы получить сложные и переобученные решающие деревья с низким
смещением.
• Процесс построения дерева рандомизирован: на этапе выбора оптимального признака, по которому
будет происходить разбиение, он ищется не среди всего множества признаков, а среди случайного
подмножества размера q.
• Следует обратить особое внимание, что случайное подмножество размера q выбирается заново каждый раз, когда необходимо разбить очередную вершину. В этом состоит основное отличие такого
подхода от метода случайных подпространств, где случайное подмножество признаков выбиралось
один раз перед построением базового алгоритма.
3. Построенные деревья объединяются в композицию:
• В задачах регрессии a(x) = 1
N
PN
n=1 bn(x);
• В задачах классификации a(x) = sign 1
N
PN
n=1 bn(x).
6
Одна из особенностей случайных лесов: они не переобучаются при росте числа базовых алгоритмов.
Рис. 8.2: Зависимость качества случайного леса от значения параметра q.
По графику видно, что ошибка на тесте сначала уменьшается с ростом числа базовых алгоритмов, а затем
выходит на асимптоту. Не происходит роста ошибки при росте числа базовых алгоритмов.
8.4. Трюки со случайными лесами
Случайный лес обладает рядом интересных особенностей.
8.4.1. Возможность распараллеливания
Поскольку каждое дерево обучается независимо от всех остальных базовых решающих деревьев, его можно
обучать на отдельном ядре или отдельном компьютере.
Фактически, данная задача допускает идеальное распараллеливание: скорость вычислений пропорциональна количеству задействованных вычислительных ядер.
8.4.2. Оценивание качества случайного леса
Каждое дерево из случайного леса обучается на бутстрапированной выборке, в которую попадают приблизительно 63% объектов полной выборки. Таким образом, около 37% объектов выборки не использовались при
обучении этого дерева, а значит их можно использовать для оценки обобщающей способности случайного
леса.
Такой подход носит название out-of-bag и позволяет оценивать качество леса без использования отложенной выборки или кросс-валидации. Формула для оценки качества случайного леса из N деревьев в рамках
подхода out-of-bag имеет вид:
OOB =
X
`
i=1
L

yi
,
1
PN
n=1[xi ∈/ Xn]
X
N
n=1
[xi ∈/ Xn]bn(xi)
!
.
Эта формула устроена следующим образом. Для каждого объекта xi из обучающей выборки вычисляется
средний прогноз по тем деревьям, в обучающую выборку которых не входит объект xi
:
1
PN
n=1[xi ∈/ Xn]
X
N
n=1
[xi ∈/ Xn]bn(xi).
Для полученного прогноза вычисляется значение ошибки. В качестве оценки качества случайного леса используется сумма таких значений для всех элементов выборки.
Также с помощью случайных лесов и out-of-bag можно отбирать наиболее важные признаки. Об этом
пойдет речь в следующем курсе.
