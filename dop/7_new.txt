Нейронные сети

В этом уроке речь пойдет о нейронных сетях вообще и в частности об однослойной нейронной сети. Нейронная сеть — это универсальная модель, решающая широкий класс задач регрессии и классификации. Задана выборка, множество пар «объект – ответ». Объект — это множество признаков в d-мерном пространстве, вектор, а ответ зависимой переменной y — это скаляр. Требуется построить аппроксимирующую поверхность, которая приближает ответы описаниями объектов. Рассмотрим задачу регрессии. На рисунке показана поверхность, которая оценивает риск в задаче страхования и финансов. По оси абсцисс и ординат — время до страхового случая и цена страховки. По оси аппликат — ожидаемый риск. Наша поверхность — нейронная сеть — аппроксимирует исторический риск y в точках x. Другие задачи регрессии: x — вектор исторических цен потребления электроэнергии, y — цена электроэнергии в следующий час; x — векторизованный снимок поверхности земли со спутника, y — объем зеленых насаждений; x — история продаж товара, y — уровень потребительского спроса. Рассмотрим задачу классификации. В этой задаче зависимая переменная y принадлежит конечному множеству и называется меткой класса. Требуется построить разделяющую поверхность, которая отделяет объекты одного класса от объектов другого класса таким образом, что при значении функции разделяющей поверхности большей нуля мы бы аппроксимировали объекты класса 1, а при меньшей нуля — объекты класса −1. На графике по осям показаны значения признаков x1 и x2, а значения функции a или значение метки класса y оно показано на нас в третьем измерении. И мы видим, толстая линия отделяет объекты синего класса от объектов оранжевого класса и как раз это и есть наша разделяющая поверхность a(x). Примеры задач классификации: x — временной ряд акселерометра мобильного телефона, y — вид физической активности; x — страница документа, y — релевантность этого документа по поисковому запросу; x — нотная запись в музыкальном произведении, y — это следующая нота, которая предполагается к проигрыванию. Что такое универсальная модель? Мы считаем нейронную сеть универсальной моделью, потому что она может аппроксимировать любые поверхности. В 1957 году Андрей Николаевич Колмогоров сформулировал следующую теорему: каждая непрерывная функция a(x), заданная на единичном кубе в d-мерном пространстве, представима в виде суперпозиции суммы функции σ от суммы функции f, где x — это наш вектор описания объекта в d-мерном пространстве. При этом функции σ и f должны быть непрерывны, и f не зависит от выбора a, что дает нам возможность конструировать различные нейронные сети. Иначе, другими словами, функцию от многих аргументов можно представить в виде суперпозиции многих функций от одного аргумента. Что такое единичный куб d-мерного пространства? Этот куб включает наши измерения, элементы выборки, которые аппроксимирует наша нейронная сеть. Если измерения — элементы вектора x — сделаны в различных шкалах, в разных шкалах (например, килограммы, амперы, секунды), то их следует обезразмерить. Например, отобразить измерения каждого из признаков в отрезок [0, 1]. Важно понимать, что Колмогоров не указал, какими именно должны быть функции σ и f, и это оставляет проблему конструирования нейронной сети очень острой и сложной. Рассмотрим однослойную сеть как единственный нейрон. Однослойная нейронная сеть или нейрон — это комбинация весов признаков или скалярное произведение объекта на вектор весов. σ — это наша функция активации, какая-то непрерывная монотонная функция, желательно дифференцируемая; w — это вектор параметров (или весов) признаков; x — это объект, это вектор с присоединенной единичкой, которая соответствует специальному весу w0, а этот вес регулирует положение нашей аппроксимирующей функции a относительно оси y. Нейрон можно графически представить в виде двудольного графа, в котором листья — это независимые переменные, а вершинка — это линейная комбинация и наша функция активации. Рассмотрим два примера использования нейронной сети как линейной модели. Первый пример — это задача регрессии, и в этой задаче функция активации тождественна алгебраической единице: что на входе, то и на выходе, и наша функция является линейной комбинацией значений признаков. Вторая задача — это задача классификации, в ней функция активации, пороговая функция сигнум от линейной комбинации. И мы говорим, что мы считаем объект крестиком, если функция, значение функции больше нуля, в противном случае, если она меньше нуля, то мы считаем объект ноликом. Однослойная нейронная сеть является моделью логистической регрессии, если мы используем сигмоидную функцию активации 1 поделить на 1 плюс экспонента от отрицательного скалярного произведения. Эта функция определяет вероятность принадлежности некоторого заданного объекта x к классу y равным единице при заданных параметрах w. На графике по осям абсцисс и ординат отложены значения признаков, точки — это объекты, y — это наши метки классов, и нашу выборку аппроксимирует как раз вот эта функция — сигмоидная функция активации от скалярного произведения. Для случая нескольких классов используется функция активации softmax. При этом сеть состоит из K одинаковых нейронов, и каждый нейрон вычисляет вероятность принадлежности к своему классу, а вся сеть вычисляет вероятность принадлежности объекта x к различным K классам одновременно. Какие есть еще виды функции активации? Гиперболический тангенс — это обобщение пороговой функции сигнум, которое может быть продифференцировано. Более мягкий вариант гиперболического тангенса — это функция активации softsign, которая сходится как и гиперболический тангенс к ±1, но данная функция она сходится медленнее, чем гиперболический тангенс. В сетях глубокого обучения, в более сложных нейронных сетях используются функция выпрямитель ReLu, работает как диод в радиоэлектронике, и эта функция она не дифференцируема, но имеет дифференцируемое приближение ln(1 + exp(x)). Итого: нейронная сеть — это универсальная модель, предназначенная для решения широкого класса задач регрессии и классификации, то есть для обучения с учителем. Нейрон, или однослойная нейронная сеть — это функция активации от линейной комбинации признаков объекта. При построении нейронной сети используются различные функции активации. Дальше двуслойные и многослойные нейронные сети.

В этом уроке мы обсудим многослойную нейронную сеть и различные функции ошибок. Однослойные нейронные сети, которые мы обсуждали ранее, применимы только для линейно разделимых выборок. Например, для конфигурации, представленной на графике, невозможно найти такую плоскость, которая разделяет крестики от ноликов. А для конкретного разделения этой выборки лучше всего подходит кривая линия. Рассмотрим двухслойную нейронную сеть. Двухслойная нейронная сеть — это линейная комбинация нейронов или однослойных нейронных сетей. Каждый нейрон — это линейная комбинация, которая представлена внутри внутренних скобок, и таких нейронов здесь D (большое). Внешние скобки — это как раз линейные комбинации или веса этих нейронов — нейронов первого слоя. σ со значком 2 — это функция активации второго слоя нейронной сети. Или то же самое в векторных обозначениях: двухслойная нейронная сеть — это следующая суперпозиция: функция активации σ со значком 2 (функция активации второго слоя), аргументом этой функции являются веса (вектор весов второго слоя), умноженные скалярно на сигмы функции активации первого слоя, а аргументом каждого элемента вектора σ первого слоя является скалярное произведение, то есть один из D (большое) нейронов первого слоя. Так как нейронная сеть — это параметрическое семейство функций, то вектор параметров нейронной сети получается соединением всех параметров нейронной сети на всех слоях. Двухслойную нейронную сеть можно представить в виде двух двудольных направленных графов, где исходящая вершина графа связана со всеми входящими вершинами. Этот граф можно дальше продолжать вправо для получения многослойной нейронной сети. В 1991 году Курт Хорник сформулировал Универсальную теорему аппроксимации, которая говорит, что для любой непрерывной функции найдется нейронная сеть a с линейным выходом, которая аппроксимирует эту функцию с заданной точностью. Теорема выполняется для различных функций активации, в частности для функции сигмоид и функции гиперболический тангенс. Для получения же заданной точности необходимо, кроме построения конфигурации нейронной сети, определить ее оптимальные параметры. Рассмотрим проблему качества аппроксимации с помощью следующего графика. На нем по осям абсцисс и ординат отложено значение признаков: x1 и x2. Объекты — синими и оранжевыми кружочками. Искомая неизвестная нам разделяющая поверхность показана пунктирной линией. Текущее значение разделяющей поверхности a, которая зависит от наших объектов x и от вектора параметров w, показана жирной линией, а несколько объектов попали в область, которая принадлежит другому классу вследствие случайной природы выборки. Тем не менее именно вот эту разделяющую поверхность мы называем оптимальной. Сравним ее с другой разделяющей поверхностью. В данном случае веса в той же самой нейросети настроены таким образом, что разделяют текущую выборку корректно, то есть все объекты принадлежат областям своего класса, но при небольшом изменении состава выборки разделение будет неверным и ошибка аппроксимации будет больше. Сеть, которая корректно аппроксимирует текущую обучающую выборку, но плохо аппроксимирует контрольную или какую-то другую выборку той же природы, называется переобученной. Сформулируем задачу нахождения оптимальных параметров нейросети как задачу оптимизации. Введем функцию ошибки Q, которая зависит от параметров. Также она, естественно, зависит от состава нашей выборки и от конфигурации нейросети. Какие есть функции ошибки? Функция ошибки для задачи регрессии называется функция «галочка», или сумма моделей разности между восстановленным значением и фактическим значением зависимой переменной y. Такая функция используется при решении прикладных задач в различных областях, например в финансах или при выполнении технических, физических, химических измерений. Это абсолютная разность между фактом и восстановленным значением. Но эта функция не дифференцируема. Есть дифференцируемая функция ошибки — это сумма квадратов разности между восстановленным значением и фактическим измерением. Для решения задачи классификации важно знать суммарное число несовпадений между восстановленными метками классов и фактическими метками классов. Такая функция ошибки называется «0–1 loss», и здесь квадратными скобками в этом выражении обозначена индикаторная функция. Она возвращает единичку, если выражение истинно, и нолик, если выражение внутри этих скобок ложно. Дифференцируемая функция ошибки в задаче классификации — это функция кросс-энтропия — функция наибольшего правдоподобия в задаче логистической регрессии, которую мы рассматривали ранее. Все 3 функции показаны на графике. В случае задачи регрессии мы видим «галочку» и аппроксимирующую ее непрерывную дифференцируемую функцию параболу (квадрат). В случае пороговой функции «0–1 loss» мы видим аппроксимирующую ее кросс-энтропийную функцию. Итак, с помощью многослойной нейронной сети можно получить аппроксимацию сколь угодно высокой точности. Для этого надо построить оптимальную структуру нейросети и оптимизировать ее параметры. Параметры оптимизируются с помощью минимизации функции ошибки. Существуют дифференцируемые функции ошибки для оптимизации ее параметров. Далее мы рассмотрим различные алгоритмы оптимизации параметров нейронной сети.

В этом уроке мы поговорим об алгоритмах оптимизации параметров нейронной сети. Задача оптимизации параметров — это задача минимизации функции ошибки. Функция ошибка... функция ошибки зависит от выборки, от структуры нейросети, то есть числа слоев, нейронов, видов функций активации, и от значения вектора параметров. На графике показана функция ошибки для двух параметров: по оси абсцисс и ординат отложено значение этих параметров, а по оси аппликат — значение функции ошибки. Функция ошибки может иметь значительное число локальных минимумов, которые даже в пространстве малой размерности нелегко обнаружить. Есть два типа алгоритмов: алгоритмы стохастической оптимизации и алгоритмы градиентного спуска. В случае стохастической оптимизации мы случайно перебираем решения вектора параметров w там, где они могут доставить минимум функции ошибки, например, случайным перебором или с помощью генетического алгоритма, который последовательно модифицирует значения вектора параметров. Или с помощью моделируемого отжига, который изменяет значения параметров по расписанию и сначала ищет минимум в широкой области, а потом сужает область поиска до нахождения глобального минимума. Алгоритм локальной аппроксимации функции ошибки минимизирует не саму функцию ошибки, а функцию, которая ее аппроксимирует в окрестности точки w. Например, удобно аппроксимировать с помощью квадратичной функции. В многомерном случае эта квадратичная форма... в многомерном случае эта квадратичная функция имеет вид квадратичной формы. На каждом шаге алгоритма мы находим минимум такой функции и сдвигаем окрестность, в которой продолжаем аппроксимацию и поиск минимума исходной функции. Алгоритм градиентного спуска предполагает, что функция ошибки дифференцируема, то есть она квадратичная или кросс-энтропийная, и, задавая значения параметров w, можно вычислить значение функции ошибки и ее градиент. На рисунке по оси абсцисс и ординат показано значение параметров — у нас опять двумерное пространство параметров, по оси аппликат показано значение функции ошибки. И требуется, отправляясь из исходной точки wC, спуститься к точке минимума wB, шагая в направлении от градиента — ∇ с индексом w Q. При этом, конечно же, надо помнить, что точка wB может оказаться как глобальным минимумом, так и локальным минимумом, как, например, точка w с индексом A. Градиентный спуск — это пошаговая процедура нахождения параметров. У нас каждый следующий шаг зависит от предыдущего и от суммы градиентов функции ошибки на одном-единственном объекте. Обозначим эту ошибку буквой φ, обозначим ее частную производную по параметрам ∇wφ. α — это величина шага, который мы делаем, и k — это номер итерации итерационной процедуры. Шагаем до тех пор, пока значение функции ошибки не стабилизируется. Вариант градиентного спуска — это стохастический градиентный спуск. Нам совсем не обязательно использовать всю выборку для вычисления градиента. Предлагается направление градиента вычислить для случайно выбранного объекта x, и, таким образом, наш градиентный спуск будет выглядеть следующим образом: wk +1 — это wk на предыдущем шаге + α — длина шага, ∇wφ — это градиент на единственном объекте. И данная процедура использует случайно переупорядоченные объекты и продолжается до стабилизации функции ошибки. Очень популярный и быстрый алгоритм — это алгоритм обратного распространения ошибки backpropagation, или backprop. Для каждого нейрона сети и одного объекта выборки x вычисляется значение выхода нейрона — оно зависит от выходов предыдущих нейронов, и это вычисление называется прямым распространением. И производную ошибки по значению нейрона и по его параметрам — эта производная зависит от значений последующих нейронов и называется обратным распространением. Существует проблема затухания градиента при обратном распространении: при больших значениях входов нейрона значения производной функции активации стремятся к 0, например, для сигмоидной функции и для гиперболического тангенса, как это показано на графиках. При этом градиент функции ошибки не распространяется по слоям. Преимущества и недостатки обратного распространения функции ошибки. Преимущества: градиент вычисляется за время, сравнимое с вычислением всей сети, алгоритм подходит для многих дифференцируемых функций активации и функции ошибки, необязательно использовать всю выборку. Но возможна медленная сходимость к решению, решение может быть в локальном минимуме и возможно переобучение сети. Итак, для оптимизации используются как стохастические, так и градиентные методы. Стохастические методы требуют многократного угадывания вектора параметров и могут работать довольно долго. Градиентные методы требуют дифференцирования функции ошибки, но могут застревать в локальных минимумах, и поэтому выбор метода оптимизации остается прикладным искусством и, конечно же, зависит от характера решаемой задачи. Далее мы поговорим о регуляризации и прореживании нейронной сети.

В этом уроке обсудим способы регуляризации и прореживания нейронной сети. Для того чтобы избежать переобучения, модифицируем задачу оптимизации и добавим к функции ошибки штраф за большие значения параметров. Чем меньше коэффициент регуляризации τ, коэффициент перед суммой значений параметров, тем точнее функция описывает выборку. Коэффициент регуляризации контролирует жесткость ограничений параметров. На рисунке слева коэффициент регуляризации имеет самое большое значение: у нас область поиска решения в пространстве параметров мала, но смещенность параметра от минимального значения функции ошибки велика. Справа мы видим, что область поиска оптимальных параметров велика, смещенности нет, но, возможно, наша сеть переобучена. В центре мы видим компромиссный вариант между смещенностью и областью поиска оптимальных значений параметров. То же самое можно показать с помощью следующего графика, здесь по оси абсцисс отложен коэффициент регуляризации, а по оси ординат — значения параметров. Видно, что регуляризация не снижает число параметров и не упрощает структуру сети. Более того, при увеличении коэффициента τ параметры перестают изменяться. Для снижения числа параметров предлагается исключить некоторые нейроны или связи. Таким образом, наш двудольный граф перестанет быть полносвязным. Принцип исключения следующий: если функция ошибки не изменяется, то сеть можно упрощать и дальше. Здесь на графике по оси абсцисс показано число удаленных связей или параметров, а по оси ординат показано значение функции ошибки. Видно, что мы удалили практически все параметры, и только в конце значение функции ошибки начало изменяться. Какие есть стратегии прореживания параметров в сети? Параметр можно удалить, если его вклад в нейрон равен нулю, то есть он сам имеет значение, близкое к нулю, дальше, если его значение сильно меняется при изменении выборки (у него большая дисперсия, то есть он реагирует на шум в данных) и если его удаление меньше всего влияет на изменение значения функции ошибки. Рассмотрим последний вариант подробней. Метод удаления параметров называется «метод оптимального прореживания» или «метод оптимального разрушения мозга». Разложим функцию ошибки в ряд Тейлора. При этом первое слагаемое при фиксированных параметрах будет константой, второе слагаемое будет нулем, потому что мы считаем, что мы находимся в оптимуме функции ошибки, третье слагаемое будем минимизировать, а четвертое слагаемое проигнорируем. Найдем такой параметр нейронной сети, для которого его изменение равно его значению, или по-другому: несмотря на его изменение, он имеет нулевой вклад в нейрон. Этот параметр имеет минимальное значение функции выпуклости, которая вычисляется как квадрат его величины, отнесенный к соответствующему диагональному элементу обратной матрицы Гессе — матрицы вторых производных, которые соответствуют третьему слагаемому нашего разложения. Каким образом строится нейронная сеть? Нейронная сеть, она используется в двух режимах: во-первых, режим обучения — при этом мы задаем структуру нейронной сети и оптимизируем ее параметры, и в режиме эксплуатации — при этом мы вычисляем значение, которое аппроксимирует нашу выборку при фиксированных параметрах. Для того чтобы задать нейронную сеть, требуется задать число слоев, число нейронов в каждом слое, тип функции активации в каждом слое, тип функции ошибки. И желательно, чтобы подготовленная выборка не содержала пропусков, а признаки были отнормированы. При обучении желательно следить за стабилизацией параметров сети и за скоростью обучения сети. По скорости обучения можно судить о соответствии выборки и нейронной сети. Если нейронная сеть будет слишком сложна, то она быстро переобучится, как, например, показывает желтая линия. Если выборка будет сложна или сильно зашумлена для нейронной сети, то нейронная сеть будет обучаться медленно, как показывает синяя линия. Если выборка по сложности соответствует нейронной сети, то, скорее всего, мы увидим красную линию — хорошую скорость обучения. Важно также следить за разницей между значениями функции ошибки на обучении и на контроле. Эта разница не должна быть существенной. Если она велика, то это значит, что нейронная сеть переобучилась и следует изменить ее сложность. Итак, регуляризация используется для снижения переобученности сети путем загрубления ее параметров. Оптимальное прореживание упрощает структуру сети, удаляя лишние параметры. Структура нейронной сети существенно зависит от решаемой прикладной задачи. Ее построение и оптимизация выполняются, как правило, экспериментальным путем.

Нейронные сети
10.1. Однослойная нейронная сеть
В этом уроке речь пойдет о нейронных сетях. Нейронная сеть — это универсальная модель, решающая широкий класс задач регрессии и классификации.
10.1.1. Нейронная сеть и задача регрессии
Пусть {(xi
, yi)}
`
i=1 — обучающая выборка в задаче регрессии, xi ∈ R
d — признаковое описание i-го объекта
выборки, yi ∈ R
1 — значение целевой зависимой переменной на i-ом объекте выборки. Требуется построить
поверхность a(x), аппроксимирующую неизвестную целевую зависимость.
Задача оценки риска в страховании и финансах — пример задачи регрессии. Признаками в данной задаче являются время до страхового случая x1 и цена страховки x2. Требуется оценить ожидаемый риск y.
Поверхность a(x), которая аппроксимирует исторический риск y в точках x, представлена на следующем
графике.
0
0.05
0.1
0.15
0.2
11
11.5
12
12.5
13
13.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
strike maturity
implied volatility
Рис. 10.1: Аппроксимирующая поверхность в задаче оценки риска.
Другие примеры задач регрессии a(x) 7→ y:
• x — вектор исторических цен потребления электроэнергии, y — цена электроэнергии в следующий час,
• x — векторизованный снимок поверхности земли со спутника, y — объем зеленых насаждений;
• x — история продаж товара, y — уровень потребительского спроса.
1
Рис. 10.2: Задача классификации с двумя признаками x1 и x2 (отложены по осям). На графике изображена
разделяющая поверхность, которая отделяет объекты синего класса от объектов оранжевого класса.
10.1.2. Нейронная сеть и задача классификации
В задачах классификации целевая переменная y принимает конечное множество значений и называется
меткой класса. Пусть {(xi
, yi)}
`
i=0 — обучающая выборка в задаче бинарной классификации, xi ∈ R
d и
yi ∈ {1, −1} — признаковое описание и метка класса для i-го объекта соответственно. Требуется построить
разделяющую поверхность
a(x) 7→ y ∈ {−1, 1},
которая отделяет объекты одного класса от объектов другого класса таким образом, что, если a(x) > 0, то
объект x принадлежит классу y = +1, и, если a(x) ≤ 0, то x принадлежит классу y = −1.
Другие примеры задач классификации a(x) 7→ y:
• x — временной ряд акселерометра мобильного телефона, y — вид физической активности;
• x — страница документа, y — релевантность этого документа по поисковому запросу;
• x — нотная запись в музыкальном произведении, y — это следующая нота, которая предполагается к
проигрыванию.
10.1.3. Нейронная сеть как универсальная модель
Нейронная сеть считается универсальной моделью, так как она способна аппроксимировать любые поверхности. Соответствующую теорему сформулировал в 1957 году Андрей Николаевич Колмогоров.
Теорема (А. Н. Колмогоров, 1957) Каждая непрерывная функция a(x), заданная на единичном кубе dмерного пространства, представима в виде
a(x) =
2
X
d+1
i=1
σi


X
d
j=1
fij (xj )

 ,
где x = [x1, . . . , xd]
T — вектор описания объекта, функции σi(·) и fij (·) являются непрерывными, а fij не
зависят от выбора a.
Согласно формулировке теоремы, функция a(x) определена только на единичном кубе, а, следовательно,
все элементы выборки должны лежать в нем. Это не является проблемой: всегда можно отмасштабировать
признаки так, чтобы на обучающей выборке каждый признак принимал значения из отрезка [0, 1].
Также следует отметить, что в теореме не указан конкретный вид функции σi и fij . Проблема конструирования нейронной сети остается сложной задачей до сих пор.
2
10.1.4. Однослойная нейронная сеть как единственный нейрон
Однослойная нейронная сеть, или нейрон, определяется выражением:
a(x, w) = σ(w
T x) = σ


X
d
j=1
w
(1)
j xj + w
(1)
0

 ,
где σ — функция активации, w — вектор параметров (весов), x — вектор описания объекта. Функция активации должна быть непрерывной, монотонной и, желательно, дифференцируемой функцией.
Следует обратить внимание, что для удобства x ∈ R
d+1 дополнен постоянным на всех объектах признаком
x0 = 1. Соответствующий ему вклад в скалярное произведение w
T x равен w0.
σ
...
x1
w1
x2
w2
xd
wd
1
w0
Рис. 10.3: Нейрон можно изобразить в виде вершины графа: он характеризуется своей функцией активации,
имеет один выход и множество входов.
10.1.5. Функции активации: нейронная сеть как линейная модель
При решении задачи линейной регрессии в качестве функции активации можно выбрать тождественную
функцию σ = id, тогда на выходе нейрона будет:
a(x, w) = w
T x,
то есть нейрон будет представлять собой линейный регрессор.
x
y
x
y
Рис. 10.4: Нейрон является линейным регрессором (график слева) или линейным классификатором (справа),
если выбрать в качестве функции активации тождественную функцию или sign соответственно.
При решении задачи линейной классификации в качестве функции активации следует использовать пороговую функцию σ = sign. В таком случае нейрон:
a(x, w) = sign(w
T x)
является линейным классификатором.
3
10.1.6. Функции активации: модель логистической регрессии
Однослойная нейронная сеть является моделью логистической регрессии, если в качестве функции активации
выбрана сигмоидная функция активации σ:
a(x, w) = σ(w
T x) = 1
1 + exp(−wT x)
.
Эта функция определяет вероятность принадлежности некоторого заданного объекта x к классу y = 1 при
заданных параметрах w:
σ(w
T x) = P(y = 1|w, x).
Рис. 10.5: Аппроксимирующая поверхность на графике построена с использованием сигмоидной функции
активации.
Если количество классов равно K:
y = [y
1
, . . . , yK]
T
,
то необходимо использовать сеть из K нейронов, каждый из которых вычисляет вероятность принадлежности
к своему классу. В качестве функции активации используется softmax:
σ = softmax(w
T
1 x, . . . , wT
Kx) = exp(w
T
k x)
PK
i=1 exp(wT
i x)
.
10.1.7. Функции активации: другие примеры
Гиперболический тангенс в качестве функции активации:
tanh(x) = exp(2x) − 1
exp(2x) + 1
представляет собой дифференцируемую альтернативу пороговой функции sign(·).
Существует еще более мягкий вариант: функция активации
softsign(x) = x
1 + |x|
,
как и tanh(x) стремится к ±1, но в отличие от него, сходится к этим значениям не так быстро.
4
-5 0 5
h
(
x
)
-1
-0.5
0
0.5
1
tanh(x)
hardtanh(x)
-5 0 5
h
(
x
)
-0.5
0
0.5
tanh(x)
σ(x)
softsign(x)
Рис. 10.6: Графики различных функций активации
В сетях глубокого обучения, в более сложных нейронных сетях, используются функция-выпрямитель
Rectified linear unit (ReLu):
ReLu(f) = max(0, f).
-5 0 5
h
(
x
)
0
1
2
3
4
5
tanh(x)
σ(x)
softsign(x)
ReLu
Рис. 10.7: Графики функций активации: ReLu(f) и ее дифференцируемого приближения.
Эту функция ведет себя также, как работает диод в радиоэлектрических цепях. Данная функция не
дифференцируема, но имеет следующее дифференцируемое приближение:
ln(1 + exp(f))
10.2. Многослойная нейронная сеть. Функция ошибки
В этом уроке будет рассказано про двухслойную нейронную сеть и про различные функции ошибок.
10.2.1. Пределы применимости однослойных сетей
Однослойные сети применимы только для линейно разделимых выборок.
5
Рис. 10.8: Два примера линейно неразделимых выборок.
10.2.2. Двухслойная нейронная сеть
Двухслойная нейронная сеть представляет собой линейную комбинацию из D нейронов (однослойных нейронных сетей):
a(x, w) = σ
(2) 

X
D
i=1
w
(2)
i
· σ
(1) 

X
d
j=1
w
(1)
ji xj + w
(1)
0i

 + w
(2)
0

 .
Это выражение можно переписать в векторных обозначениях:
a(x, w) = σ
(2) 
w
T (2)
σ
(1) 
[w
T
1
(1)
x, . . . , wT
D
(1)
x]
 .
Вектор w параметров нейронной сети получается соединением всех параметров нейронной сети на всех слоях:
w = {W(1), w(2)},
где:
W(1) = [w
(1)
0
, w
(1)
1
, . . . , w
(1)
d
]
T ∈ R
(d+1)×D,
w
(1)
i = [w
(1)
0i
, w
(1)
1i
, . . . , w
(1)
di ]
T ∈ R
d+1, w(2) = [w
(2)
0
, w
(2)
1
, . . . , w
(2)
D ]
T ∈ R
D+1
.
x1
w
(1)
11
w
(1)
d1
w
(1)
01
xd
1
z1
zD
1
a(x)
w
(2)
1
w
(2)
D
w
(2)
0
Рис. 10.9: Изображение двухслойной нейронной сети с помощью направленного графа.
Продолжая по аналогии, можно получить трехслойную и многослойную нейронные сети.
6
10.2.3. Разделяющая способность многослойной нейронной сети
Теорема (Универсальная теорема аппроксимации, К. Hornik, 1991) Для любой непрерывной функции f(x) найдется нейронная сеть a(x) c линейным выходом a(x, W) = σ
(M)
(x), где
f
(k)
(x) = w
(k)
0 + W(k)
z
(k−1)(x), z(k)
(x) = σ
(k)
(f
(k−1)(x)),
аппроксимирующая f(x) c заданной точностью.
Теорема выполняется для различных функций активации, в частности для функции сигмоид и функции
гиперболический тангенс. Чтобы получить требуемую аппроксимацию необходимо определить оптимальные
значения параметров w
∗
.
10.2.4. Разделяющая поверхность: проблема переобучения
Качество аппроксимации целевой переменной y функцией a(x, w) зависит от выбора параметров w.
Рис. 10.10: Разделяющая поверхность нейронной сети в случае оптимальных и неоптимальных значений
параметров.
В случае оптимальных значений параметров, как это видно по графику (левый), разделяющая поверхность отнесла несколько объектов не к тому классу, к которому они принадлежат. Тем не менее именно эту
разделяющую поверхность следует считать оптимальной.
Действительно, в случае неоптимальных значений параметров, веса нейросети подстроены таким образом,
что текущая выборка классифицируется идеально: каждый объект принадлежит области своего класса. Однако при изменении состава выборки разделение уже будет неверным. Такая нейросеть, которая корректно
аппроксимирует обучающую выборку, но плохо справляется с контрольной, называется переобученной.
10.2.5. Функции ошибки нейронной сети
Пусть Q(w) — функция ошибки, которая зависит как от конфигурации w нейронной сети, так и от ее состава. Задача нахождения оптимальных параметров w
∗
, то есть таких, при которых ошибка нейронной сети
минимальна, имеет вид:
w
∗ = argminw Q(w).
7
a
-1 0 1 2
Q
(
a
)
0
1
2
3
4
0-1 loss
quadratic
cross-entropy
Рис. 10.11: Графики функций потерь
Выбор функции ошибки зависит от специфики решаемой задачи:
• В задаче регрессии (при решении различных прикладных задач) в качестве функции ошибки часто
используется функция «галочка»:
Q(w) = X
`
i=1
|a(xi
, w) − yi
|.
Но, к сожалению, эта функция не является дифференцируемой.
• Дифференцируемой функцией ошибки, используемой в задачах регрессии, является, например, квадратичная функция ошибки:
Q(w) = X
`
i=1
(a(xi
, w) − yi)
2
.
• В задачах классификации используется функция ошибки «0-1 loss», которая равна числу несовпадений
между восстановленными метками классов и фактическими:
Q(w) = X
`
i=1
[sign a(xi
, w) = yi
].
• Дифференцируемая функция ошибки для задачи классификации — кросс-энтропия, функция наибольшего правдоподобия в задаче логистической регрессии:
Q(w) = −
X
`
i=1
(yi
ln a(xi
, w) + (1 − yi)ln(1 − a(xi
, w))).
10.3. Оптимизация параметров нейронной сети
10.3.1. Задача оптимизации
Задача оптимизации для нахождения оптимальных значений параметров:
w
∗ = argminw Q(w),
где Q — функция ошибки, которая зависит от выборки, структуры нейросети (числа слоёв, нейронов и видов
функций активаций) и значения вектора параметров w.
На следующем графике изображено характерное поведение функции ошибки при изменении значений
двух параметров.
8
Рис. 10.12: Функция ошибки в зависимости от двух параметров.
Как отчетливо видно по графику, функция ошибки может иметь значительное число локальных минимумов. Задача является нетривиальной даже в пространстве малой размерности. При решении задачи
оптимизации для нахождения оптимальных значений параметров есть два типа алгоритмов:
• Алгоритмы стохастической оптимизации:
– Случайный перебор w1, w2, . . . ;
– Генетический алгоритм оптимизации w1 → w2 → . . . ;
– Моделируемый отжиг, значения w задаются по расписанию;
• Алгоритмы градиентного спуска.
Применение алгоритмов градиентного спуска к данной задаче будет обсуждаться далее.
10.3.2. Локально-квадратичная аппроксимация функции ошибки
Алгоритм локальной аппроксимации функции ошибки минимизирует не саму функцию ошибки, а функцию,
которая ее аппроксимирует в окрестности точки w
∗
. Например, удобно аппроксимировать исходную функцию
квадратичной функцией:
Q(w) ≈ Q(w
∗
) + 1
2
(w − w
∗
)
T H(w − w
∗
).
На каждой итерации этого алгоритма ищется минимум приближенной функции и окрестность сдвигается в
сторону более оптимальных значений.
10.3.3. Градиентный спуск
Алгоритм градиентного спуска предполагает, что функция ошибки является дифференцируемой (например
квадратичная или кросс-энтропийная) и можно вычислить ее значение Q(w) и значение ее градиента ∇wQ(w).
При использовании градиентного спуска следует помнить, что он может найти как точку глобального
минимума, так и точку локального минимума. Градиентный спуск — итеративная процедура нахождения
параметров:
wk+1 = wk − α
X
`
i=1
∇wϕ(wk, xi),
где ϕ(wk, xi) — ошибка на одном объекте, α — размер шага, k — номер итерации. Итеративный процесс
останавливается, когда стабилизируется значение функции ошибки.
9
10.3.4. Стохастический градиентный спуск
Стохастический градиентный спуск, вариант метода градиентного спуска, заключается в том, что градиент
считается не на всех элементах выборки, а только на одном случайно выбранном объекте xi
:
wk+1 = wk − α∇wϕ(wk, xk).
Итерации также продолжаются до стабилизации функции ошибки.
10.3.5. Обратное распространение ошибки (backprop)
Очень популярный и быстрый алгоритм — это алгоритм обратного распространения ошибки backpropagation,
или backprop. Для каждого нейрона сети h(w
T x) и одного объекта выборки x вычисляется:
• Взвешенная сумму входных сигналов z = w
T x.
• Значение на выхода h(z) (прямое распространение).
• Производная ошибки ∂ϕ(z)
∂z по значению нейрона и его параметрам. Эта производная зависит от значений
последующих нейронов и называется обратным распространением.
По обратному распространению можно вычислить градиент функции ошибки по w:
∇wϕ(z) = ∂ϕ(z)
∂z ∇wz =
∂ϕ(z)
∂z x,
а затем подкорректировать веса аналогично тому, как это делалось в градиентных методах.
z = w
T x
h(z)
∂ϕ
∂h
w and x
∂ϕ
∂z =
∂ϕ
∂h
∂h
∂z
Существует так называемая проблема затухания градиента. При больших значениях входов нейронов |x|
значения производной функции активации h
0
(x) → 0, например для сигмоидной функции h(x) = sigmoid(x)
или гиперболического тангенса h(x) = tanh(x). Следовательно, в данном случае градиент ∂ϕ
∂z(s) не будет
распространяться на предыдущие слои.
-2 0 2
h
(
x
)
-1
-0.5
0
0.5
sigmoid
tanh
linear
-4 -2 0 2 4
h
′(
x
)
0.2
0.4
0.6
0.8
1
sigmoid
tanh
linear
Рис. 10.13: Графики некоторых функций активаций и их производных.
Преимущества алгоритма обратного распространения ошибки:
• Градиент вычисляется за время, сравнимое с временем вычислением сети.
• Алгоритм подходит для многих дифференцируемых функций активации.
• Не обязательно использовать всю обучающую выборку.
10
Недостатки алгоритма обратного распространения ошибки:
• Возможна медленная сходимость к решению.
• Решение может быть локальным, а не глобальным минимумом.
• Возможно переобучение сети.
10.4. Регуляризация и прореживание нейронной сети
10.4.1. Регуляризация
Чтобы избежать переобучения, необходимо модифицировать задачу оптимизации: ввести штраф за большие
значения весов:
w
∗ = argminw

Q(w) + τ
X
i,j,k

w
(k)
ij 2

 ,
где τ — коэффициент регуляризации, который контролирует жесткость ограничений параметров w. При этом,
чем меньше τ , тем точнее функция a(x) описывает выборку.
На следующем рисунке изображены характерные смещенность, разброс и область поиска решения в пространстве параметров в случае различных значений параметра регуляризации τ .
На рисунке слева изображен случай, когда коэффициент регуляризации имеет самое большое значение.
Область поиска решения в пространстве параметров мала, но велика смещенность параметра от минимального значения функции ошибки.
Справа изображена противоположная ситуация: коэффициент τ мал, область поиска оптимальных параметров велика и смещенности нет. Но, возможно, нейронная сеть окажется переобученной. В центре рисунка
изображен компромиссный вариант.
На следующем графике изображена зависимость значений параметров нейронной сети от τ .
0 2 4 6 8 10
−15
−10
−5
0
5
10
15
20
25
30
Regularization, τ
Parameters,
w
Рис. 10.14: Значения параметров сети в зависимости от τ .
По графику отчетливо видно, что регуляризация не снижает число параметров и не упрощает структуру
сети. Более того, по мере увеличения τ параметры перестают изменяться.
1
10.4.2. Прореживание сети
Для снижения числа параметров предлагается исключить некоторые нейроны или связи. Принцип исключения следующий: если функция ошибки не изменяется, то нейронную сеть можно упрощать и дальше.
На следующем графике изображена характерная зависимость функции ошибки от числа удаленных параметров:
Рис. 10.15: Зависимость функции ошибки Q(w) от числа удаленных связей.
По этому графику отчетливо видно, что функция ошибки начала изменяться, только когда значительное
число связей было удалено. Связи (параметры) следует удалять исходя из следующих соображений. Параметр
можно удалить, если:
• его значение близко к нулю.
• соответствующий сигнал обладает большой дисперсией, то есть реагирует на шум в данных.
• его удаление практически не меняет функцию ошибки.
Последний вариант следует рассмотреть подробнее: это так называемы «метод оптимального разрушения
мозга» (optimal brain damage), или метод оптимального прореживания. Функцию ошибки можно разложить
в ряд Тейлора в окрестности оптимума:
Q(w + ∆w) = Q(w) + g
T
(w)∆w +
1
2
∆w
T H∆w + o(kwk
3
),
где H матрица Гессе, а g
T
(w) = 0, поскольку разложение идет в окрестности оптимума.
В методе оптимального прореживания необходимо исключить один параметр wj и, возможно, подкорректировать остальные веса w таким образом, чтобы приближенное выражение для изменения функции ошибки:
∆Q(w, ∆w) ≈
1
2
∆w
T H∆w
было минимиальным. Исключению j-го параметра соответствует выполнение условия:
∆wj + wj = 0.
Таким образом, чтобы определить исключаемый признак, требуется решить задачу условной оптимизации:
j = argminj

min
∆w

∆w
T H∆w

∆wj + wj = 0

.
Можно показать, что для этого параметра wj будем минимальным значение функции выпуклости:
Lj =
w
2
j
2H−1
jj
.
10.4.3. Построение нейронной сети
Нейронная сеть может работать в двух режимах:
• Режим обучения: В этом режиме задается структура нейронной сети и оптимизируются ее параметры.
• Режим эксплуатации: вычисление значений a(x, w∗
) при фиксированных значениях параметров.
Для того чтобы задать нейронную сеть, требуется указать число слоев, число нейронов в каждом слое, тип
функции активации в каждом слое, тип функции ошибки. Также желательно, чтобы подготовленная выборка
не содержала пропусков, а признаки были отнормированы.
1
10.4.4. Стабилизация параметров сети
Рис. 10.16: Зависимость ошибки от номера итерации.
По скорости обучения можно судить о соответствии выборки и нейронной сети:
• Если нейронная сеть будет слишком сложна, то она быстро переобучится, как, например, показывает
желтая линия.
• Если выборка будет сложна или сильно зашумлена для нейронной сети, то нейронная сеть будет обучаться медленно, как показывает синяя линия.
• Если выборка по сложности соответствует нейронной сети, то, скорее всего, мы увидим красную линию
— хорошую скорость обучения.
• Важно также следить за разницей между значениями функции ошибки на обучении и на контроле. Эта
разница не должна быть существенной. Если она велика, то это значит, что нейронная сеть переобучилась и следует изменить ее сложность.
Рис. 10.17: Существенная разница между значениями ошибки на обучении и на контроле говорит о переобученности нейронной сети.
