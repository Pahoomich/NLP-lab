Градиентный бустинг

Мы начинаем урок, посвященный градиентному бустингу, и в первую очередь мы обсудим, почему случайные леса применимы не ко всем задачам, и зачем могут понадобиться другие подходы к построению композиций. Итак, случайный лес — это композиция большого количества глубоких деревьев. При этом базовые алгоритмы (базовые решающие деревья в случайном лесе) строятся независимо друг от друга. На самом деле здесь есть несколько проблем. Проблема первая состоит в том, что базовые алгоритмы (деревья) должны быть глубокими. Они должны быть очень сложными и улавливать сложные закономерности в данных. Из-за этого строить такие деревья очень долго, если у вас большая выборка или много признаков. Возникает вопрос: а что будет, если мы введем ограничения, если будем ограничивать глубину базовых решающих деревьев? Тогда мы получим примерно такую картину. Смотрите, здесь синий класс состоит из двух групп: одна в центре, одна с краю. Из-за того, что деревья очень небольшой глубины (в данном случае — 2), они могут уловить только одну из этих групп — ту, которая в центре, а на второй они полностью ошибаются. Именно эта проблема не позволяет строить неглубокие деревья в случайном лесе. В этом случае случайный лес будет слишком слабым, его сдвиг будет большим. Вторая проблема случайного леса состоит в том, что деревья строятся ненаправленно, каждое следующее дерево в композиции не зависит от предыдущих деревьев. Из-за этого для решения сложных задач деревьев нужно довольно много. Это тоже может быть проблемой, связанной с производительностью. Бустинг — это подход к построению композиций, который призван решить все эти проблемы. В бустинге базовые алгоритмы строятся последовательно, один за другим. И при этом каждый следующий выбирается так, чтобы исправлять ошибки уже построенной композиции, исправлять ошибки предыдущих базовых алгоритмов. Благодаря тому, что построение композиций в бустинге направленное, в нем достаточно простых базовых алгоритмов, например, неглубоких деревьев. Давайте разберем простой пример того, как может быть устроен бустинг для задачи регрессии. Допустим, мы хотим минимизировать среднеквадратичную ошибку, с которой вы уже хорошо знакомы. Итак, давайте начнем с того, что обучим один алгоритм, который будет решать нашу задачу, минимизировать среднеквадратичную ошибку. Это очень простая задача, мы умеем ее решать, например, градиентным спуском. Хорошо. Итак, допустим, мы нашли b1 — алгоритм из некого семейства алгоритмов, например, из семейства неглубоких решающих деревьев, который решает данную задачу. После этого мы можем нарисовать такую таблицу. У нас всего l объектов обучающей выборки, на каждом мы знаем ответ (yi) и прогноз нашего алгоритма b1 — b1 (xi). Представьте, что теперь мы хотим добавить в композицию еще один алгоритм b2. И возникает вопрос: а какие же ответы b2 должен давать на объектах обучающей выборки, чтобы ошибка нашей композиции была как можно меньше? В общем-то, если записать уравнение b1 (xi) + b2 (xi) = yi, из него легко понять, чему должен быть равен b2 (xi), чтобы давать наилучшее приближение к истинным ответам. b2 (xi) должен быть равен yi − b1 (xi). Тогда, если мы прибавим ответ нашего второго алгоритма к ответу первого алгоритма, то ответ b1 (xi) сократится, и останется только yi. То есть после прибавления b2 к b1 мы получим на объектах обучающей выборки нулевую ошибку, получим идеальные ответы. Отлично. Давайте тогда обучать b2 так, чтобы его прогнозы были как можно ближе вот к этому вектору сдвигов, этому вектору ошибок. Получаем задачу, где минимизируется среднеквадратичное отклонение b (xi) от вот этих самых ошибок yi − b1 (xi). Если удастся решить задачу точно, то есть получить нулевую ошибку, то и наша композиция после добавления этого алгоритма b2 будет иметь нулевую ошибку. Но поскольку у нас алгоритмы базовые очень простые, скорее всего, точно решить задачу не получится, и поэтому b2 будет просто чуть-чуть улучшать качество первого базового алгоритма. Этот процесс можно продолжать очень долго. n-ный базовый алгоритм мы будем настраивать на ошибку композиции из (n − 1) алгоритма, которая записана вот здесь: yi − сумма ответов уже построенных (n − 1) алгоритма. Мы будем продолжать этот процесс до тех пор, пока ошибка на обучающей выборке не будет нас устраивать. Итак, мы с вами обсудили, в чем могут быть проблемы случайного леса, а именно в том, что строить глубокие деревья, а это очень долго и сложно, и в том, что его построение ненаправленное, каждый следующий алгоритм не зависит от предыдущих. И поговорили о том, что такое бустинг, который как раз таки является противоположностью случайного леса, он строит направленную композицию: каждый следующий алгоритм исправляет ошибки предыдущего. И разобрали на примере, как может выглядеть такое построение для среднеквадратичной ошибки и задачи регрессии. А в следующем видео мы поговорим о градиентном бустинге — более общем подходе, который обосновывает тот простой алгоритм, о котором мы только что говорили.

В этом видео мы разберемся, как работает градиентный бустинг — один из лучших способов направленного построения композиции на сегодняшний день. Итак, будем строить композиции вот такого вида. Саму композицию из N алгоритмов будем обозначать как a с индексом N (x) и она будет представлять собой сумму N базовых алгоритмов bn (x). Обратите внимание, что мы не усредняем, а просто складываем базовые алгоритмы. Поскольку каждый следующий корректирует ошибки предыдущих. И будем считать, что у нас есть некая функция потерь, которую мы хотим минимизировать. Функция потерь — это некая функция L, которая измеряет ошибку на одном объекте. Ее аргументами являются y, истинный ответ на этом объекте, и z, прогноз нашего алгоритма на этом объекте. Примерами функции потерь в задаче регрессии может служить, например, среднеквадратичная ошибка — это (y – z) в квадрате. В случае с классификацией это может быть логистическая функция потерь, которая устроена вот так. Мы с ней уже сталкивались, когда обсуждали логистическую регрессию. Начнем с того, что инициализируем нашу композицию. Построим самый первый базовый алгоритм b0 (x). Он не должен быть очень сложным, не стоит тратить много усилий на его построение. Например, это может быть константный алгоритм, который всегда возвращает ноль, если задача регрессии. Или чуть сложнее — средний ответ по всей обучающей выборке. Если же это классификация, он может возвращать самый популярный класс на обучающей выборке. Ничего сложного. Будем действовать по индукции. Будем считать, что мы уже построили N – 1 алгоритмов, например, для N = 1 — это будет означать, что мы построили только самый первый алгоритм b0. И попробуем понять, как именно нужно выбрать следующий базовый алгоритм b с индексом N. Задача будет выглядеть вот так. Мы суммируем потери на всей обучающей выборке суммы уже построенной композиции a(N – 1) и нового алгоритма b (x). И будем пытаться выбрать алгоритм b (x) так, чтобы как можно сильнее уменьшить ошибку композиции на обучающей выборке, то есть, чтобы как можно сильнее уменьшить вот этот функционал. Давайте для начала упростим себе задачу и попробуем ответить на более простой вопрос, а именно: какие значения наш новый базовый алгоритм должен принимать на объектах обучающей выборки, чтобы как можно сильнее уменьшить ошибку на обучающей выборке? Задача будет выглядеть вот так. Мы суммируем функцию потерь по всем объектам из обучения и подставляем в нее следующий прогноз. Прогноз уже построенной композиции N – 1, и некоторый сдвиг этого прогноза на i-ом объекте, который мы будет обозначать, как si, и нужно найти такие значения si, чтобы они как можно сильнее уменьшили значение ошибки. Итак, мы получаем следующую задачу оптимизации. Нам нужно найти такой вектор сдвигов s, который будет минимизировать данную функцию F (s), и на самом деле мы уже знаем, как решать такую задачу. Вектор, который как можно сильнее уменьшает функцию — это антиградиент, поскольку он направлен в сторону наискорейшего убывания функции. Значит, вектор s должен быть просто равен антиградиенту функции F, а именно он будет выглядеть вот так. У него будет компонент столько, сколько объектов у нас на обучающей выборке и, например, первая компонента, это будет частная производная функции потерь L по второму аргументу, по прогнозу, и вычислять мы ее будем в точке, которая равна прогнозу уже построенной композиции на объекте x1, и все это берется с минусом. Последняя компонента, для примера, этого вектора, это снова частная производная функции потерь с минусом и при этом она вычисляется уже в точке равная прогнозу построенной композиции на объекте xl. Итак, мы с вами поняли, как именно нужно сдвинуть прогнозы уже построенной композиции, чтобы достаточно хорошо уменьшить значение функции потерь на обучающей выборке. Иными словами, мы знаем какие значения новый алгоритм должен принимать на объектах обучающей выборки, и по этим значениям, в конечном числе точек, мы должны построить функцию b (x), которая будет выдавать прогноз на любой точке из нашего пространства объектов. На самом деле это задача, с которой мы уже много раз сталкивались и обсуждаем ее не первую неделю. Это задача обучение на размеченных данных. У нас есть обучающая выборка и есть ответы на ней, которые в нашем случае равны сдвигам si, и нужно по этим данным построить алгоритм b (x). Мы это умеем решать. Давайте настраивать алгоритм bn (x), следующий алгоритм, так, чтобы он был как можно ближе к сдвигам si, и при этом близость будем измерять с помощью среднеквадратичного отклонения. Функционал нашей задачи будет выглядеть вот так. Это будет сумма квадратов отклонений, ответов нашего алгоритма b (x) от сдвигов si. Обратите внимание, что вся информации об исходной функции потерь L, которая может быть не квадратичная, это может быть, например, логистическая функция потерь или абсолютная ошибка, вся эта информация уже содержится в градиенте, содержится в сдвигах si-тых. И потому нам не нужно использовать эту же функцию потерь на данном шаге. Достаточно приближать ответы к сдвигам по квадрату отклонения. Этого достаточно в большинстве задач. Именно этот функционал используется в градиентном спуске. Итак, давайте еще раз поговорим, как устроен градиентный спуск. В первую очередь мы находим инициализацию — самый первый базовый алгоритм b0, каким-то простым способом, например, усреднением, или это алгоритм, который возвращает самый популярный класс. Далее мы по итерациям повторяем следующие шаги. На каждой итерации мы строим новый базовый алгоритм bn. В первую очередь мы вычисляем вектор сдвига s, который показывает, как нужно скорректировать прогнозы уже построенной композиции, чтобы довольно сильно уменьшить ошибку на обучающей выборке. Вектор s устроен вот так, это вектор частных производных функции потерь в точках обучающей выборки. Далее мы строим базовый алгоритм bn путем подгонки его ответов на обучающей выборке к данным сдвига si-тое. После того, как алгоритм найден, это должно быть довольно просто из-за простого функционала, мы добавляем его в композицию. Повторяем эти шаги до тех пор по ка не наступит сходимость или не будет выполнен некоторый критерий останова, о которых мы поговорим в следующих видео. Итак, мы с вами разобрались, что такое градиентный бустинг и выяснили, что он строит композицию последовательно, и каждый следующий алгоритм приближает вектор антиградиента на обучающей выборке. За счет чего он довольно сильно уменьшает ошибку уже построенной композиции на объектах обучения. По сути градиентный бустинг представляет собой градиентный спуск в пространстве всех возможных алгоритмов, всех возможных функций, и каждый шаг этого градиентного спуска делается по базовому алгоритму bn (x). К сожалению, градиентный бустинг в отличие от случайного леса может переобучаться. И в следующем видео мы поговорим о том, как с этим можно бороться.

В этом видео мы обсудим проблему переобучения градиентного бустинга и поговорим о том, как с ней бороться. На этом графике изображена ошибка градиентного бустинга на обучающей и контрольной выборках в зависимости от числа деревьев в нем. Синяя кривая — это ошибка на обучающей выборке. Видно, что она монотонно убывает и в какой-то момент уходит в 0. Красная кривая — это ошибка на контрольной выборке, видно, что она сильно больше, чем ошибка на обучающей выборке, и при этом она в какой-то момент, на примерно 10-й итерации или 20-й, достигает минимума, после чего начинает опять возрастать. Налицо переобучение. В чем же дело? Эту проблему легко объяснить. В градиентном бустинге каждый базовый алгоритм пытается приблизить вектор антиградиента на обучающей выборке. При этом в градиентном бустинге используются довольно простые базовые алгоритмы, например, невысокие решающие деревья, которые вряд ли могут хорошо аппроксимировать вектор антиградиента. В итоге вектор, который построит базовый алгоритм, будет указывать не в сторону наискорейшего убывания ошибки, а куда-то в другую сторону. И у нас есть риск вместо градиентного спуска получить случайное блуждание в пространстве. Из-за этого и получается, что качество на тесте оказывается не очень хорошим. Как бороться с этой проблемой? Нужно не доверять тому направлению, которое построил базовый алгоритм и лишь чуть-чуть смещаться в сторону этого вектора. Благодаря этому мы получим очень аккуратное движение в пространстве и есть надежда, что мы сойдемся-таки к локальному минимуму. Итак, для того чтобы не доверять тому направлению, мы будем прибавлять новый базовый алгоритм bN с некоторым коэффициентом η (эта). Данный коэффициент η называется длиной шага и принимает значения от 0 до 1. При этом понятно, что выставлять его равным 0 не имеет смысла, в этом случае композиция будет константной. Посмотрим, как влияет длина шага на кривые качества на обучении и контроле. Первый график показывает ошибку на обучении и контроле при η = 1. Это та картинка, которую мы уже видели. Налицо переобучение, красная кривая, то есть ошибка на контроле сильно выше, чем ошибка на обучении. Выставим η равным 0,1. В этом случае качество на контроле получается уже гораздо лучше, и при этом оно монотонно убывает. То есть мы в каком-то смысле начинаем бороться с переобучением. Если уменьшить η еще сильнее и выставить равным 0,01, то видно, что сходимость гораздо медленнее. Даже чтобы достичь низкого качества на обучении, градиентному бустингу нужно существенно больше итераций, на несколько сотен больше. Но при этом и качество на контроле получается чуть-чуть лучше. Итак, мы заметили одну важную особенность, связанную с размером шага: чем меньше шаг, чем меньше η, тем больше нужно базовых алгоритмов, чтобы достичь хорошего качества. Таким образом нам нужно выбирать — мы хотим потратить больше времени на обучение, построить больше алгоритмов, получить качество получше, или же быстрее получить результат, но при этом получить качество чуть-чуть меньше. Также обратите внимание, что размер шага — это гиперпараметр, который нужно как-то подбирать: или по отложенной выборке, или по кросс-валидации. Получается, что у градиентного бустинга есть 2 важных гиперпараметра — это число деревьев, или, что то же самое, число итераций N, и размер шага η. Перебирать два гиперпараметра довольно сложно, поэтому обычно выбирают одну из двух следующих стратегий: первая — это зафиксировать размер шага η, например, взять его равным 0,01, и подбирать число итераций N, либо же зафиксировать число итераций N, например, взять его равным тысяче, и подбирать размер шага η. Обе стратегии неплохо работают, но если у вас есть много времени и ресурсов, то можно подобрать и оба гиперпараметра одновременно. Еще один подход к борьбе с переобучением градиентного бустинга — это бэггинг. То есть давайте обучать каждый базовый алгоритм не по всей обучающей выборке, а по некоторой случайной подвыборке. Такой подход называется стохастическим градиентным бустингом. Давайте посмотрим, как влияет сокращение шага и бэггинг на качество на контроле. На этом графике по оси X отложено число деревьев в композиции, по оси Y — качество на контрольной выборке. Оранжевая кривая — это качество градиентного бустинга без применения сокращения шага и без бэггинга. Видно, что у этой кривой есть явно выраженный минимум, после чего алгоритм начинает переобучаться. Бирюзовая кривая — это качество при использовании сокращения шага. Здесь η выставлена равной 0,1. Видно, что здесь требуется больше итераций, чтобы достичь хорошего качества, но и при этом достигается более низкая ошибка. То есть сокращение шага здесь действительно работает. Синяя кривая — это градиентный бустинг, который обучен с сокращением шага, η = 0,1, и с бэггингом, где каждый базовый алгоритм обучается по половине обучающей выборки. Видно, что здесь форма кривой такая же, как и при использовании только сокращения шага, но при этом за такое же количество итераций данный алгоритм достигает более низкой ошибки. То есть использование стохастического градиентного бустинга позволяет уменьшить ошибку или достичь той же ошибки при таком же числе итераций. Итак, мы обсудили, что градиентный бустинг переобучается из-за того, что в нем используются довольно простые базовые алгоритмы, и вывели два способа борьбы — это сокращение шага и бэггинг, который также называется стохастическим градиентным спуском. В следующем видео мы поговорим о том, как применять градиентный бустинг для конкретных функций потерь в классификации и регрессии.

В этом видео мы поговорим о том как использовать градиентный бустинг для решения задач классификации и регрессии. И давайте сначала вспомним, как выглядит общий алгоритм градиентного бустинга. На каждой итерации мы строим новый базовый алгоритм. Для этого мы сначала вычисляем вектор сдвигов s, который показывает насколько надо изменить прогноз уже построенной композиции на каждом объекте обучающей выборки, чтобы уменьшить ошибку на этой обучающей выборке. После того как вектор сдвигов s вычислен, мы настраиваем базовый алгоритм b n-ное так, чтобы его ответы на обучающей выборке были как можно ближе к этим сдвигам, причем близость мы измеряем с помощью квадрата отклонения. Итак, градиентный бустинг, как правило, используется для решающих деревьев, то есть в качестве базовых алгоритмов используются решающие деревья, это наиболее популярный выбор. При этом решающие деревья выбираются не очень глубокими. Глубина обычно варьируется от двух до восьми, при этом, как правило, ближе к двум. То есть деревья очень неглубокие, и этого достаточно, чтобы восстанавливать сложные закономерности, поскольку бустинг строит направленную композицию. Чтобы он не переобучался, нужно использовать оба подхода к борьбе с переобучением, который мы обсуждали в прошлом видео. Это сокращение шага и обучение каждого базового алгоритма по случайной подвыборке объектов. Давайте посмотрим, как выглядят формулы для сдвигов в конкретных задачах, конкретных функционалах ошибки, и начнем с регрессии. Типичный функционал ошибки в регрессии — это среднеквадратичная ошибка, или MSE, которая выглядит вот так. При этом функция потерь L, которая измеряет ошибку для одного объекта, будет выглядеть как (z- y)², где z — это прогноз нашего алгоритма, а y — истинный ответ на данном объекте. Легко посчитать производную по z этой функции потерь. Она будет выглядеть как 2(z − y). Соответственно, вектор сдвигов будет выглядеть вот так. Каждая его компонента показывает, как нужно модифицировать ответ на каждом объекте обучающей выборки, чтобы уменьшить среднеквадратичную ошибку. Например, для... для первого объекта этот сдвиг будет выглядеть как разность прогноза уже построенной композиции и истинного ответа, умноженное на −2. Перейдем к классификации. Будем говорить про бинарную классификацию, в которой метки имеют значение −1 и +1. Популярным выбором для функции потерь в случае с классификацией является логистическая функция потерь. Например, вы уже её использовали, чтобы строить логистическую регрессию, линейный метод. Логистическая ошибка выглядит вот так. Здесь стоит суммирование по всем объектам, и обратите внимание, здесь мы считаем, что a(x) — это алгоритм, который возвращает не бинарные ответы, а вещественные числа, которые оценивают принадлежность объекта к положительному классу. Если a(x) больше 0, то классификатор относит объект к классу +1, если a(x) меньше 0 то к классу −1. И при этом чем больше по модулю от x, тем больше классификатор уверен в своём выборе. Итак, функция потерь L в этом случае записывается вот так. Это логарифм от 1 + экспонента, и в экспоненте стоит (−yz). От этой функции тоже довольно легко посчитать производную по z. Она будет выглядеть как дробь, где в числителе стоит y, а в знаменателе — 1 + экспонента от (yz), и вся эта дробь с минусом. Соответственно, вектор сдвигов s будет выглядеть вот так. Мы будем настраивать новый базовый алгоритм, так чтобы его ответы на объектах обучающей выборки были как можно ближе вот к этим числам. После того как мы нашли алгоритм от x, мы сможем захотеть классифицировать объекты. Тогда нужно смотреть на знак числа, которое возвращает a от x. Если же мы хотим посчитать вероятность принадлежности объекта x к классу +1, то нужно взять сигмоиду от a от x. То есть посчитать дробь: 1 / 1 + экспонента, от минус ответа алгоритма. Соответственно, вероятность класса −1 вычисляется так же, только в экспоненте не будет знака минуса. Итак, мы вспомнили, что такое градиентный бустинг и обсудили какие именно деревья в нем, как правило, используются. И посмотрели на конкретные формулы, которые получаются при среднеквадратичной функции потерь и логистической функции потерь. А в следующем видео мы обсудим одну особенность, которая возникает при применении градиентного бустинга к решающим деревьям.

В этом видео мы поговорим о том, как применять градиентный бустинг, если базовый алгоритм — это решающие деревья. Сначала вспомним как выглядят поверхности, которые восстанавливают решающие деревья. Начнем с классификации. Представьте, что у нас есть три класса, и в этом случае решающее дерево может разделить выборку примерно вот так. Поскольку условия в каждой вершине дерева довольно простые — они сравнивают значение конкретного признака с порогом — то решающее дерево выделяет каждый класс с помощью некой области, стороны которой параллельны осям координат. В этой задаче области будут примерно вот такие. Видно, что их три штуки, и в каждой области предсказания константные. Например, в красной области дерево относит все объекты к красному классу. В регрессии, функция которой восстанавливает решающее дерево, тоже кусочно постоянная. В данном случае у нее есть четыре участка, где она возвращает одно и то же число. Итак, если говорить об этом более формально, то мы приходим к тому, что решающее дерево разбивает все пространство объектов на J областей, которые мы обозначим как R1, R2, ..., RJ, и при этом в каждой области дерево возвращает константное предсказание. В области R1 оно будет обозначаться как b1, в области R2 — как b2, и так далее, в RJ — как bj-ое. Таким образом решающее дерево b(x) можно записать как сумму по всем областям — от 1 до j — вот таких индикаторов. Индикаторов того, что объект x, в котором мы хотим посчитать прогноз, попал в область RJ. Если он не попал, то это слагаемое будет равно нулю, если попал, то мы возвращаем bj-ое — константный прогноз в этой области. В градиентном бустинге мы прибавляем каждый новый базовый алгоритм bN к уже построенной композиции. Представим, что у нас базовый алгоритм — это решающие деревья, то есть они выглядят так, как мы только что обсудили. В этом случае новый алгоритм... новая композиция aN будет выглядеть как сумма уже построенной композиции aN − 1 и вот такой суммы, которая представляет собой решающее дерево. Обратите внимание, что на это можно посмотреть и немножко с другой стороны — по сути, мы прибавляем не одно решающее дерево, а J очень простых алгоритмов. Каждый алгоритм возвращает константное предсказание в некоторой области Rj и ноль во всем остальном пространстве объекта. Здесь возникает следующая идея: что, если мы подберем прогноз в каждой области, которая обозначается как bNj-ое, где N — это номер дерева — N-ное, которое мы только что добавили, j — номер листа этого дерева, номер области. Так вот — что если мы подберем этот прогноз bNj-ое так, чтобы он был оптимален с точки зрения исходной функции потерь L, тогда как, напомню, мы дерево строили на среднеквадратичную функцию потерь. Получаем следующую задачу: здесь стоит сумма по всем объектам обучающей выборки, и каждое слагаемое — это ошибка суммы уже построенной композиции aN − 1 и ответа нашего нового решающего дерева. Мы хотим найти такие прогнозы в листьях bNj-ое, чтобы как можно сильнее уменьшить эту сумму потерь. Можно показать, что данная задача распадается на J маленьких подзадач — сколько у нас было листьев в дереве, столько и подзадач. При этом, например, поиск оптимального прогноза в j-ом листе будет выглядеть вот так: мы будем минимизировать сумму по всем объектам обучающей выборки, которые попали в данный лист, то есть в Rj-ое, в область Rj-ое, отклонений истинного ответа yi-ое от суммы уже построенной композиции N − 1 и прогноза в этом листе, который обозначается как γ (гамма). То есть мы ищем такой прогноз в этом листе, который будет оптимален для данных объектов обучающей выборки. γ — это число из... вещественное число, и мы будем искать ее каким-нибудь простым методом. Часто эта задача решается аналитически, или можно, например, решать ее перебором γ-фасетки или каким-то градиентным методом. Итак, структура базового решающего дерева в градиентном бустинге настраивается по среднеквадратичной ошибке, которая измеряет отклонение от веток дерева от вектора сдвигов S. При этом мы можем переподобрать ответы в листьях, перенастроить их так, чтобы они были оптимальны не с точки зрения среднеквадратичной ошибки, а с точки зрения исходной функции потерь L. Оказывается, если мы так сделаем, то сходимость градиентного бустинга очень сильно ускорится. Нам понадобится гораздо меньше деревьев, чтобы достичь такого же качества, как и без переподбора. Давайте разберем пример. Представим, что мы решаем задачу классификации с логистической функцией потерь. В этом случае практически оптимальные значения для коэффициентов для прогнозов в листьях будут выглядеть вот так: оптимальный прогноз в j-ом листе зависит от значений сдвигов si-ых для тех объектов, которые попадают в этот лист. Итак, мы выяснили, что решающее дерево — это кусочно постоянный алгоритм, и в градиентном бустинге он настраивается на среднеквадратичную ошибку. Если мы перенастроим ответы в листьях этого дерева, так чтобы они были оптимальны с точки зрения исходного функционала, то мы существенно ускорим сходимость градиентного бустинга. На этом урок про градиентный бустинг оканчивается, и теперь вам предстоит решить несколько практических заданий, где вы сами воспользуетесь случайным лесом и градиентным бустингом, чтобы решать реальные задачи.

Мы уже разобрались с двумя классами методов построения композиций — бустингом и бэггингом, и познакомились с градиентным бустингом и случайным лесом,
которые являются наиболее яркими представителями этих классов. На практике реализация градиентного бустинга оказывается очень непростой задачей, в которой
успех зависит от множества тонких моментов. В этом тексте мы рассмотрим конкретную реализацию градиентного бустинга — пакет XGBoost [1], который считается
одним из лучших на сегодняшний день. Это подтверждается, например, активным
его использованием в соревнованиях по анализу данных на kaggle.com.
1 Градиентный бустинг
Вспомним, что на каждой итерации градиентного бустинга вычисляется вектор
сдвигов s, который показывает, как нужно скорректировать ответы композиции на
обучающей выборке, чтобы как можно сильнее уменьшить ошибку:
s =

−
∂L
∂z




z=aN−1(xi)
!ℓ
i=1
= −∇s
X
ℓ
i=1
L(yi
, aN−1(xi) + si)
После этого новый базовый алгоритм обучается путем минимизации среднеквадратичного отклонения от вектора сдвигов s:
bN (x) = arg min
b∈A
X
ℓ
i=1
(b(xi) − si)
2
Также можно вычислять шаг с помощью методов второго порядка. В этом случае
задача поиска базового алгоритма примет вид
bN (x) = arg min
b∈A
X
ℓ
i=1

b(xi) −
si
hi
2
, (1.1)
где через hi мы обозначили вторые производные функции потерь:
hi =
∂
2L
∂z2




z=aN−1(xi)
1
2
1.0.1 Альтернативный подход
Мы аргументировали использование среднеквадратичной функции потерь тем,
что она наиболее проста для оптимизации. Попробуем найти более адекватное обоснование этому выбору.
Мы хотим найти алгоритм b(x), решающий следующую задачу:
X
ℓ
i=1
L(yi
, aN−1(xi) + b(xi)) → min
b
Разложим функцию L в каждом слагаемом в ряд Тейлора до второго члена с центром
в ответе композиции aN−1(xi):
X
ℓ
i=1
L(yi
, aN−1(xi) + b(xi)) ≈
≈
X
ℓ
i=1

L(yi
, aN−1(xi)) − sib(xi) + 1
2
hib
2
(xi)

Первое слагаемое не зависит от нового базового алгоритма, и поэтому его можно
выкинуть. Получаем функционал
X
ℓ
i=1

−sib(xi) + 1
2
hib
2
(xi)

(1.2)
Покажем, что он очень похож на среднеквадратичный из формулы (1.1). Преобразуем его:
X
ℓ
i=1

b(xi) −
si
hi
2
=
X
ℓ
i=1

b
2
(xi) − 2
si
hi
b(xi) + s
2
i
h
2
i

= {последнее слагаемое не зависит от b}
=
X
ℓ
i=1

b
2
(xi) − 2
si
hi
b(xi)

=
X
ℓ
i=1
2
hi

−sib(xi) + 1
2
hib
2
(xi)

Видно, что последняя формула совпадает с (1.2) с точностью до коэффициентов 2
hi
.
Можно считать, что в (1.2) они отброшены для большей устойчивости функционала — из-за них может произойти деление на ноль в окрестности оптимума.
2 Регуляризация
Будем далее работать с функционалом (1.2). Он измеряет лишь ошибку композиции после добавления нового алгоритма, никак при этом не штрафуя за излишнюю сложность модели. Ранее мы решали проблему переобучения путем ограничения глубины деревьев, можно подойти к вопросу и более гибко. Мы выясняли, что
3
дерево b(x) можно описать формулой
b(x) = X
J
j=1
bj
[x ∈ Rj
]
Его сложность зависит от двух показателей:
1. Число листьев J. Чем больше листьев имеет дерево, тем сложнее его разделяющая поверхность, тем больше у него параметров и тем выше риск переобучения.
2. Норма коэффициентов в листьях kbk
2 =
PJ
j=1 b
2
j
. Чем сильнее коэффициенты
отличаются от нуля, тем сильнее данный базовый алгоритм будет влиять на
итоговый ответ композиции.
Добавляя регуляризаторы, штрафующие за оба этих вида сложности, получаем следующую задачу:
X
ℓ
i=1

−sib(xi) + 1
2
hib
2
(xi)

+ λJ +
µ
2
X
J
j=1
b
2
j → min
b
Если вспомнить, что дерево b(x) дает одинаковые ответы на объектах, попадающих
в один лист, то можно упростить функционал:
X
J
j=1( −
X
i∈Rj
si
!
| {z }
=−Sj
bj +
1
2

µ +
X
i∈Rj
hi
| {z }
=Hj
!
b
2
j + λ
)
Каждое слагаемое здесь можно минимизировать по bj независимо. Заметим, что отдельное слагаемое представляет собой параболу относительно bj
, благодаря чему
можно аналитически найти оптимальные коэффициенты в листьях:
bj =
Sj
Hj + µ
Подставляя данное выражение обратно в функционал, получаем, что ошибка дерева
с оптимальными коэффициентами в листьях вычисляется по формуле
H(b) = 1
2
X
J
j=1
S
2
j
Hj + µ
+ λJ (2.1)
3 Обучение решающего дерева
Мы получили функционал H(b), который для заданной структуры дерева вычисляет минимальную ошибку, которую можно получить путем подбора коэффициентов в листьях. Заметим, что он прекрасно подходит на роль критерия информативности — с его помощью можно принимать решение, какое разбиение вершины
4
является наилучшим! Значит, с его помощью мы можем строить дерево. Будем выбирать разбиение так, чтобы оно решало следующую задачу максимизации:
Q = H(bl) + H(br) − H(b) − λ → max
За счет этого мы будем выбирать структуру дерева так, чтобы оно как можно лучше
решало задачу минимизации исходной функции потерь. При этом введем вполне
логичный критерий останова: вершину нужно объявить листом, если даже лучшее
из разбиений приводит к отрицательному значению функционала Q.
4 Заключение
Итак, градиентный бустинг в XGBoost имеет ряд важных особенностей.
1. Базовый алгоритм приближает направление, посчитанное с учетом вторых производных функции потерь.
2. Отклонение направления, построенного базовым алгоритмом, измеряется с помощью модифицированного функционала — из него удалено деление на вторую
производную, за счет чего избегаются численные проблемы.
3. Функционал регуляризуется — добавляются штрафы за количество листьев и
за норму коэффициентов.
4. При построении дерева используется критерий информативности, зависящий
от оптимального вектора сдвига.
5. Критерий останова при обучении дерева также зависит от оптимального сдвига.

Привет! Вы уже изучили два вида композиции алгоритмов: случайный лес и градиентный бустинг. Строить случайный лес с помощью Sklearn вы уже умеете. И на этом видео мы потренируемся строить градиентный бустинг. Sklearn предоставляет нам готовую реализацию градиентного бустинга. Она находится в том же модуле, что и случайный лес, — модуль ensemble, класс называется gradient boosting classifier. Мы с вами не будем изучать эту модель (вы можете сделать это самостоятельно), а мы будем строить XGBoost — тот алгоритм, который вы изучали на прошлом уроке. Давайте импортируем необходимые библиотеки и поговорим про данные. Мы будем изучать эти алгоритмы на основе данных из задачи bioresponse. В этой задаче требуется предсказать, будет ли дан биологический ответ на основе данных о молекуле. Мы уже работали с этими данными ранее, когда изучали random forest. Давайте загрузим эти данные. Сделаем это с помощью библиотеки pandas, функции read_csv. И давайте вспомним, как они выглядели. Помним, что в первом столбце у нас дана метка класса: 1 означает, что биологический ответ будет дан, 0 означает обратное. И также нам доступны столбцы с параметрами молекулы. Давайте теперь отделим данные от метки класса. И можем переходить к построению моделей. И случайный лес, и градиентный бустинг являются композициями алгоритмов. Понятно, что их качество зависит от количества простых моделей, над которыми они строятся. Давайте проанализируем, как изменяется качество алгоритма в зависимости от количества деревьев, над которыми они построены. Начнем со случайного леса. Сначала зададим количество деревьев. Давайте смотреть на одно дерево и далее на количество деревьев от 10 до 55 с шагом 5. Что мы хотим понять? Мы хотим понять, как будет меняться качество в зависимости от того, сколько деревьев мы разрешили строить алгоритму. Для этого давайте пройдемся в цикле по заданному количеству деревьев и будем оценивать качество с помощью функции cross_val_score. При этом мы будем делать кросс-валидацию на три фолда и будем использовать метрику accuracy. Вот давайте получим результаты этого скоринга. И дальше будем строить график. Отложим на прямой, как меняется качество алгоритма. Ну мы с вами будем ожидать, что качество должно расти. Ведь, казалось бы, чем больше деревьев, тем лучше алгоритм должен быть обучен. Теперь давайте посмотрим на скоринг, который мы получили. Мы видим, что мы получили матрицу. Эта матрица состоит из 10 строк. Каждая строка соответствует количеству деревьев, над которыми мы строили случайный лес. Получается, что первая строка соответствует одному дереву, последняя строка соответствует 50 деревьям. Теперь давайте посмотрим, что же внутри. Мы видим в каждой строке три значения качества. Помните, что мы делали кросс-валидацию по трем фолдам, соответственно, каждое значение соответствует качеству на одном фолде. Теперь давайте построим следующий график: по оси x отложим количество деревьев, по оси y отметим качество. Мы предполагаем, что качество должно расти с количеством деревьев, поэтому давайте наглядно в этом убедимся. Будем строить график с помощью функции plot. Сразу же добавим на него сетку, чтобы было легче ориентироваться. Добавим имена осей x и y, а также зададим название графика. Вот давайте смотреть. Да, видим вполне ожидаемую картинку. Когда у нас было всего одно дерево, качество было довольно низкое, и дальше оно начало расти с увеличением количества деревьев — то, что мы и хотели. Теперь давайте построим градиентный бустинг и посмотрим, как же в этом случае будет меняться качество алгоритма в зависимости от количества деревьев. Мы будем использовать тот же список количества деревьев — от 1 до 50. И теперь давайте обучать модель. Для этого мы будем пользоваться библиотекой XGBoost (мы ее импортировали в самом начале) и будем использовать класс XGBClassifier. Передаем ему параметры, которые мы хотим использовать: это learning_rate — глубина дерева, количество деревьев и так далее. И дальше мы будем для оценки качества снова использовать функцию cross_val_score. Это очень удобно, потому что получившийся объект имеет интерфейс, совместимый с этой функцией. Итак, давайте теперь получим скоринг для градиентного бустинга и попробуем построить аналогичный график. Итак, оценки качества для градиентного бустинга готовы. Обратите внимание на время работы алгоритма. Для сравнения можем вспомнить, как долго обучался случайный лес. Мы видим, что сильно быстрее — на него потребовалось всего порядка 15 секунд. Теперь давайте проанализируем наш результат. Видим, что мы получили аналогичную матрицу, практически такую же, как мы получали в предыдущем случае, только для градиентного бустинга. Поэтому давайте теперь возьмем скоринг для градиентного бустинга, скоринг для случайного леса и отрисуем их на одной плоскости, чтобы можно было их удобнее сравнивать. Итак, давайте построим их вместе. И что мы видим: оба алгоритма имеют довольно высокое качество. Это видно из правой части графика. Однако, для того чтобы достигнуть его, градиентному бустингу нужно существенно меньше деревьев, чем случайному лесу. Мы можем посмотреть в левой части графика, что градиентный бустинг начинает с более высокой отметки. Это довольно интересно. А мы с вами на этом заканчиваем. В этом уроке мы научились строить модель XGBoost, проанализировали, как изменяется качество алгоритма в зависимости от количества деревьев. А на следующем уроке вы займетесь новым классом алгоритмов — нейронные сети.

Градиентный бустинг
9.1. Композиции простых алгоритмов
В начале данного урока обсудим, почему случайные леса подходят не для всех задач.
9.1.1. Недостатки случайного леса
Случайный лес — композиция глубоких деревьев, которые строятся независимо друг от друга. Но такой подход имеет следующую проблему. Обучение глубоких деревьев требует очень много вычислительных ресурсов,
особенно в случае большой выборки или большого числа признаков.
Если ограничить глубину решающих деревьев в случайном лесе, то они уже не смогут улавливать сложные
закономерности в данных. Это приведет к тому, что сдвиг будет слишком большим.
Рис. 9.1: Неглубокие деревья не способны улавливать все закономерности в данных. В данном случае синий
класс состоит из двух групп объектов, но неглубокое дерево смогло уловить только центральную группу. На
объектах из второй группы такое дерево ошибается.
Вторая проблема со случайным лесом состоит в том, что процесс построения деревьев является ненаправленным: каждое следующее дерево в композиции никак не зависит от предыдущих. Из-за этого для решения
сложных задач необходимо огромное количество деревьев.
1
9.1.2. Бустинг: основная идея
Решить данные проблемы можно с помощью так называемого бустинга. Бустинг — это подход к построению
композиций, в рамках которого:
• Базовые алгоритмы строятся последовательно, один за другим.
• Каждый следующий алгоритм строится таким образом, чтобы исправлять ошибки уже построенной
композиции.
Благодаря тому, что построение композиций в бустинге является направленным, достаточно использовать
простые базовые алгоритмы, например неглубокие деревья.
9.1.3. Бустинг на примере задачи регрессии
Пусть дана задача регрессии, в которой в качестве ошибки используется среднеквадратичная ошибка:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
Для начала необходимо обучить первый простой алгоритм (например, неглубокое решающее дерево):
b1(x) = argminb
1
`
X
`
i=1
(b(xi) − yi)
2
.
Такая задача минимизации квадратичной ошибки легко решается, например, градиентным спуском. Этот
алгоритм будет первым алгоритмом в строящейся композиции.
Второй алгоритм должен быть обучен таким образом, чтобы композиция первого и второго алгоритмов:
b1(xi) + b2(xi)
имела наименьшую из возможных ошибку на обучающей выборке:
b2(x) = argminb
1
`
X
`
i=1
(b1(xi) + b(xi) − yi)
2 = argminb
1
`
X
`
i=1
(b(xi) − (yi − b1(xi)))2
.
Другими словами, алгоритм b2(x) улучшает качество работы алгоритма b1(x). Продолжая по аналогии на N
шаге очередной алгоритм bN (X) будет определяться следующим образом:
bN (x) = argminb
1
`
X
`
i=1
b(xi) −

yi −
N
X−1
n=1
bn(xi)
!!2
.
Процесс продолжается до тех пор, пока ошибка композиции b1(x) + ... + bN (x) не будет устраивать.
9.2. Градиентный бустинг
Градиентный бустинг является одним из лучших способов направленного построения композиции на сегодняшний день. В градиентном бустинге строящаяся композиция
aN (x) = X
N
n=1
bn(x)
является суммой, а не их усреднением базовых алгоритмов bi(x). Это связано с тем, что алгоритмы обучаются
последовательно и каждый следующий корректирует ошибки предыдущих.
Пусть задана функция потерь L(y, z), где y — истинный ответ, z — прогноз алгоритма на некотором
объекте. Примерами возможных функций потерь являются:
• среднеквадратичная ошибка (в задаче регрессии):
L(y, z) = (y − z)
2
• логистическая функция потерь (в задаче классификации):
L(y, z) = log(1 + exp(−yz)).
2
9.2.1. Инициализация
В начале построения композиции по методу градиентного бустинга нужно ее инициализировать, то есть
построить первый базовый алгоритм b0(x). Этот алгоритм не должен быть сколько-нибудь сложным и не
стоит тратить на него много усилий. Например, можно использовать:
• алгоритм b0(x) = 0, который всегда возвращает ноль (в задаче регрессии);
• более сложный b0(x) = 1
`
P`
i=1 yi
, который возвращает средний по всем элементам обучающей выборки
истинный ответ (в задаче регрессии);
• алгоритм b0(x) = argmaxy∈Y
P`
i=1[yi = y], который всегда возвращает метку самого распространенного
класса в обучающей выборке (в задаче классификации).
9.2.2. Обучение базовых алгоритмов
Обучение базовых алгоритмов происходит последовательно. Пусть к некоторому моменту обучены N − 1
алгоритмов b1(x), ..., bN−1(x), то есть композиция имеет вид:
aN−1(x) =
N
X−1
n=1
bn(x).
Теперь к текущей композиции добавляется еще один алгоритм bN (x). Этот алгоритм обучается так, чтобы
как можно сильнее уменьшить ошибку композиции на обучающей выборке:
X
`
i=1
L(yi
, aN−1(xi) + b(xi)) → min
b
.
Сначала имеет смысл решить более простую задачу: определить, какие значения s1, ..., s` должен принимать
алгоритм bN (xi) = si на объектах обучающей выборки, чтобы ошибка на обучающей выборке была минимальной:
F(s) = X
`
i=1
L(yi
, aN−1(xi) + si) → min
s
,
где s = (s1, ..., s`) — вектор сдвигов.
Другими словами, необходимо найти такой вектор сдвигов s, который будет минимизировать функцию F(s).
Поскольку направление наискорейшего убывания функции задается направлением антиградиента, его можно
принять в качестве вектора s:
s = −∇F =


−L
0
z
(y1, aN−1(x1)),
...
−L
0
z
(y`, aN−1(x`))

 .
Компоненты вектора сдвигов s, фактически, являются теми значениями, которые на объектах обучающей
выборки должен принимать новый алгоритм bN (x), чтобы минимизировать ошибку строящейся композиции.
Обучение bN (x), таким образом, представляет собой задачу обучения на размеченных данных, в которой
{(xi
, si)}
`
i=1 — обучающая выборка, и используется, например, квадратичная функция ошибки:
bN (x) = argminb
1
`
X
`
i=1
(b(xi) − si)
2
.
Следует обратить особое внимание на то, что информация об исходной функции потерь L(y, z), которая не
обязательно является квадратичной, содержится в выражении для вектора оптимального сдвига s. Поэтому
для большинства задач при обучении bN (x) можно использовать квадратичную функцию потерь.
3
9.3. Описание алгоритма градиентного бустинга
1. Инициализация: инициализация композиции a0(x) = b0(x), то есть построение простого алгоритма b0.
2. Шаг итерации:
(a) Вычисляется вектор сдвига
s = −∇F =


−L
0
z
(y1, an−1(x1)),
...
−L
0
z
(y`, an−1(x`))

 .
(b) Строится алгоритм
bn(x) = argminb
1
`
X
`
i=1
(b(xi) − si)
2
,
параметры которого подбираются таким образом, что его значения на элементах обучающей выборки были как можно ближе к вычисленному вектору оптимального сдвига s.
(c) Алгоритм bn(x) добавляется в композицию
an(x) = Xn
m=1
bm(x)
3. Если не выполнен критерий останова (об этом будет рассказано далее), то выполнить еще один шаг
итерации. Если критерий останова выполнен, остановить итерационный процесс.
9.4. Проблема переобучения градиентного бустинга
9.4.1. Проблема переобучения градиентного бустинга
На следующем графике изображена зависимость ошибки градиентного бустинга от числа используемых деревьев на обучающей и контрольной выборках.
Рис. 9.2: Ошибка в зависимости от числа деревьев: синяя линия — ошибка на обучающей выборке. Красная
линия — ошибка на контрольной выборке.
4
По мере увеличения числа деревьев ошибка на обучающей выборке постепенно уходит в 0. Ошибка на контрольной выборке существенно больше ошибки на обучающей выборке, достигает минимума примерно на 10
итерации, а затем начинает опять возрастать. Имеет место переобучение.
Это связано с тем, что базовый алгоритм пытается приблизить вектор антиградиента на обучающей выборке. Но в градиентном бустинге используются очень простые базовые алгоритмы, например невысокие
решающие деревья, которые не могут хорошо аппроксимировать вектор антиградиента на обучающей выборке. Вектор, построенный алгоритмом, будет указывать не в сторону наискорейшего убывания ошибки, то
есть вместо градиентного спуска можно получить случайное блуждание. Из-за этого и получается не очень
хорошее качество на контроле.
9.4.2. Сокращение размера шага
Чтобы решить эту проблему, нужно «не доверять» направлению, которое построил базовый алгоритм и лишь
чуть-чуть смещаться в сторону этого вектора:
aN (x) = aN−1(x) + ηbN (x),
где η ∈ (0, 1] — длина шага. Это обеспечивает очень аккуратное движение в пространстве, что делает возможным нахождение локального минимума.
(a) Случай η = 1. (b) Случай η = 0.1. (c) Случай η = 0.01.
Рис. 9.3: Качество градиентного бустинга на обучающей выборке и контроле при различных η.
Как видно по графикам, при η = 0.1 качество на контрольной выборке уже существенно лучше, то есть в некотором смысле удалось побороть переобучение. При еще меньшей длине шага η = 0.01 градиентному бустингу
требуется существенно больше итераций, чтобы достичь чуть-чуть большего качества. Таким образом:
• Чем меньше размер шага, тем больше нужно базовых алгоритмов, чтобы достичь хорошего качества, и
тем больше времени занимает процесс.
• Чем меньше размер шага, тем лучшего качества можно достичь.
Другими словами, приходится выбирать: или быстро получить достаточно хорошее качество, или получить
качество чуть-чуть лучше за большее время.
9.4.3. Подбор гиперпараметров
Размер шага η также является гиперпараметром градиентного бустинга, как и число итерации N. Эти гиперпараметры следует подбирать либо по отложенной выборке, либо по по кросс-валидации. Но подбирать сразу
два гиперпараметра довольно сложно, поэтому обычно используют одну из двух следующих стратегий:
1. Зафиксировать размер шага η и подбирать число итераций N
2. Зафиксировать число итераций N и подбирать размер шага η
Обе стратегии неплохо работают, но если время и ресурсы не ограничены, можно попробовать подобрать оба
параметра одновременно.
5
9.4.4. Стохастический градиентный бустинг
Бэггинг — еще один подход к борьбе с переобучением градиентного бустинга, который заключается в том,
что каждый базовый алгоритм обучается не на всей выборке, а на некоторой ее случайной подвыборке. Такой
подход еще называется стохастическим градиентным бустингом.
Рис. 9.4: Качество на контрольной выборке в зависимости от числа деревьев.
На графике изображены зависимость качества на контроле от числа деревьев:
• Оранжевая кривая: без применения сокращения шага и без бэггинга. Кривая обладает явно выраженным минимумом, после чего алгоритм начинает переобучаться.
• Бирюзовая кривая: при использовании сокращения шага с параметром η = 0.1 без бэггинга. В этом
случае требуется больше итерации, чтобы достичь хорошего качества, но и при этом достигается более
низкое значение ошибки. То есть метод сокращения шага действительно работает.
• Синяя кривая: при использовании сокращения шага с параметром η = 0.1 и бэггинга с размером подвыборки равным половине обучающей выборки. Форма кривой совпадает совпадает с формой бирюзовой
кривой, но при этом за такое же количество итераций алгоритм достигает более низкой ошибки.
То есть использование стохастического градиентного бустинга позволяет уменьшить ошибку или достичь
такой же ошибки при таком же числе итераций.
9.5. Градиентный бустинг для регрессии и классификации
9.5.1. Градиентный бустинг
В градиентном бустинге в качестве базовых алгоритмов, как правило, используются не очень глубокие (глубина выбирается от 2 до 8, обычно ближе к 2) решающие деревья. Использования таких не очень глубоких
деревьев все же достаточно, чтобы восстанавливать сложные закономерности, поскольку бустинг строит направленную композицию. Чтобы решить возникающую в градиентном бустинге проблему с переобучением,
необходимо использовать оба подхода борьбы с ним: сокращение шага и бэггинг.
9.5.2. Градиентный бустинг для регрессии
Типичный функционал ошибки в регрессии — это среднеквадратичная ошибка:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
При этом функция потерь, которая измеряет ошибку для одного объекта:
L(y, z) = (z − y)
2
, L0
z
(y, z) = 2(z − y),
6
где z — это прогноз нашего алгоритма, а y — истинный ответ на данном объекте. Соответственно, вектор
сдвигов, каждая компонента которого показывает, как нужно модифицировать ответ на каждом объекте
обучающей выборки, чтобы уменьшить среднеквадратичную ошибку, имеет вид:
s =


−2

aN−1(x1) − y1

...
−2

aN−1(x`) − y`



.
9.5.3. Градиентный бустинг для классификации
В задаче бинарной классификации (Y = {−1, +1}) популярным выбором для функции потерь является логистическая функция потерь:
Xn
i=1
log
1 + exp
− yia(xi)
 ,
где a(x) ∈ R — оценка принадлежности положительному классу. Если a(x) > 0, классификатор относит
объект x к классу +1, а при a(x) ≤ 0 – к классу −1. Причем, чем больше |a(x)|, тем больше классификатор
уверен в своем выборе. Функция потерь в этом случае записывается следующим образом:
L(y, z) = log(1 + exp(−yz)), L0
z
(y, z) = −
y
1 + exp(yz)
.
Вектор сдвигов s в этом случае будет иметь вид:
s =


y1
1+exp(y1aN−1(x1))
...
y`
1+exp(y`aN−1(x`))

 .
Новый базовый алгоритм будет настраиваться таким образом, чтобы вектор его ответов на объектах обучающей выборки был как можно ближе к s. После того, как вычислен алгоритм aN (x), можно оценить
вероятности принадлежности объекта x к каждому из классов:
P(y = 1|x) = 1
1 + exp (−aN (x)), P(y = −1|x) = 1
1 + exp (aN (x)).
9.6. Градиентный бустинг для решающих деревьев
В этом разделе речь пойдет о том, как применять градиентный бустинг, если базовый алгоритм — это решающие деревья.
9.6.1. Поверхности, которые восстанавливают решающие деревья
В задаче классификации с тремя классами решающее дерево может разделить выборку примерно вот так:
Поскольку условия в каждой вершине дерева есть сравнение значения какого-то признака с порогом, решающее дерево выделяет каждый класс с помощью некой области, стороны которой параллельны осям координат.
В задаче регрессии функция, которую восстанавливает решающее дерево — кусочно постоянная:
В данном случае есть четыре участка, на каждом из которых функция возвращает постоянное значение.
Решающее дерево, таким образом, разбивает все пространство объектов на J областей:
R1, R2, ..., RJ ,
в каждой из которых дерево возвращает постоянное предсказание. Пусть bj — предсказание дерева в области Rj , тогда решающее дерево b(x) можно записать в следующем виде:
b(x) = X
J
j=1
[x ∈ Rj ] bj .
Здесь [x ∈ Rj ] — индикатор того, что объект x попал в область Rj .
9.6.2. Градиентный бустинг для решающих деревьев
В градиентном бустинге каждый новый базовый алгоритм bN прибавляется к уже построенной композиции:
aN (x) = aN−1(x) + bN (x)
Если базовые алгоритмы — это решающие деревья
bN (x) = X
J
j=1
[x ∈ RNj ]bNj ,
тогда новая композиция aN будет выглядеть следующим образом:
aN (x) = aN1(x) +X
J
j=1
[x ∈ RNj ]bNj
Последнее выражение можно проинтерпретировать не только как прибавление одного решающего дерева,
но и как прибавление J очень простых алгоритмов, каждый из которых возвращает постоянное значение в
некоторой области и ноль во всем остальном пространстве. Можно подобрать каждый прогноз bNj , где N —
номер дерева, j — номер листа в этом дереве, таким образом, чтобы он был оптимальным с точки зрения
исходной функции потерь:
X
`
i=1
L

yi
, aN−1(x) +X
J
j=1
[x ∈ RNj ] bNj

 → min
b1,...,bJ
8
Можно показать, что данная задача распадается на J подзадач:
bNj = argminγ∈R
X
xi∈Rj
L(yi
, aN−1(x) + γ).
Такая задача часто решается аналитически или любым простым методом. Итак, структура базового решающего дерева (структура областей Rj ) в градиентном бустинге настраивается минимизацией среднеквадратичной ошибки. Потом можно переподобрать ответы в листьях, то есть перенастроить их, так, чтобы они
были оптимальны не с точки зрения среднеквадратичной ошибки (с помощью которой строилось дерево),
а с точки зрения исходной функции потерь L. Это позволяет существенно увеличить скорость сходимости
градиентного бустинга.
Например, в задаче классификации с логистической функцией потерь, практически оптимальные значения
для прогнозов в листьях имеют вид:

