

Мы начинаем урок, посвященный метрикам качества. В нем мы поговорим о том, как измерять качество алгоритмов в классификации регрессии и какие аспекты качества могут возникнуть в тех или иных задачах. И давайте сначала обсудим, где могут использоваться метрики качества в машинном обучении. Первое применение — это функционалы ошибки, которую мы оптимизируем при обучении алгоритма на обучающей выборке. С этим мы уже много раз сталкивались. Мы использовали, например, среднеквадратичную ошибку, или долю неправильных ответов, или говорили про логистическую функцию — понятие и классификация. Также вы можете обучать алгоритм, используя один функционал, одну метрику качества, а вот проверять его качество на отложенной выборке или на кросс-валидации с помощью другой метрики, например, если вы знаете, что в вашей задаче много выбросов, то нужно использовать какую-то метрику, которая слабо штрафует за ошибки на таких выбросах. Далее, когда вы выбрали параметры и гиперпараметры алгоритма, и у вас есть финальная модель, которую вы собираетесь использовать, то вы можете захотеть измерить еще какую-то, третью метрику качества, которая отражает ценность, например, для бизнеса вашей модели. Скажем, если вы решаете задачу медицинской диагностики, то есть строите модель, которая будет определять: болен или нет пациент тем или иным заболеванием, то вы можете интересоваться: какую долю всех больных пациентов ваша модель сможет обнаружить, сможет понять, что у них есть проблема. Дайте поговорим о том, какие метрики качества бывают в регрессии. Наше видео именно об этом. И первая метрика, о которой мы поговорим, с которой мы уже много раз сталкивались — это среднеквадратичная ошибка, она вычисляется очень просто: мы вычисляем отклонения, прогнозы нашего алгоритма от истинного ответа на каждом объекте выборки, возводим в квадрат это отклонение и усредняем по всем объектам обучающей или какой-то другой выборки. Преимущество этого функционала в том, что его легко оптимизировать. Если мы используем линейную модель, то у него даже есть аналитическое решение, у этой задачи оптимизации. Но при этом есть и проблема: данный функционал возводит отклонение в квадрат. Таким образом, если отклонение сильное, если этот объект — выброс и ответ на нем не очень логичный, то штраф за отклонение, соответственно, на этом объекте будет очень сильный. Таким образом алгоритм может настроиться на выборосы, может дать хороший ответ на тех объектах, на который не имеет смысла настраиваться. Похожий функционал качества — это средняя абсолютная ошибка. В ней мы вычисляем модуль отклонения прогноза от истинного ответа и усредняем это по всем объектам обучающей выборки. Этот функционал немного сложнее. Его тяжелее оптимизировать из-за того, что у модуля производная есть не везде, в нуле она отсутствует. Но при этом здесь считается модуль отклонения, а не квадрат, и поэтому штраф за сильное отклонение гораздо меньше. Это функционал гораздо более устойчив к выбросам. У среднеквадратичной ошибки есть одна модификация — коэффициент детерминации, которая позволяет интерпретировать свое значение. Давайте сначала обсудим, как он задается. Основная часть коэффициента детерминации, или коэффициента R квадрат, — это дробь, у которой в числителе стоит сумма квадратов отклонений прогнозов алгоритма от истинных ответов, то есть практически среднеквадратичная ошибка, только без усреднения, просто сумма. В знаменателе стоит сумма квадратов отклонений истинных ответов от среднего истинного ответа, вычисленного по всем... по всей обучающей выборке. При этом средний истинный ответ мы обозначаем как y с верхней чертой. После того как эта дробь посчитана, мы вычитаем ее из 1. И получаем коэффициент детерминации. У этого коэффициента есть одна интересная интерпретация: он показывает, какую долю дисперсии во всем целевом векторе y наша модель смогла объяснить. Иными словами, какую долю разнообразия ответов наша модель смогла объяснить или предсказать. Как я уже говорил, коэффициент детерминации можно интерпретировать. Давайте разберемся, как именно. Оказывается, что для разумных моделей — что такое разумная модель, скажем чуть позже — коэффициент детерминации находится между 0 и 1, в отрезке от 0 до 1. При этом, если он равен 1, то это идеальная модель, которая идеально угадывает ответы на обучающей выборке. Если коэффициент детерминации равен 0, это означает, что его качество совпадает с оптимальным константным алгоритмом. Оптимальный константный алгоритм — это тот, который на всех объектах возвращает средний ответ по всей обучающей выборке, то есть y с верхней чертой, который мы вводили на прошлом слайде. Если коэффициент детерминации находится между 0 и 1, то можно говорить о том, насколько он лучше, чем константная модель, и насколько он хуже, чем идеальная модель. Например, если он равен 0,2, то, скорей всего, он не очень хороший, ближе к константной модели. Если же коэффициент детерминации алгоритма равен 0,9, скорей всего, это хороший алгоритм, который близок к оптимальному. Коэффициент детерминации может быть меньше 0, если алгоритм работает хуже, чем константный, это те алгоритмы, которые никогда не нужно рассматривать. Пока что мы говорили о метриках качества, которые симметричные, которые одинаково штрафуют как за недопрогноз, так и за перепрогноз, то есть как за завышение, так и за занижение прогноза. При этом бывают задачи, где эти ошибки имеют разную цену. Давайте разберем простой пример: представим, что мы торгуем ноутбуками одной и той же марки. И хотим предсказывать, каков будет спрос на эти ноутбуки в следующем месяце. Если наш прогноз будет занижен, то есть мы предскажем спрос ниже, чем он будет на самом деле, это очень плохо. Во-первых, мы потеряем лояльность клиентов, они будут приходить к нам за покупками, но мы не сможем продать им этот ноутбук, потому что у нас они закончились, клиенты, скорее всего, разочаруются в нас. Также мы теряем потенциальную прибыль — мы могли бы заработать, продав эти ноутбуки, но нам нечего было продать. Поэтому недопрогноз, заниженная прогнозная задача — это плохо. Если же будет иметь место перепрогноз, завышенный прогноз, то мы удовлетворим всех клиентов, но при этом у нас будут остатки ноутбуков, у нас останется несколько ноутбуков непроданными. Это не очень плохо. Да, мы потратим деньги на хранение, но ноутбуки — это довольно компактные вещи, поэтому они не займут много места. Итак, в этой задаче функция потери должна быть несимметричной, мы должны сильнее штрафовать за недопрогноз, чем за перепрогноз. В этом случае хорошо подходит квантильная ошибка, квантильная функция потерь. Давайте разберемся, как она задается. Она представляет собой сумму по всем объектам обучающей выборки вот таких сложных выражений. Давайте поймем, что они означают. Здесь стоит отклонение прогноза алгоритма от истинного ответа: yi-тое − a(xi-того), и это отклонение домножается либо на число τ (тау), если имеет место недопрогноз, то есть если прогноз меньше истинного ответа, либо на число τ − 1, если имеет место перепрогноз, то есть ответ алгоритма, прогноз, больше истинного ответа. τ — это некоторый параметр данного функционала, который варьируется от 0 до 1. Если нарисовать зависимость ошибки, посчитанной данным образом, от отклонения yi-тое − a(xi-тое), то получим вот такую картину. Видно, что эта функция потерь действительно несимметричная. При этом если τ большое, если τ близко к 1, то мы сильнее боимся недопрогноза, мы сильнее боимся занизить прогноз, если τ близко к 0, мы боимся перепрогноза. Чтобы разобраться, почему эта функция потерь называется квантильной, давайте поговорим про вероятностный смысл, вероятностную интерпретацию этих функционалов. Представьте следующую ситуацию: в нашей выборке один и тот же объект x с одним и тем же признаковым описанием повторяется n раз. Это... такая ситуация вполне может возникнуть в ряде задач. При этом ответы на этих n повторах разные, они немного отличаются друг от друга, обозначим их через y1, ..., yn. Такое может возникнуть, например, при измерении роста человека. Человек один и тот же, но при этом результат конкретного измерения зависит от показателей, от шума прибора, которым мы измеряем рост, и от самого человека, он может выпрямиться или сгорбиться, например, и из-за этого рост получится немножко другим, чем в прошлый раз. Объект один и тот же, а ответы немного разные. При этом обратите внимание: наш алгоритм должен на одном и том же объекте возвращать один и тот же прогноз. Таким образом возникает вопрос: какой ответ алгоритма на объекте x оптимален для данной выборки y1, ..., yn с точки зрения того или иного функционала ошибки. Давайте разберемся! Оказывается, если мы используем среднеквадратичную ошибку, то оптимальным прогнозом будет просто средний ответ на этом объекте, то есть среднее по y1, ..., yn. Если мы используем среднюю абсолютную ошибку, то оптимальным прогнозом будет медиана, то есть мы считаем медиану по нашей выборке. Известно, что медиана более устойчива к выборосам, чем среднее. Если же мы используем квантильную регрессию с параметром τ, то оказывается, что оптимальным прогнозом будет τ-квантиль. Это очень логично. Если τ — большое, мы боимся недопрогноза и будем брать большую квантиль, будем завышать прогноз, будем брать его выше, чем среднее значение y-ков. Если же τ — маленькое, и мы боимся перепрогноза, то мы будем брать маленькую квантиль, специально занижать прогноз, делать его ниже, чем среднее. Итак, мы поговорили о том, какие метрики качества бывают в задачах регрессии. Поговорили про среднеквадратичную среднюю абсолютную ошибку и про коэффициент детерминации, который является интерпретируемой версией среднеквадратичной ошибки. Также мы обсудили квантильную функцию потерь, которая является несимметричной и может оказаться важной в ряде задач. А в следующем видео мы поговорим о том, как измерять качество в задачах классификации.

 В этом видео мы начнем разговор о том, как можно измерять качество в задачах классификации. И, на самом деле, мы уже знаем некоторый ответ на этот вопрос. Мы использовали долю неправильных ответов, чтобы обучать линейные классификаторы. Она считается очень просто. Мы для каждого объекта выборки выясняем, дает ли алгоритм правильный ответ или нет, и если дает неправильный ответ, то записываем единичку, если правильный — то нолик, и усредняем эти нолики и единички по всем объектам выборки. Так вышло, что в задачах классификации метрики принято выбирать так, чтобы их нужно было максимизировать, тогда как в регрессии метрики были такие, что мы их минимизировали, например среднюю квадратичную ошибку или квантильные потери. Чтобы максимизировать долю неправильных ответов, нужно ее немножко модифицировать и превратить в долю правильных ответов, или accuracy на английском. Она вычисляется точно так же: мы усредняем по всем объектам выборки индикаторы того, что на данном объекте алгоритм выдает правильный ответ. Это очень простая метрика качества, которая широко используется, но при этом у нее есть две проблемы. Давайте поговорим о них подробнее. Проблема первая связана с несбалансированными выборками. Давайте рассмотрим простой пример. Пусть в выборке 1000 объектов, из них 950 относится к классу −1, и 50 — к классу +1. И при этом рассмотрим константный алгоритм a(x), который на всех объектах, абсолютно всех объектах возвращает ответ −1. Этот алгоритм бесполезен, не имеет смысла его использовать ни в каких задачах. Он не восстанавливает никакие закономерности в данных. При этом его доля верных ответов на данной выборке будет равна 0,95 или 95 %. Это очень много, но не соответствует нашим ожиданиям. Понятно, что проблема именно в несбалансированности. В том, что одного из классов сильно больше, чем другого. Чтобы бороться с этой проблемой, имеет смысл измерять долю объектов самого крупного класса в данной выборке. Обозначим это через q₀. В нашем случае самый крупный класс — это −1, и доля объектов этого класса равняется как раз 95 %. Это означает, что доля правильных ответов для разумных классификаторов будет лежать в интервале от q₀ до 1, от 0,95 до 1, а не от 1/2 до 1, как мы могли бы ожидать в случае с бинарной классификацией. Еще раз совет на случай, если вы настроили некоторый классификатор и получили большую долю верных ответов — посмотрите на баланс классов. Возможно, дело не в том, что вы построили хороший классификатор, а в том, что просто одного из классов сильно больше, чем другого, и из-за этого легко получить высокую долю верных ответов. Вторая проблема, которая имеется в доле верных ответов — это то, что она никак не учитывает разные цены разных типов ошибок, тогда как цены действительно могут быть разными. Давайте разберем простой пример. Рассмотрим задачу кредитного скоринга, в которой нужно для клиента банка, который просит кредит, понять, выдавать ему кредит или не выдавать, вернет он этот кредит или не вернет. И представим, что у нас есть две модели. Первая модель говорит, что нужно выдать кредит ста клиентам. При этом если мы их выдадим, то из них 80 вернут деньги, а 20 не вернут. Вторая модель более консервативная. Она говорит, что нужно выдать кредит всего 50 клиентам, и если мы это сделаем, то из них 48 вернут кредит и всего 2 не вернут. Непонятно, какая из этих моделей лучше. Вторая модель более консервативная. Если мы воспользуемся ей, то практически все клиенты вернут кредиты, но при этом многим мы кредиты не дадим, хотя они вернули бы деньги. Мы не заработаем. Первая модель рискует сильнее, она выдает кредиты большему количеству человек, мы заработаем больше, но при этом и будут некоторые потери, связанные с тем, что 20 клиентов кредит не вернут. И в зависимости от того, каковы потери от невозврата кредита, можно отдать предпочтение либо одной модели, либо другой. Таким образом, нужны какие-то дополнительные метрики качества, которые позволяют учесть цену той или иной ошибки. Об этом будем говорить в следующем видео. Итак, мы поговорили про основную метрику качества классификации, долю верных ответов, и обсудили, что у нее есть две проблемы. Первая связана с неадекватными значениями в случае с несбалансированными выборками, а вторая — с тем, что данная метрика качества не умеет учитывать цены ошибок. А в следующем видео мы поговорим о том, как можно учитывать разные цены ошибок при разных типах ошибок классификации.

В этом видео мы поговорим о точности и полноте, метриках качества классификации, которые позволяют учитывать разные цены ошибок. В прошлом видео мы выяснили, что цены ошибок действительно могут быть разные. Например, в случае с кредитным скорингом непонятно, что лучше: выдать кредит плохому клиенту, который не вернёт кредит, или не выдать кредит хорошему клиенту, который мог бы вернуть этот кредит. То, какая ошибка лучше или хуже, какая важнее, какая нет, зависит от конкретной стратегии банка. Цена этой ошибки может варьироваться. Доля верных ответов неспособна учитывать цены разных ошибок. Чтобы рассуждать о том, у какой ошибки какая цены, удобно ввести матрицу ошибок, которая производит некоторую классификацию типов ошибок. Она состоит из двух строк и двух столбцов. Строка зависит от того, какой ответ выдаёт наш алгоритм, наша модель. Первая строка соответствует объектам, которых наша модель относит к классу +1. Вторая строка соответствует объектам, которых наша модель относит к классу -1. Столбец зависит от того, к какому классу на самом деле относится объект. Если объект относится к классу 1, он попадает в первый столбец. Если объект относится к классу -1, он попадает во второй столбец. Когда алгоритм относит объект к классу +1, будем говорить, что алгоритм срабатывает, он делает срабатывание. Итак, если алгоритм сработал, отнёс объект к классу +1, и объект действительно относился к классу +1, это верное срабатывание или True Positive. Если алгоритм сработал, но объект не относился к первому классу, на самом деле он из класса -1, то это ложное срабатывание или False Positive. Если алгоритм выдаёт ответ -1, будем говорить, что он пропускает объект. Итак, если имеет место пропуск, но при этом объект относится к классу 1, то это ложный пропуск или False Negative. Если же алгоритм пропускает объект, и, действительно, этот объект относится к классу -1, то это верный пропуск или True Negative. Таким образом, у нас есть два вида ошибок: ложные срабатывания и ложные пропуски. И для каждой из них нужна своя метрика качества, чтобы как-то измерить, какое количество таких ошибок мы допускаем. Давайте будем разбирать наши метрики на двух примерах, на примере двух моделей. Будем считать, что у нас выборка состоит из двухсот объектов, из которых сто относится к классу 1, и сто относится к классу -1, при этом первая модель относит к классу 1 сто объектов, из которых 80 — это верное срабатывание и 20 — это ложное срабатывание. Вторая модель срабатывает на пятидесяти объектах. Из них 48 — это верное срабатывание, а 2 — это ложное срабатывание. Первая метрика, о которой мы поговорим — это точность или precision. Она показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. В случае, если он относит объект к первому классу. Формально точно задаётся как отношение числа верных срабатываний к общему числу срабатываний, то есть число верных срабатываний плюс число ложных срабатываний. True Positive плюс False Positive. Давайте посчитаем точность в нашем примере. В случае с первой моделью, она срабатывает на ста объектах, и из них 80 действительно относятся к первом классу. Значит, нам нужно 80 поделить на сто. Получаем 0.8. Точность первого алгоритма = 0.8 или 80 процентам. Вторая модель срабатывает на пятидесяти объектах, и из них 48 — это верные срабатывания. Её точность равняется 48 поделить на 50 или 0.96. Её точность гораздо выше, она равняется 96 %. Если вторая модель срабатывает, то мы можем быть с большой долей вероятности уверены, что это срабатывание верное. Вторая метрика — это полнота или recall. Она показывает, как много истинных объектов первого класса алгоритм выделяет, на скольки из них он срабатывает. Формально она задаётся как отношение числа верных срабатываний к общему числу объектов первого класса выборки, то есть число верных срабатываний плюс число ложных пропусков. Посчитаем полноту для наших двух моделей. К первому классу относится сто объектов. И первая модель срабатывает на 80 из них, значит её полнота равна 0.8 или 80 %. Вторая модель срабатывает лишь на 48 положительных объектах. Таким образом, её полнота равняется 48 поделить на сто или 0.48. Вторая модель очень точная, но из-за этого страдает её полнота, она выделяет далеко не все объекты первого класса. Давайте разберём два примера того, как можно пользоваться точностью и полнотой в совокупности. Первый пример про кредитный скоринг. Представьте, что руководство банка решило, что, если среди всех выданных кредитов не более 5 % будут ошибочными, то есть лишь 5 % из них не вернут, то такая схема не будет убыточной. Эти невозвращённые кредиты не дадут нам слишком много убытков. Таким образом, мы получаем ограничение на точность в 0.95. Точность должна быть ≥, чем 0.95. И при таком ограничении мы будем максимизировать полноту, то есть стараться выдать кредиты как можно большему количеству хороших заёмщиков. Второй пример про медицинскую диагностику. Представьте, что мы сделали модель, хотим сделать модель, которая определяет: есть или нет то или иное заболевание у пациента. При этом наш заказчик требует, чтобы среди всех протестированных пациентов мы выделили как минимум 80 % тех, которые действительно имеют это заболевание. Таким образом, мы получаем ограничение, что полнота должна быть не меньше, чем 80 %. И при этом ограничении мы будет максимизировать точность, то есть пытаться сделать как можно меньше число ложных срабатываний. Наконец, обратите внимание, как точность и полнота работают на несбалансированных выборках. Представьте, что у нас есть выборка, в которой сто объектов первого класса и более десяти тысяч объектов отрицательного класса, -1 класса. При этом у нас 10 верных срабатываний, 20 ложных срабатываний и 90 ложных пропусков. Доля верных ответов на данной выборке равняется 99 %. Скорее всего, это число ни о чём не говорит. Чтобы понять, что плохого с данным алгоритмом, нужно померить точность и полноту. Давайте измерим точность. Всего алгоритм срабатывает на тридцати объектах, и из них лишь 10 — это верные срабатывания, значит точность равна 33 %. Видно, что алгоритм делает слишком много ложных срабатываний — 66 %. Далее полнота. Всего в выборке сто объектов первого класса, из их них лишь на 10 алгоритм срабатывает. Таким образом, полнота равняется 10 %. Видно, что у него также много ложных пропусков. Он пропускает 90 % объектов первого класса. Благодаря точности и полноте мы можем видеть, что не так с этим алгоритмом и что можно пытаться улучшить. Итак, мы с вами ввели матрицу ошибок и на её основе определили две метрики качества: точность и полноту. Точность измеряет, как много у нас ложных срабатываний, а полнота — как много ложных пропусков. И можно отдавать предпочтение одной или другой в зависимости от специфики задачи. Также мы выяснили, что точность и полнота могут быть очень полезными в случаях со сбалансированными выборками. В следующем видео мы поговорим о том, как можно объединить точность и полноту в одну метрику качества.

 В этом видео мы поговорим о том, как объединить точность и полноту в одну метрику качества классификации. В прошлый раз мы выяснили, что точность показывает, насколько мы можем доверять классификатору в случае, если он срабатывает. То есть в случае, если он относит объект к первому классу. Полнота же измеряет, как много объектов первого класса наш классификатор выделил, на скольки из них он сработал. При этом есть задачи, где имеет место ограничение на одну из этих метрик, например, точность должна быть не меньше 95 %. И при этом мы будем оптимизировать другую метрику, например, полноту. Но при этом, точность и полнота хороши сами по себе, например, тем, что они более выразительны на несбалансированных выборках. И у нас может просто возникнуть желание максимизировать и точность, и полноту одновременно, но, при этом максимизировать две метрики, это не очень удобно. Лучше сначала объединить их в одну. Давайте выясним, как это правильно сделать. Первый подход, который мы обсудим, это арифметическое среднее. Просто сложим точность и полноту и поделим на 2. Чтобы визуализировать данный подход к их усреднению, мы будем рисовать линии уровня. По оси x мы будем откладывать точность, по оси y — полноту, и рисовать линии уровня, то есть линии, на которых арифметическое среднее принимает одно и то же значение. Давайте разберём простой пример. Представьте, что у нас есть алгоритм, у которого точность равна 10 %, а полнота — 100 %. На самом деле, это может быть выборка, в которой всего 10 % положительных объектов и алгоритм, который абсолютно на всех объектах выдаёт ответ +1, константный алгоритм. Понятно, что он бесполезен. Среднее арифметическое точности и полноты в этом случае = 55 %. А вот другой алгоритм. У него точность и полнота = 55 %. Этот алгоритм гораздо лучше предыдущего, но при этом среднее арифметическое снова = 55 %. Эти два алгоритма лежат на одной линии уровня. Это очень плохо. Константный и разумный алгоритмы получают один и тот же показатель. Чтобы устранить эту проблему, приходит в голову следующая идея. Раз мы хотим одновременно максимизировать и точность, и полноту, давайте максимизировать минимум из них. В этом случае линии уровня будут выглядеть как-то так. Видно, что они сильнее концентрируются в правом верхнем углу, то есть там, где находится алгоритм с точностью и полнотой, = 1. Данный подход с взятием минимума из точности и полноты решает проблему, которую мы обсуждали чуть раньше. Если взять алгоритм с точностью 5 % и полнотой 100 %, то минимум будет = 5 %. При этом есть другой нюанс. Рассмотрим два алгоритма, оба из которых имеют точность 40 %, но при этом полнота первого = 50 %, а полнота второго = 90 %. Понятно, что второй алгоритм лучше. При такой же точности он даёт более высокую полноту, но при этом и минимум и там, и там = 40 %. Они снова лежат на одной линии уровня, хотя этого не должно быть. Чтобы устранить проблему, давайте попробуем сгладить минимум. Это можно сделать с помощью гармонического среднего или F-меры. Чтобы её посчитать, нужно вычислить дробь, в числителе которой стоит произведение точности и полноты, умноженное на 2, а в знаменателе сумма точности и полноты. Если мы рассматриваем два алгоритма, оба из которых имеют точность 40 %, и при этом первый имеет полноту 50 %, а второй — 90 %, то у первого F-мера = 44 %, а у второго — 55 %. Второй оказывается на линии уровня, которая ближе к правому верхнему углу, ближе к идеальному классификатору. При этом, если вы хотите отдать предпочтение либо точности, либо полноте, можно воспользоваться расширенной версией F-меры, который имеет параметр β. Она вычисляется по такой страшной формуле. При этом, если вы возьмёте β = 0.5, то важнее окажется полнота. Дело в том, что если вы зафиксируете полноту и будете менять точность, то данная F-мера будет меняться довольно гладко. Если же вы зафиксируете точность и будете менять полноту, изменения будут очень резкие. Таким образом, полнота важнее в этом случае. Если же взять β = 2, то ситуация поменяется. Важнее окажется точность. Поскольку при фиксированной полноте изменение точности будет гораздо сильнее приводить к перемене F-меры. Итак, мы обсудили, что лучший способ объединения точности и полноты в одну метрику, это F-мера, которая представляет собой сглаженную версию минимума из точности и полноты. При этом, если вы хотите отдать предпочтение либо точности, либо полноте при усреднении, можно воспользоваться параметром β в F-мере. В следующем видео мы поговорим о том, как измерять качество оценок принадлежности тому или иному классу.

 В этом видео мы поговорим о том, как измерять качество оценок принадлежности к классу. И давайте начнем с того, что разберемся, что это за оценки принадлежности. Дело в том, что многие алгоритмы классификации устроены следующим образом: на самом деле, сначала вычисляется некоторое вещественное число b(x), и далее оно сравнивается с некоторым порогом t. Если оно больше порога, то относим объект к положительному классу, если меньше порога — то к отрицательному классу. Таким образом, b(x) выступает как некоторая оценка уверенности классификатора в том, что объект относится к единичному классу — классу +1. Примером может служить линейный классификатор. В нем мы вычисляем скалярное произведение вектора весов на вектор признаков и дальше сравниваем его, например, с нулем. Если оно больше нуля, то относим объект к одному классу, если меньше нуля — то к другому классу. Здесь в качестве оценки принадлежности выступает скалярное произведение. И, действительно, мы обсуждали, что если есть два объекта, у обоих скалярное произведение больше нуля, но при этом на первом оно больше, чем на втором, это означает, что в принадлежности первого к этому классу алгоритм уверен больше. Итак, зачастую нужно измерить качество именно оценки принадлежности b(x), потому что порог будет выбран заказчиком позже. Например, мы оцениваем вероятность возврата кредита всеми клиентами банка, и дальше банк уже будет выбирать порог, в зависимости от своего желания рискнуть или, наоборот, желания делать консервативную выдачу кредитов. Вот еще одна причина, по которой может понадобиться измерять качество именно оценки принадлежности. Представьте, что мы занимаемся кредитным скорингом и построили некоторую функцию b(x), которая оценивает вероятность того, что клиент x вернет кредит. Далее мы построили классификатор следующим образом: взяли данную вероятность, и если она больше 1 / 2, то будем выдавать клиенту кредит, если меньше 1 / 2, то не будем выдавать ему кредит. И при этом получилось, что точность = 10 %, полнота = 70 %. Это очень плохой алгоритм. Точность в 10 % означает, что 90 % клиентов, которым мы выдадим кредит, не вернут его. Банк такое явно не примет. При этом не понятно, в чем дело: в том, что мы плохо выбрали порог, и нужно было взять его, например, не 1 / 2, а, скажем, 9 / 10, или же в том, что сама оценка b(x) — плохая, и как бы мы ни старались с порогом, невозможно с ее помощью построить классификатор, который будет давать высокую точность. Именно для этого и нужно измерять качество самих оценок b(x). Мы разберем два способа, и первый из них основан на кривой точности-полноты. По оси y будем откладывать... по оси x будем откладывать полноту, по оси y — точность. И точка в этих осях будет соответствовать конкретному классификатору, то есть выбору конкретного порога, по которому мы отсекаем оценку принадлежности b(x). Давайте на примере разберем, как строится кривая точности и полноты. Пусть у нас есть выборка, в которой шесть объектов, из них три относятся к классу 1, три — к классу 0. И они имеют вот такие оценки принадлежности к классу 1. Сначала возьмем порог, при котором ни один объект не будет отнесен к классу 1. В этом случае и точность, и полнота, будем считать, что они равны нулю. Ставим точку (0, 0). Далее чуть-чуть уменьшаем порог так, чтобы ровно один объект с максимальной оценкой был отнесен к классу 1. В этом случае точность будет равна 100 %, полнота будет равна 1 / 3, поскольку мы выделяем один из трех положительных объектов. Ставим следующую точку. При дальнейшем уменьшении порога мы два объекта отнесем к первому классу, и оба будут верными срабатываниями — точность все еще равна 100 %, полнота увеличивается до 2 / 3. Далее, когда мы три объекта отнесем к первому классу, то точность уменьшится, поскольку третий относится к негативному классу, на самом деле, — точность станет равна 2 / 3, — полнота останется такой же. Уменьшаем порог еще сильнее — точность уменьшается, полнота остается такой же. Когда мы отнесем пять объектов к первому классу, точность окажется равной 3 / 5, а полнота будет 100 %, поскольку мы уже выделили все объекты первого класса. Наконец, когда мы все объекты отнесем к классу... классу 1, то получим, что точность равняется 1 / 2, полнота равняется 100 %. Получается вот такая кривая. В реальных задачах, где объектов тысячи и десятки тысяч, кривая точности-полноты выглядит как-то так. Заметим, что стартует она всегда из точки (0, 0). Финальная точка этой кривой находится по координатам 1 и r, полнота равняется 100 %, а точность равняется доли объектов первого класса во всей выборке, которую мы обозначаем как r. Если у нас имеется идеальный классификатор, то и существует такой порог, при котором и точность, и полнота — 100%, то кривая пройдет через точку (1, 1). Чем ближе к этой точке она пройдет, тем лучше наши оценки. Таким образом, площадь под этой кривой может быть хорошей мерой качества оценок принадлежности к классу 1. Введем эту метрику. Будем называть ее AUC — PRC, или площадь под precision-recall-кривой. Второй способ измерить качество — это ROC-кривая, она строится немножко в других осях. По оси x откладывается доля ложных срабатываний, или False Positive Rate. Она считается как отношение числа ложных срабатываний к общему размеру отрицательного класса, то есть False Positives + True Negatives. По оси y будем откладывать долю верных срабатываний, или True Positive Rate. В числителе стоит количество верных срабатываний, в знаменателе — размер первого класса, то есть True Positive + False Negative. Разберем на том же примере, как строится ROC-кривая. Сначала выбираем порог, при котором ни один объект не относится к первому классу. Получаем точку (0, 0) — число... доля верных срабатываний, доля ложных срабатываний равны 0. Далее, когда мы один объект отнесем к классу 1, доля верных срабатываний увеличится на 1 / 3, доля ложных срабатываний останется нулевой. При дальнейшем уменьшении порога доля верных срабатываний увеличится до 2 / 3, доля ложных срабатываний — все еще 0. Отнесем три объекта к классу 1. В этом случае доля верных срабатываний все еще равна 2 / 3, доля ложных срабатываний — 1 / 3. Уменьшаем еще сильнее — доля верных срабатываний остается такой же, доля ложных срабатываний увеличивается до 2 / 3. Далее, доля верных срабатываний увеличивается до 1, доля ложных срабатываний останется 2 / 3. И, наконец, когда все объекты отнесем к классу 1, доля и верных, и ложных срабатываний будет равна 1. В случае с большой выборкой ROC-кривая выглядит как-то так. Она стартует из точки (0, 0) и приходит в точку (1, 1), при этом если есть идеальный классификатор, то его доля верных ответов будет равна 1, доля ложных срабатываний будет равна 0, то есть кривая пройдет через точку (0, 1). Опять же, чем ближе кривая к этой точке, тем лучше наши оценки, и площадь по этой кривой будет характеризовать качество оценок принадлежности к первому классу. Эта метрика называется AUC — ROC, или площадь под ROC-кривой. Давайте разберемся, в чем особенности площади под ROC-кривой и площади под кривой точности-полноты. Начнем с ROC-кривой. Вспомним, что она измеряет долю верных срабатываний и долю ложных срабатываний. При этом доля ложных срабатываний делится на размер негативного класса, доля верных срабатываний делится на размер положительного класса. За счет того, что эти величины делятся на объемы классов, площадь под ROC-кривой не зависит от баланса классов. Если свойства объектов выборки останутся такими же, но лишь изменится соотношение классов, площадь под ROC-кривой не изменится. Площадь под ROC-кривой для идеального алгоритма равна 1, площадь под ROC-кривой для худшего алгоритма, то есть того, который выдает случайные ответы, находится в районе 1 / 2. При этом у площади под ROC-кривой есть много интересных интерпретаций, которые помогают объяснять ее другим людям. Например, она равняется вероятности того, что если вы выберете случайный положительный и случайный отрицательный объект из выборки, то положительный объект получит оценку принадлежности выше, чем отрицательный объект. Перейдем теперь к площади под precision-recall-кривой, она зависит от точности и полноты. При этом в точности нормировка производится не на размер положительного класса, а на число срабатываний алгоритма. Таким образом, если соотношение классов изменится, то изменится и точность, значит и площадь под precision-recall-кривой зависит от соотношения классов. При этом площадь под precision-recall-кривой проще интерпретировать, если выборка сильно несбалансированная. Давайте разберем это на примере. Представьте, что мы построили такие оценки принадлежности, что максимальные оценки — у 50 тысяч объектов отрицательного класса. Далее идут 100 объектов положительного класса. И далее — 950 тысяч объектов отрицательного класса. У нас очень большой отрицательный класс — миллион объектов, и маленький положительный — 100 объектов. И при этом, при такой сортировке, при таком упорядочивании, 100 объектов положительного класса оказались довольно далеко от верха — сначала идет 50 тысяч отрицательных объектов. Понятно, что такая сортировка нас не устраивает — положительные объекты находятся слишком далеко. При этом площадь под ROC-кривой равняется 95 %, площадь под precision-recall-кривой — 0,1 %. Почему-то площадь под ROC-кривой получилась большой, это может ввести в заблуждение. Давайте разберемся, почему так вышло. Чтобы понять, давайте рассмотрим одну точку в пространстве ROC-кривой. Возьмем порог, при котором к первому классу будут отнесены 50 тысяч объектов негативного класса и 95 объектов позитивного класса. Понятно, что это не очень хороший классификатор — у него слишком много ложных срабатываний. Их будет 50 тысяч, при этом верных срабатываний — 95. Доля верных срабатываний равна 95 %, доля ложных срабатываний равна всего 5 %, поскольку в ней нормировка производится на размер всего отрицательного класса. А 50 тысяч — это очень мало, по сравнению с миллионом объектов во всем отрицательном классе. Понятно, что эта точка лежит близко к точке с координатами (0, 1), и поэтому ROC-кривая очень похожа на идеальную — площадь под ней близка к 1. При этом точность и полнота этого алгоритма гораздо лучше отражают ситуацию. Полнота равняется 95 %, а точность — меньше 1 %, поскольку слишком много ложных срабатываний. Таким образом, площадь под кривой точности-полноты гораздо лучше отражает ситуацию в данном примере с несбалансированными выборками. Итак, мы обсудили, что зачастую в машинном обучении нужно измерять качество модели еще до того, как мы выбрали порог, нужно измерять качество оценок принадлежности к первому классу. Для этого подходят такие метрики, как площадь под кривой точности и полноты и площадь под ROC-кривой. При этом площадь под ROC-кривой не зависит от баланса классов и гораздо лучше интерпретируется. А площадь под кривой точности и полноты гораздо выразительнее в случае дисбаланса классов. На этом мы заканчиваем урок, посвященный метрикам качества, а дальше продолжим говорить о линейных моделях.

Метрики качества
4.1. Метрики качества в задачах регрессии
4.1.1. Применение метрик качества в машинном обучении
Метрики качества могут использоваться:
• Для задания функционала ошибки (используется при обучении).
• Для подбора гиперпараметров (используется при измерении качества на кросс-валидации). В том числе
можно использовать другую метрику, которая отличается от метрики, с помощью которой построен
функционал ошибки.
• Для оценивания итоговой модели: пригодна ли модель для решения задачи.
Далее мы рассмотрим, какие метрики можно использовать в задачах регрессии.
4.1.2. Среднеквадратичная ошибка
Первая метрика, о которой уже шла речь — среднеквадратичная ошибка:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
Такой функционал легко оптимизировать, используя, например, метод градиентного спуска.
Этот функционал сильно штрафует за большие ошибки, так как отклонения возводятся в квадрат. Это
приводит к тому, что штраф на выбросе будет очень сильным, и алгоритм будет настраиваться на выбросы.
Другими словами, алгоритм будет настраиваться на такие объекты, на которые не имеет смысл настраиваться.
4.1.3. Средняя абсолютная ошибка
Похожий на предыдущий функционал качества — средняя абсолютная ошибка:
MAE(a, X) = 1
`
X
`
i=1
|a(xi) − yi
| .
Этот функционал сложнее минимизировать, так как у модуля производная не существует в нуле. Но у такого
функционала больше устойчивость к выбросам, так как штраф за сильное отклонение гораздо меньше.
4.1.4. Коэффициент детерминации
Коэффициент детерминации R2
(a, X):
R
2
(a, X) = 1 −
P`
i=1
a(xi) − yi
2
P`
i=1(yi − y¯)
, y¯ =
1
`
X
`
i=1
yi
,

позволяет интерпретировать значение среднеквадратичной ошибки. Этот коэффициент показывает, какую
долю дисперсии (разнообразия ответов) во всем целевом векторе y модель смогла объяснить.
Для разумных моделей коэффициент детерминации лежит в следующих пределах:
0 ≤ R
2 ≤ 1,
причем случай R2 = 1 соответствует случаю идеальной модели, R2 = 0 — модели на уровне оптимальной
«константной», а R2 < 0 — модели хуже «константной» (такие алгоритмы никогда не нужно рассматривать).
Оптимальным константым алгоритмом называется такой алгоритм, который возвращает всегда среднее значение ответов y¯ для объектов обучающей выборки.
4.1.5. Несимметричные потери
До этого рассматривались симметричные модели, то есть такие, которые штрафуют как за недопрогноз, так
и за перепрогноз. Но существуют такие задачи, в которых эти ошибки имеют разную цену.
Пусть, например, требуется оценить спрос на ноутбуки. В этом случае заниженный прогноз приведет к
потере лояльности покупателей и потенциальной прибыли (будет закуплено недостаточное количество ноутбуков), а завышенный — только к не очень большим дополнительным расходам на хранение непроданных
ноутбуков. Чтобы учесть это, функция потерь должна быть несимметричной и сильнее штрафовать за недопрогноз, чем за перепрогноз.
4.1.6. Квантильная ошибка
В таких случаях хорошо подходит квантильная ошибка или квантильная функция потерь:
ρτ (a, X) = 1
`
X
`
i=1

(τ − 1)
yi < a(xi)

+ τ

yi ≥ a(xi)


(yi − a(xi)).
τ − 1
τ
Рис. 4.1: График квантильной функции потерь
Параметр τ ∈ [0, 1] определяет то, за что нужно штрафовать сильнее — за недопрогноз или перепрогноз.
Если τ ближе к 1, штраф будет больше за недопрогноз, а если, наоборот, ближе к 0 — за перепрогноз.
4.1.7. Вероятностный смысл квантильной ошибки
Чтобы разобраться, почему такая функция потерь называется квантильной, нужно разобраться с ее вероятностным смыслом. Пусть один и тот же объект x с одним и тем же признаковым описанием повторяется в
выборке n раз, но на каждом из повторов — свой ответ y1, ..., yn.
Такое может возникнуть при измерении роста человека. Измерения роста одного и того же человека могут
отличаться ввиду ошибки прибора, а также зависеть от самого человека (может сгорбиться или выпрямиться).
При этом алгоритм должен для одного и того же признакового описания возвращать одинаковый прогноз.
Другими словами, необходимо решить, какой прогноз оптимален для x с точки зрения различных функционалов ошибки.
Оказывается, что если используется квадратичный функционал ошибки, то наиболее оптимальным прогнозом будет средний ответ на объектах, если абсолютный, то медиана ответов. Если же будет использоваться
квантильная функция потерь, наиболее оптимальным прогнозом, будет τ -квантиль. В этом и состоит вероятностный смысл квантильной ошибки.
2
4.2. Метрика качества классификации
В этом блоке речь пойдет о том, как измерять качество в задачах классификации.
4.2.1. Доля правильных ответов
Как меру качества в задачах классификации естественно использовать долю неправильных ответов:
1
`
X
`
i=1
[a(xi) 6= yi
]
Однако в задачах классификации принято выбирать метрики таким образом, чтобы их нужно было максимизировать, тогда как в задачах регрессии — так, чтобы их нужно было минимизировать. Поэтому определяют:
accuracy(a, X) = 1
`
X
`
i=1
[a(xi) = yi
] .
Эта метрика качества проста и широко используется, однако имеет несколько существенных недостатков.
4.2.2. Несбалансированные выборки
Первая проблема связана с несбалансированными выборками. Показателен следующий пример. Пусть в выборке 1000 объектов, из которых 950 относятся к классу −1 и 50 — к классу +1. Рассматривается бесполезный
(поскольку не восстанавливает никаких закономерностей в данных) константный классификатор, который
на всех объектах возвращает ответ −1. Но доля правильных ответов на этих данных будет равна 0.95, что
несколько много для бесполезного классификатора.
Чтобы «бороться» с этой проблемой, используется следующий факт. Пусть q0 — доля объектов самого
крупного класса, тогда доля правильных ответов для разумных алгоритмов accuracy ∈ [q0, 1], а не [1/2, 1],
как это можно было бы ожидать. Поэтому, если получается высокий процент правильных ответов, это может
быть связано не с тем, что построен хороший классификатор, а с тем, что какого-то класса сильно больше,
чем остальных.
4.2.3. Цены ошибок
Вторая проблема с долей верных ответов состоит в том, что она никак не учитывает разные цены разных
типов ошибок. Тогда как цены действительно могут быть разными.
Например, в задаче кредитного скоринга, то есть в задаче принятия решения относительно выдачи кредита, сравниваются две модели. При использовании первой модели кредит будет выдан 100 клиентам, 80 из
которых его вернут. Во второй модели, более консервативной, кредит был выдан только 50 клиентам, причем
вернули его в 48 случаях. То, какая из двух моделей лучше, зависит от того, цена какой из ошибок выше:
не дать кредит клиенту, который мог бы его вернуть, или выдать кредит клиенту, который его не вернет.
Таким образом, нужны дополнительные метрики качества, которые учитывают цены той или иной ошибки.
4.3. Точность и полнота
4.3.1. Цены ошибок
В этом разделе пойдет речь о метриках качества классификации, которые позволяют учитывать разные цены ошибок. В конце предыдущего разделе уже было сказано, что цены ошибок действительно могут быть
разными. Так, в задаче банковского скоринга необходимо принять решение, что хуже: выдать кредит «плохому» клиенту или не выдать кредит «хорошему» клиенту. Доля верных ответов не способна учитывать цены
разных ошибок и поэтому не может дать ответа на этот вопрос.
3
4.3.2. Матрица ошибок
Удобно классифицировать различные случаи, как соотносятся между собой результат работы алгоритма и
истинный ответ, с помощью так называемой матрицы ошибок.
y = 1 y = −1
a(x) = 1 True Positive (TP) False Positive (FP)
a(x) = −1 False Negative (FN) True Negative (TN)
Когда алгоритм относит объект к классу +1, говорят, что алгоритм срабатывает. Если алгоритм сработал
и объект действительно относится к классу +1, имеет место верное срабатывание (true positive), а если объект
на самом деле относится к классу −1, имеет место ложное срабатывание (false positive).
Если алгоритм дает ответ −1, говорят, что он пропускает объект. Если имеет место пропуск объекта
класса +1, то это ложный пропуск (false negative). Если же алгоритм пропускает объект класса −1, имеет
место истинный пропуск (true negative).
Таким образом, существуют два вида ошибок: ложные срабатывания и ложные пропуски. Для каждого
из них нужна своя метрика качества, чтобы измерить, какое количество ошибок какого типа совершается.
4.3.3. Точность и полнота
Пусть для примера рассматриваются две модели a1(x) и a2(x). Выборка состоит из 200 объектов, из которых
100 относятся к классу 1 и 100 — к классу −1. Матрицы ошибок имеют вид:
y = 1 y = −1
a1(x) = 1 80 20
a1(x) = −1 20 80
y = 1 y = −1
a2(x) = 1 48 2
a2(x) = −1 52 98
Введем две метрики. Первая метрика, точность (precision), показывает, насколько можно доверять классификатору в случае срабатывания:
precision(a, X) = T P
T P + F P
.
Вторая метрика, полнота (recall), показывает, на какой доле истинных объектов первого класса алгоритм
срабатывает:
recall(a, X) = T P
T P + F N
.
В примере выше точность и полнота первого алгоритма оказываются равными:
precision(a1, X) = 0.8, precision(a2, X) = 0.96
recall(a1, X) = 0.8, recall(a2, X) = 0.48
Вторая модель является очень точной, но в ущерб полноте.
4.3.4. Примеры использования точности и полноты
Первый пример — использование в задаче кредитного скоринга. Пусть в задаче кредитного скоринга ставится условие, что неудачных кредитов должно быть не больше 5%. В таком случае задача является задачей
максимизации полноты при условии precision(a, X) ≥ 0.95.
Второй пример — использование в медицинской диагностике. Необходимо построить модель, которая определяет, есть или нет определенное заболевание у пациента. При этом требуется, чтобы были выявлены как
минимум 80% пациентов, которые действительно имеют данное заболевание. Тогда ставят задачу максимизации точности при условии recall(a, X) ≥ 0.8.
Следует особо обратить внимание на то, как точность и полнота работают в случае несбалансированных
выборок. Пусть рассматривается выборка со следующей матрицей ошибок:
y = 1 y = −1
a(x) = 1 10 20
a(x) = −1 90 10000
4
Доля верных ответов (accuracy), точность(precision) и полнота(recall) для данного случая:
accuracy(a, X) = 0.99, precision(a, X) = 0.33, recall(a, X) = 0.1.
То, что доля верных ответов равняется 0.99, ни о чем не говорит: алгоритм все равно делает 66% ложных
срабатываний и выявляет только 10% положительных случаев. Благодаря введению точности и полноты
становится понятно, что алгоритм нужно улучшать.
4.4. Объединение точности и полноты
В этом разделе пойдет речь о том, как соединить точность и полноту в одну метрику качества классификации.
4.4.1. Точность и полнота (напоминание)
Точность показывает, насколько можно доверять классификатору в случае срабатывания:
precision(a, X) = T P
T P + F P
.
Полнота показывает, на какой доле истинных объектов первого класса алгоритм срабатывает:
recall(a, X) = T P
T P + F N
.
В некоторых задачах есть ограничения на одну из этих метрик, тогда как по второй метрике будет производиться оптимизация. Но в некоторых случаях хочется максимизировать и точность, и полноту одновременно.
Встает вопрос об объединении этих двух метрик.
4.4.2. Арифметическое среднее
Единая метрика может быть получена как арифметическое среднее точности и полноты:
A =
1
2
(precision + recall)
Пусть есть алгоритм, точность которого равна 10%, а полнота — 100%:
precision = 0.1 recall = 1.
Это может быть случай, когда в выборке всего 10% объектов класса +1, а алгоритм является константным
и всегда возвращает +1. Очевидно, что этот алгоритм плохой, но введенная выше метрика для него равна
A = 0.55. В свою очередь другой, гораздо более лучший алгоритм, с precision = 0.55 и recall = 55 также
характеризуется A = 0.55.
Ситуация, когда константный и разумный алгоритмы могут лежать на одной линии, является недопустимой, поэтому следует искать другой способ построения единой метрики.
5
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.2: Линии A =
1
2
(precision + recall) = const в координатах precision–recall
4.4.3. Минимум
Чтобы констрантный и разумный алгоритмы не лежали на одной линии уровня, можно рассматривать:
M = min(precision, recall).
Данный подход решает вышеупомянутую проблему, например:
precision = 0.05, recall = 1 =⇒ M = 0.05.
Но есть другой нюанс: два алгоритма, для которых точности одинаковы, но отличаются значения полноты,
будут лежать на одной линии уровня M:
precision = 0.4, recall = 0.5 =⇒ M = 0.4,
precision = 0.4, recall = 0.9 =⇒ M = 0.4.
Такое тоже недопустимо, так как второй алгоритм существенно лучше первого. recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.3: Линии M = min(precision, recall) = const в координатах precision–recall
6
4.4.4. F-мера
«Сгладить» минимум можно с помощью гармонического среднего, или F-меры:
F =
2 · precision · recall
precision + recall .
Для двух упомянутых выше алгоритма значения F-меры, в отличие от M, будут отличаться:
precision = 0.4, recall = 0.5 =⇒ F = 0.44,
precision = 0.4, recall = 0.9 =⇒ F = 0.55.
Если необходимо отдать предпочтение точности или полноте, следует использовать расширенную F-меру, в
которой есть параметр β:
F = (1 + β
2
)
precision · recall
β
2 · precision + recall.
Например, при β = 0.5 важнее оказывается полнота, а в случае β = 2, наоборот, важнее оказывается точность. recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
recall
precision
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.4: Линии F = const в координатах precision–recall при значениях β = 1, β = 0.5 и β = 2 соответственно
4.5. Качество оценок принадлежности классу
4.5.1. Оценка принадлежности
Многие алгоритмы бинарной классификации устроены следующим образом: сначала вычисляется некоторое
вещественное число b(x), которое сравнивается с порогом t.
a(x) = [b(x) > t],
где b(x) — оценка принадлежности классу +1. Другими словами, b(x) выступает в роли некоторой оценки
уверенности, что x принадлежит классу +1.
В случае линейного классификатора a(x) = [hw, xi > t] оценка принадлежности классу +1 имеет вид
b(x) = hw, xi.
Часто бывает необходимо оценить качество именно оценки принадлежности, а порог выбирается позже из
соображений на точность или полноту.
4.5.2. Оценка принадлежности в задаче кредитного скоринга
Пусть рассматривается задачного кредитного скоринга и была построена некоторая функция b(x), которая
оценивает вероятность возврата кредита клиентом x. Далее классификатор строится следующим образом:
a(x) = [b(x) > 0.5]
При этом получилось, что точность (precision) равна 10%, а полнота (recall) — 70%. Это очень плохой алгоритм, так как 90% клиентов, которым будет выдан кредит, не вернут его.
При этом не понятно, в чем дело: был плохо выбран порог или алгоритм не подходит для решения данной
задачи. Именно для этого необходимо измерять качество самих оценок b(x).
7
4.5.3. PR-кривая
Первый способ оценки принадлежности классу основан на использовании кривой точности-полноты. По оси
X откладывается полнота, а по оси Y — точность. Каждой точке на этой кривой будет соответствовать
классификатор с некоторым значением порога. precision
recall
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.5: Кривая полноты–точности
Для примера будет приведено построение PR-кривой для выборки из 6 объектов, три из которых относятся
к классу 1 и 3 — к классу 0. Соответствующий ей график изображен выше.
b(x) 0.14 0.23 0.39 0.54 0.73 0.90
y 0 1 0 0 1 1
1. При достаточно большом пороге ни один объект не будет отнесен к классу 1. В этом случае и точность
и полнота равны 0.
2. При таком пороге, что ровно один объект отнесен к классу 1, точность будет 100% (поскольку этот
объект действительно из 1 класса), а полнота — 1/3 (поскольку всего 3 объекта 1 класса).
3. При дальнейшем уменьшении порога уже два объекта отнесены к классу 1, точность также остается
100%, а полнота становится равной 2/3.
4. При таком пороге, что уже три объекта будут отнесены к классу 1, точность становится равной 2/3, а
полнота остается такой же.
5. При таком пороге, что четыре объекта отнесены к классу 1, точность уменьшится до 0.5, а полнота
опять не изменится.
6. При дальнейшем уменьшении порога уже 5 объектов будут отнесены к 1 классу, полнота станет равной
100%, а точность — 3/5.
В реальных задачах с числом объектов порядка нескольких тысяч или десятков тысяч, кривая точностиполноты выглядит примерно следующим образом.
8
Рис. 4.6: Кривая точности-полноты в реальных задачах с десятками тысяч объектов
Следует отметить, что начинается PR-кривая всегда из точки (0, 0), а заканчивается точной (1, r), где r
— доля объектов класса 1.
В случае идеального классификатора, то есть если существует такой порог, что и точность, и полнота равны 100%, кривая будет проходить через точку (1, 1). Таким образом, чем ближе кривая пройдет к этой точке,
тем лучше оценки. Площадь под этой кривой может быть хорошей мерой качества оценок принадлежности
к классу 1. Такая метрика называется AUC–PRC, или площадь под PR-кривой.
4.5.4. ROC-кривая
Второй способ измерить качество оценок принадлежности к классу 1 — ROC-кривая, которая строится в осях
False Positive Rate (ось X) и True Positive Rate (ось Y ):
F P R =
F P
F P + T N
, T P R =
T P
T P + F N
.
ROC-кривая строится аналогично PR-кривой: постепенно рассматриваются случаи различных значений порогов и отмечаются точки на графике. Для упомянутой выше выборки ROC-кривая имеет следующий вид: TPR
FPR
0.0
0.0
0.2
0.2
0.4
0.4
0.6
0.6
0.8
0.8
1
1
Рис. 4.7: ROC–кривая
9
В случае с большой выборкой ROC-кривая выглядит следующим образом:
Рис. 4.8: Кривая ROC в реальных задачах с десятками тысяч объектов
Кривая стартует с точки (0, 0) и приходит в точку (1, 1). При этом, если существует идеальный классификатор, кривая должна пройти через точку (0, 1). Чем ближе кривая к этой точке, тем лучше будут оценки,
а площадь под кривой будет характеризовать качество оценок принадлежности к первому классу. Такая
метрика называется AUC–ROC,или площадь под ROC-кривой.
4.5.5. Особенности AUC-ROC
Как было написано выше, ROC-кривая строится в осях F P R и T P R, которые нормируются на размеры
классов:
F P R =
F P
F P + T N
, T P R =
T P
T P + F N
.
Следовательно, при изменении баланса классов величина AUC-ROC и неизменных свойствах объектов выборки площадь под ROC-кривой не изменится. В случае идеального алгоритма AUC − ROC = 1, а в случае
худшего AUC − ROC =
1
2
.
Значение AUC−ROC имеет смысл вероятности того, что если были выбраны случайный положительный и
случайный отрицаельный объекты выборки, положительный объект получит оценку принадлежности выше,
чем отрицательный объект.
4.5.6. Особенности AUC-PRC
PR-кривая строится в осях precision и recall:
precision =
T P
T P + F P
, recall =
T P
T P + F N
,
а следовательно изменяется при изменении баланса классов.
