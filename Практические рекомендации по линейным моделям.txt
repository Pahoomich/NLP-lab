

Мы начинаем урок, в котором обсудим различные особенности, с которыми вы можете столкнуться при применении линейных моделей к реальным задачам. И первый аспект, о котором мы поговорим, это масштабирование признаков. Давайте начнем с простого примера, на котором поймём необходимость масштабирования. Представьте, что нам нужно найти минимум простой функции w1²+ w2². В общем-то понятно, что минимум достигается в точке (0, 0), но давайте посмотрим, что будет, если мы воспользуемся градиентным спуском для минимизации этой функции. Её линии уровня выглядят как-то так. Это круги. Поскольку переменные в этой функции симметричны, можно поменять местами w1 и w2, то линии уровня тоже симметричные. Если вы решите запустить градиентный спуск из точки (1, 1), то вектор антиградиента будет смотреть влево и вниз, а его координаты равны (-2, -2). Этот вектор проходит через точку минимума (0, 0). Если вы подберёте правильный размер шага при этом антиградиенте, то уже на первом шаге градиентного спуска попадёте строго в точку минимума этой функции. Градиентный спуск будет хорошо работать на этой функции. Давайте теперь немного её изменим. Добавим перед слагаемым w2² коэффициент 100. В этом случае функционал будет выглядеть вот так. Он уже несимметричный. Перед переменной w2 стоит большой коэффициент. В этом случае линии уровня будут выглядеть вот так. Это уже эллипсы, сильно вытянутые вдоль оси x, поскольку перед второй переменной стоит большой коэффициент, изменение по ней при небольшом изменении w2 гораздо сильнее. Если мы, опять же, запустим градиентный спуск из точки (1, 1), то вектор антиградиента в этой точке будет иметь координаты -2 и -200, он будет смотреть практически строго вниз и проходить мимо точки минимума функции. Если вы сделаете шаг у этого вектора, то промахнётесь, и у вас есть шанс стать ещё дальше от минимума, чем вы были в начальном приближении. Градиентный спуск будет иметь большие проблемы, если вы запустите его на этой функции. Итак. Градиентный спуск работает хорошо, если линии уровня функции похожи на круги, как на этом примере. В этом случае, откуда бы вы ни начали, вектор антиградиента будет смотреть в сторону минимума функции и будет сходиться довольно быстро. Если же линии уровня вот такие, то градиентный спуск будет иметь проблемы. Направление антиградиента будет слабо совпадать с направлением в сторону минимума функции, и градиентный спуск будет делать много лишних шагов. Его сходимость будет медленная. И более того, есть риск расхождения градиентного спуска, если размер шага будет подобран неправильно. Вот ещё один пример. Представьте, что у вас есть некая заявка на грант, и вам нужно предсказать, будет ли выдан грант по этой заявке, будет ли она одобрена. И представьте, что у вас есть два признака. Первый признак говорит, сколько уже успешных заявок было у данного заявителя. Понятно, что если много его предыдущих заявок было одобрено, у него большой опыт, у него хорошо получается писать заявки, и данная, скорее всего, тоже будет одобрена. Второй признак — это год рождения заявителя. Масштабы у этих признаков очень разные. Число одобренных грантов — это, скорее всего, единицы, а год рождения — это тысячи. У них разный масштаб. И из-за этого линии уровня функции будут скорее выглядеть как вытянутые эллипсы, чем как круги. Именно различие в масштабе признаков приводит к тому, что линии уровня не похожи на круги. Чтобы бороться с этой проблемой, чтобы у градиентного спуска не было никаких плохих нюансов при применении к таким выборкам, признаки нужно масштабировать, то есть приводить к одному масштабу. Мы разберём два способа масштабирования. И первый из них называется нормализацией. Итак. Представьте, что мы хотим отмасштабировать j-тый признак. В этом случае нам нужно сначала вычислить две вспомогательные величины: среднее значение этого признака и стандартное отклонение этого признака. Для вычисления среднего мы просто суммируем значение этого признака на всех объектах обучающей выборки, и делим на размер выборки. Чтобы вычислить стандартное отклонение, мы суммируем квадраты отклонений значений этого признака на объектах обучающей выборки от среднего значения μj. И делим на число объектов обучающей выборки, после чего извлекаем корень. После этого нам известны среднее значение μj-тое и стандартное отклонение σj-тое. Теперь, чтобы отмасштабировать признак, мы берём каждое его значение, например на i-том объекте xij-тое, вычитаем из него среднее μj-тое и делим на стандартное отклонение σj-тое. После этих операций мы уберём сдвиги и различия в масштабах у всех признаков, и они будут иметь примерно одинаковый масштаб. Второй подход называется масштабированием на отрезок [0, 1]. В этом случае нам нужно тоже вычислить две вспомогательные величины, но немного другие. Это будут минимальное и максимальное значение данного признака на всей обучающей выборке. Минимальное значение обозначаем буквой mj-тое, максимальное значение буквой Mj-тое. После того, как они найдены, мы берём значение данного признака на конкретном объекте, вычитаем из него минимальное значение данного признака и делим на разность между максимальным и минимальным значением данного признака. После такого преобразования минимальное значение признака будет отображено в ноль, максимальное в единицу. Получается, что данный признак отмасштабирован на отрезок [0, 1]. Итак. Мы с вами обсудили, что различия в масштабах признаков — это очень плохо, применение градиентного спуска к таким выборкам может привести к его очень плохой сходимости или даже к его расхождению. Чтобы бороться с этим признаки нужно масштабировать. Мы обсудили два способа масштабирования признаков. Первый называется нормализацией, в котором мы вычитаем среднее и делим остаток на отклонение признака, второй — это масштабирование на [0, 1]. В следующем видео мы поговорим о том, как использовать в линейных моделях нелинейные признаки.

В этом видео мы поговорим о спрямляющих пространствах, которые позволяют восстанавливать нелинейные зависимости с помощью линейных моделей, и начнем с простого примера. Представьте, что мы решаем задачу регрессии, в которой есть всего один признак, который отложен по оси X, и по этому признаку нужно восстановить целевую переменную y, которая отложена по оси Y. Если мы попробуем применить линейную модель, то она получится вот такой. Видно, что она плохо подходит для решения задачи. Зависимость y от x явно нелинейная. Давайте теперь попробуем немножко модифицировать нашу модель. Добавим к исходному признаку x еще три признака: x², x³ и x⁴. Если мы над этими новыми признаками надстроим линейную модель, в которой будет уже 5 коэффициентов, а не 2, как было раньше, то получим вот такую модель. Видно, что она практически идеально описывает данные. Она очень хорошо решает задачу и при этом не переобучается. Получается, что мы перешли к новому признаковому пространству, в котором 4 признака, а не 1, в нем построили линейную модель, а в исходном пространстве эта модель уже нелинейная, и она очень хорошо описывает данные. А вот другой пример. Задача классификации с двумя признаками, x₁ и x₂, которые отложены по осям. Опять же видно, что разделяющая поверхность здесь вовсе не линейная. Если мы настроим линейный классификатор, он получится вот таким. Все объекты будет относить к красному классу. Это лучшее, что он может сделать, но понятно, что это никуда не годится. Опять же попробуем добавить новых признаков, а именно x₁², x₂² и x₁ * x₂, то есть квадратичные признаки. Если над ними построить линейную модель, то разделяющая поверхность в исходном пространстве будет вот такой. Она будет иметь форму окружности и очень хорошо разделять красные точки и синие точки. Опять же, в новом признаковом пространстве, имеющем большую размерность, мы построили линейную модель, и это соответствует построению нелинейной разделяющей поверхности в исходном двумерном признаковом пространстве. Таким образом, мы приходим к понятию спрямляющего пространства. Это такое признаковое пространство, в котором задача хорошо решается линейной моделью. Давайте разберем несколько примеров, как такое пространство можно отстроить. И первый пример — это добавление квадратичных признаков. Пусть объект описывается признаками x₁, ..., xd. Всего d признаков. Тогда добавим к этим признакам еще несколько, а именно квадраты исходных признаков x₁², ..., xd² и попарные произведения x₁x₂, x₁x₃ и так далее до x(d−1)xd. Заметим, что число признаков увеличится на порядок. Если у вас было не очень много объектов, то есть риск переобучения в таком большом признаковом пространстве. Нужно быть осторожным при использовании спрямляющих пространств. Если же у вас объектов много и вы не боитесь переобучения, но при этом знаете, что зависимости очень нелинейные, можно попробовать полиномиальные признаки более высоких порядков, например признаки третьего порядка. В этом случае помимо квадратичных признаков мы добавим еще кубы исходных признаков, то есть x₁³, x₂³, ..., а также произведение всех троек признаков x i-тое * x j-тое * x k-тое, где i, j и k — это какие-то индексы признаков. Также можно брать другие нелинейные функции. Например представьте, что мы используем признак «стоимость книги в интернет-магазине». Мы уже обсуждали этот пример ранее. Как мы говорили, большинство книг будут иметь стоимость в районе нескольких сотен рублей, но при этом есть очень дорогие книги. Распределение значений этого признака будет иметь тяжелый правый хвост. Это не очень хорошо для линейных моделей. Известно, что они работают гораздо лучше, если распределение признаков близко к нормальному. Чтобы сделать такое распределение тяжелых хвостов более близким к нормальному, нужно его прологарифмировать. Итак, если признак принимает только неотрицательные значения, то мы берем значение данного признака xᵢ, прибавляем к нему единицу, чтобы не взять логарифм от нуля, и берем логарифм от xᵢ + 1. После этого распределение станет более похожим на нормальное. Или же, если признак принимает как положительные, так и отрицательные значения, то можно сначала взять модуль от значения этого признака, а затем уже прибавить единицу и взять логарифм. Можно пробовать и другие нелинейные функции, но не будем об этом говорить сейчас. Итак, мы обсудили, что далеко не все задачи хорошо решаются линейными моделями. Но линейные модели можно применить к восстановлению нелинейных зависимостей, если перейти в спрямляющее пространство, то есть перейти к новым признакам, которые гораздо более сложные, чем исходные. Порождать эти признаки можно самыми разными способами, например достроить квадратичные, или кубические, или полиномиальные признаки более высоких размерностей. Или, скажем, брать логарифмы от исходных признаков. В следующем видео мы поговорим о том, как применять линейные модели к категориальным признакам.

В этом видео мы поговорим о том, как использовать категориальные признаки в линейных или других моделях. Мы уже приводили много примеров категориальных признаков. Это может быть город или цвет или, например, тарифный план у мобильного оператора или марка автомобиля. Особенность категориальных признаков в том, что это элементы некоторого неупорядоченного множества. Мы не можем говорить, что одно значение больше или меньше другого, можем только сравнивать их на равенство. А при этом в линейных моделях нам нужно брать значение признака, умножать его на вес и складывать с какими-то другими числами. Это нельзя делать со значениями категориальных признаков, их нужно как-то преобразовать, чтобы их можно было использовать в линейных моделях. Одним из наиболее популярных подходов к кодированию признаков, категориальных признаков, является бинарное кодирование. Давайте введем несколько обозначений, которые помогут нам понять, в чем оно заключается. Итак, представьте, что j-тый признак задачи категориальный. Значение j-того признака на объекте x будем обозначать, как fj (x). Допустим, он принимает n различных значений. Пронумеруем их. Обозначим эти значения, как c1, c2... cn. Чтобы закодировать данный признак, введем n новых бинарных признаков, которые обозначим, как b1 (x), b2 (x)... до bn (x). Значение i-того бинарного признака равно 1 только в том случае, если на данном объекте категориальный признак принимает значение ci. Если же он принимает какое-то другое значение, то i-тый признак будет равен 0. Таким образом, мы заменяем один категориальный признак на n бинарных, значения которых — это по сути числа, и из этих бинарных признаков единице равен только тот, который соответствует нашему значению категориального признака на этом объекте. Давайте разберем простой пример. Представьте, что j-тый признак — это цвет и он принимает три значения: синий, зеленый и красный. И у нас есть три объекта (x1, x2 и x3), на которых значение категориального признака равно «синий», «красный» и «синий», соответственно. Итак, категориальный признак принимает три значения. Нам понадобится три бинарных признака, чтобы его закодировать. Мы получим вот такую матрицу: первый столбец в ней, первый признак, соответствует значению «синий», второй — значению «зеленый», третий — значению «красный». И у нас есть три объекта, каждый из которых соответствует одной из строк. На первом и третьем объекте категориальный признак принимает значение «синий», значит, единица у них будет стоять в первом столбце. На втором объекте категориальный признак принимает значение «красный». Красный — это третий столбец, значит, единица стоит в третьем столбце. Эта матрица кодирует наш категориальный признак тремя бинарными. При этом вы можете столкнуться с такой проблемой: когда вы будете пытаться построить такое же кодирование для тестовой выборки, там может оказаться объект, на котором категориальный признак принимает новое, (n + 1)-е значение, которое вы не видели раньше на обучающей выборке. В этом случае логичным подходом будет не добавлять новый признак, это очень сложно, просто приравнять 0 все существующие признаки. Поскольку смысл наших бинарных признаков — это принимает ли категориальный признак то или иное значение от c1 до cn, то мы просто выставляем их равными 0, поскольку ни одно из них не получается на данном объекте. Итак, мы обсудили, что категориальные признаки нельзя непосредственно использовать в линейных моделях, и поговорили о том, как использовать бинарное кодирование, то есть кодирование одного категориального признака с помощью n бинарных, чтобы внедрять каким-то образом категориальные признаки в линейные модели. В следующем видео мы поговорим о том, как работать с задачами несбалансированной классификации.

В этом видео мы поговорим о том, что такое несбалансированные выборки, к каким проблемам они могут привести и как бороться с такими проблемами. Итак, представьте, что мы решаем задачу классификации с некоторой выборкой. Эта задача называется несбалансированной, если объектов одного или нескольких классов в этой выборке существенно меньше, чем объектов всех остальных классов. Например, если мы решаем задачу бинарной классификации, то есть класса всего два, то есть такое правило: выборка считается несбалансированной, если объектов одного класса 10 % или меньше от общего числа объектов выборки. Примеров задач с несбалансированными выборками довольно много. Например, представьте, что мы хотим предсказывать, случится ли на следующий день резкий скачок курса доллара. Если определение резкого скачка будет такое, что мы хотим ловить только очень сильные изменения, то примеров таких изменений за всю историю – единицы, но при этом практически каждый день – это отрицательный пример, то есть пример, когда такого скачка не было. Выборка в этом случае будет очень несбалансированной. Примеров может быть очень много: это медицинская диагностика, где больных, как правило, сильно меньше, чем здоровых, это обнаружение мошеннических транзакций по картам в банке, где примеров таких плохих транзакций существенно меньше, чем обычных транзакций, или это может быть классификация текстов, где мы пытаемся находить какие-то очень редкие классы. Основная проблема, связанная с несбалансированными выборками, в том, что практически все классификаторы пытаются минимизировать число ошибок на обучающей выборке. Они никак не учитывают цены ошибок, и может оказаться выгоднее отнести все объекты к наибольшему классу, не пытаясь как-то выделить объекты маленького класса. То есть при работе с несбалансированными выборками классификаторы могут получаться очень плохие с точки зрения точности или полноты. Мы разберем два подхода к работе с несбалансированными выборками, и первый называется undersampling. Его основная идея состоит в том, что нам не нужно много примеров объектов из больших классов, можно выкинуть часть из них. Например, представьте, что у нас есть три класса: первый — очень большой; второй — совсем маленький; и третий имеет средний размер. В этом случае мы выкинем большую часть объектов первого класса и половину объектов третьего класса. В этом случае размеры классов примерно сравняются. При этом то, сколько именно объектов каждого класса мы выбрасываем, это гиперпараметр, который имеет смысл настраивать по отложенной выборке или на кросс-валидации. Второй подход – это oversampling. Он противоположен предыдущему. Мы будем дублировать объекты маленьких классов так, чтобы выравнять соотношение классов. В нашем примере мы пять раз повторим объекты второго класса, а для третьего класса мы возьмем случайную половину объектов и продублируем их. Таким образом третий класс мы увеличим в полтора раза. В этом случае размеры выборок, размеры классов тоже выравняются. То, насколько мы будем увеличивать каждый класс, – это тоже гиперпараметр. Обратим внимание на одну особенность. Если мы решаем задачу на исходной выборке, то, например, среднеквадратичная ошибка будет выглядеть вот так. Это среднее значение квадратичной ошибки по всем объектам. Если же мы делаем oversampling, то есть дублируем какие-то объекты, то это будет означать, что какое-то слагаемое войдет в эту сумму несколько раз. Таким образом, вместо реального дублирования объектов, мы можем просто выставить соответствующие веса при каждом слагаемом. Например, если первый объект мы продублируем три раза, то мы просто выставим вес при нем равным трем, v1 будет равно 3. Обратим внимание на еще одну проблему, с которой можно столкнуться при работе с несбалансированными выборками. Напомню, что когда мы проводим кросс-валидацию, мы разбиваем исходную выборку на k блоков примерно одинаковой длины. При этом если выборка несбалансированная и, например, первого класса очень мало, то при таком разбиении может оказаться, что в некоторые блоки объекты первого класса не попадут вообще. Это будет очень плохо. Например, при обучении на этом блоке мы получим классификатор, который никогда не видел один из классов. Чтобы бороться с этим, нужно делать стратификацию. При стратификации мы строим разбиение на блоки так, чтобы распределение классов в каждом блоке примерно совпадало с распределением классов в исходной выборке. В этом случае будет гарантироваться, что объекты каждого класса будут представлены в каждом из блоков разбиения. Итак, мы обсудили, что несбалансированные выборки – это проблема, с которой можно столкнуться при решении задач классификации. В этом случае константный классификатор может оказаться лучше с точки зрения алгоритма обучения, чем какой-то разумный классификатор, выделяющий объекты маленького класса. Чтобы бороться с такой проблемой, есть несколько подходов, например oversampling и undersampling, в которых мы либо уменьшаем большие классы, либо дублируем объекты маленьких классов, чтобы как-то выравнять пропорции этих классов. Также мы поговорили, что в случае с несбалансированными выборками могут возникнуть проблемы при разбиении данных на кросс-валидацию или на обучающую и отложенную выборку. В этом случае нужно делать стратификацию, то есть стараться сохранить соотношение классов в каждой подвыборке при разбиении. В следующем видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей.

В этом видео мы поговорим о том, как решать задачи многоклассовой классификации с помощью линейных моделей. Итак, как следует из названия, в задачах многоклассовой классификации — K возможных классов. Например, на этой картинке изображена выборка, у которой три класса: синий, красный и зелёный. И нужно как-то научиться отличать каждый класс от всех остальных. В случае с бинарной классификацией наш подход был довольно простой. Мы находили такой вектор весов w, что знак скалярного произведения этого вектора весов на вектор признаков говорил, к какому классу относится тот или иной объект. На самом деле, этот подход можно расширить и применить его же к задаче многоклассовой классификации. Это называется — один против всех. Мы будем строить свой бинарный классификатор для каждого класса. И задачей этого классификатора будет отделение данного класса от всех остальных. Например, на этой картинке мы можем отделить зелёные точки от всех остальных с помощью такого линейного классификатора. А красные точки от всех остальных — с помощью вот такого. Давайте поговорим об этом подходе чуть более формально. Итак, Мы будем решать K задач бинарной классификации. Рассмотрим одну из них. Допустим, мы хотим отделить класс k от всех остальных классов. В этом случае у нас будет несколько специфичная выборка. Объекты x i-тое останутся такими же, а вот ответы будут бинарными. Ответ на i-том объекте будет = 1, если этот объект относится к классу k и — 0, если он относится к какому-то другому классу. Объектов в выборке будет столько же, сколько и в условной задаче — l штук. Мы построим некоторый линейный классификатор, который отделяет k-тый класс от всех остальных. Он будет иметь вид знака скалярного произведения электровесов в w k-тое на вектор признаков x. Как мы говорили раньше, если скалярное произведение больше 0, то классификатор считает, что объект относится к классу 1. В нашем случае это будет класс k. И чем больше значение этого скалярного произведения, тем больше классификатор уверен в этом решении. Таким образом, будет логично отнести объект к тому классу, уверенность в принадлежности к которому больше всего, то есть для которого скалярное произведение w k-тое на x больше всего. Именно так и будет выглядеть итоговый многоклассовый классификатор a(x). Он будет возвращать тот класс k, для которого скалярное произведение w k-того на x больше всего. Удобно смотреть на матрицу ошибок, когда мы пытаемся проанализировать, насколько хорошо работает наш многоклассовый классификатор. Она может выглядеть вот так. Каждая строка соответствует тем объектам, который классификатор отнёс к тому или иному классу, а каждый столбец соответствует объектам, который на самом деле относится к тому или иному классу. Например, на пересечении первой строки второго столбца будет стоять число q12, которое показывает, сколько объектов второго класса наш классификатор отнёс к первому классу. Эта матрица, например, может позволить понять, какие классы мы путаем между собой чаще всего. Можно измерять и знакомые нам метрики качества. Например, долю правильных ответов или accuracy. Формула её вычисления никак не поменяется в зависимости от числа классов — два их, три или сто. Также можно измерять точность и полноту для задачи отделения того или иного класса от всех остальных классов. Если мы вычислим такие точность и полноту для каждого из классов, после этого их можно усреднить, получив такие агрегированные оценки. Или, например, можно вычислить F-меру для сдачи отделения одного класса от всех остальных и потом усреднить этот показатель по всем классам. Итак, мы обсудили, что многоклассовые задачи можно решать путём нахождения нескольких бинарных классификаторов. Этих классификаторов будет столько, сколько у нас классов в исходной задаче. При этом, например, удобно смотреть на матрицу ошибок, которая позволяет понять, какие классы мы путаем между собой чаще всего. Или можно вычислять знакомые нам метрики качества: долю правильных ответов, точность, полноту или F-меру.

Практические рекомендации по
линейным моделям
Этот урок будет посвящен сложностям, с которыми можно столкнуться при применении линейных моделей
к реальным задачам.
6.1. Масштабирование признаков
6.1.1. Пример: необходимость масштабирования
Понять необходимость масштабирования можно на следующем простом примере. Пусть необходимо найти
минимум:
w
2
1 + w
2
2 → min
w
.
Ответ в этом случае очевиден — это точка (0, 0). При поиске этого минимума методом градиентного спуска
с начальной точкой w = (1, 1), вектор антиградиента будет иметь координаты (−2, −2). Это вектор проходит
через точку минимума, а значит при правильно подобранном размере шага, уже на первом шаге градиентного
спуска можно попасть строго в точку минимума. Градиентный спуск будет хорошо работать на этой функции.
Изменим функцию:
w
2
1 + 100w
2
2 → min
w
.
В этом случае линии уровня представляют собой эллипсы, сильно вытянутые вдоль оси x. Если запустить
градиентный спуск из точки w = (1, 1), вектор антиградиента в этой точке будет иметь координаты (−2, −200).
Вектор будет смотреть почти строго вниз и проходить мимо точки минимума функции. Более того, существует
шанс на следующей итерации уйти еще дальше от минимума.
Итак, градиентный спуск работает хорошо, если линии уровня функции похожи на круги. В этом случае,
откуда бы вы не начали, вектор градиента будет всегда смотреть в сторону минимума функции, а итеративный процесс будет сходиться довольно быстро. Если же линии уровня похожи на эллипсы, направление
антиградиента будет слабо совпадать с направлением в сторону минимума функции. Градиентный спуск будет делать много лишних шагов. Сходимость будет медленная, и более того, существует риск расхождения
итеративного процесса, если размер шага будет подобран неправильно.
6.1.2. Масштабирование выборки
Пусть требуется предсказать, будет ли выдан грант по заявке. Заявка характеризуется двумя признаками —
сколько уже успешных заявок было у данного заявителя и год рождения заявителя. Масштабы этих двух
признаков существенно отличаются: количество одобренных грантов обычно меряется единицами, а год рождения — тысячами. Из-за такого различия в масштабе линии уровня функции будут выглядеть скорее как
эллипсы, а не как круги.
1
Рис. 6.1: Если масштабирование не было произведено, при использовании метода градиентного спуска будет
сделано много лишних шагов, а также существует риск расхождения итеративного процесса.
В таком случае, чтобы без проблем пользоваться градиентным спуском, признаки необходимо привести к
одному масштабу, то есть отмасштабировать. Будут рассматриваться два способа масштабирования.
Первый способ называется стандартизацией. Для начала необходимо вычислить вспомогательные величины: средние значения признаков и стандартные отклонения:
µj =
1
`
X
`
i=1
x
j
i
, σj =
vuut
1
`
X
`
i=1
(x
j
i − µj )
2
Чтобы произвести стандартизацию признака, достаточно вычесть из него его среднее значение и разделить
на его стандартное отклонение:
x
j
i
:=
x
j
i − µj
σj
После того, как это будет выполнено для всех признаков, сдвиги и различия в масштабах будут убраны.
Второй подход называется «масштабирование на отрезок [0, 1]». В этом случае также необходимо вычислить вспомогательные величины: максимальное и минимальное значение каждого признака на обучающей
выборке:
mj = min(x
j
1
, ..., x
j
`
), Mj = max(x
j
1
, ..., x
j
`
).
После этого значение каждого признака на конкретном объекте преобразовывается следующим образом:
x
j
i
:=
x
j
i − mj
Mj − mj
.
Тогда минимальное значение признака отображается в ноль, а максимальное — в 1, то есть признаки масштабируются на отрезок [0, 1].
6.2. Нелинейные зависимости
В этом разделе речь пойдет о спрямляющих пространствах, которые позволяют восстанавливать нелинейные
зависимости с помощью линейных моделей. Для начала простой пример.
6.2.1. Нелинейная задача регрессии
Пусть решается задача регрессии с одним признаком, отложенным по оси x. По этому признаку требуется
восстановить целевую переменную y.
2
Рис. 6.2: Линейная модель сама по себе не способна восстанавливать нелинейные зависимости.
Как можно в этом убедиться, непосредственное применение линейной модели не дает желаемых результатов и плохо подходит для решения данной задачи. Зависимость y от x явно нелинейная.
Поэтому, кроме признака x, также рассматриваются признаки x
2
, x
3 и x
4
. Если построить линейную
модель на этих признаках, в ней уже будет 5 коэффициентов.
Рис. 6.3: Описать данные удалось с помощью перехода к другому признаковому пространству.
С помощью этой модели уже можно почти идеально описывать данные: она очень хорошо решает задачу,
а также не переобучается.
Фактически был совершен переход к новому признаковому пространству из четырех признаков вместо
одного, в котором была построена линейная модель. А на исходном пространстве эта модель уже нелинейная
и отлично описывает данные.
6.2.2. Задача классификации с нелинейной границей
Другой пример — решается задача классификации с двумя признаками, которые отложены по осям.
Рис. 6.4: Набор данных для рассматриваемой задачи классификации.
3
Видно, что разделяющая поверхность здесь не является линейной. Применение линейного классификатора
дает следующий результат:
Рис. 6.5: Линейный классификатор не смог решить задачу.
То есть все объекты будут отнесены к красному классу: это лучшее, что он может сделать, но понятно,
что это никуда не годится.
Но если кроме признаков x1 и x2 рассмотреть признаковое пространство, которое также включает в себя
признаки x1x2, x
2
1 и x
2
2
, результат будет совершенно иной: разделяющая поверхность будет иметь форму
окружности и очень хорошо разделять красные и синие точки.
4
Рис. 6.6: Красные и синие точки хорошо разделились.
Здесь также в новом пространстве была построена линейная модель, которая является нелинейной в
исходном признаковом пространстве.
6.2.3. Спрямляющее пространство
Два рассмотренных примера дают представление о спрямляющем пространстве. Спрямляющим пространством признаков называется такое пространство, в котором задача хорошо решается линейной моделью.
Спрямляющее пространство может, в том числе, быть построено:
• Через добавление квадратичных признаков, то есть когда к исходным признакам добавляются их квадраты и попарные произведения:
(x1, ..., xd) → (x1, ..., xd, x2
1
, ..., x2
d
, x1x2, ..., xd−1xd).
Следует особо отметить, что в таком случае число признаков увеличивается на порядок. Если объектов
не слишком много, существует риск переобучения в таком большом признаковом пространстве.
• Через добавление полиномиальных признаков:
(x1, ..., xd) → (x1, ..., xd, ..., xixj , ..., xixjxk, ...).
Этот способ следует использовать только, когда объектов достаточно много, то есть риск переобучения
минимален, а также заранее известно, что зависимости очень нелинейные.
• Через логарифмирование (или любые другие нелинейные функции):
xi → ln(xi + 1), xi → ln(|xi
| + 1).
Ранее приводился пример про стоимость книг в интернет-магазине. В данном случае признаком будет
стоимость книги, значение которого для большинства книг составит несколько сотен рублей. Но существуют и встречаются весьма часто очень дорогие книги, так что распределение этого признака будет
иметь «тяжелый правый хвост». Известно, что линейные модели плохо применимы в таком случае и
работают гораздо лучше, если распределение признаков близко к нормальному. Чтобы распределение
признака «с хвостом» сделать более близким к нормальному, нужно прологарифмировать этот признак.
5
6.3. Работа с категориальными признаками
В этом разделе пойдет речь о том, как использовать категориальные признаки в линейных или других моделях.
Ранее уже было приведено множество примеров категориальных признаков:
• Город
• Цвет
• Тарифный план
• Марка автомобиля
• и так далее...
Особенность категориальных признаков состоит в том, что это элементы некоторого неупорядоченного множества, и нельзя говорить, что какое-то значение больше или меньше другого. Можно только сравнивать их
на равенство. Но в линейных моделях нужно брать значение признака, умножать на вес, а потом складывать с
другими числами, и эту операцию нельзя делать со значениями категориальных признаков. Категориальные
признаки нужно сначала преобразовать, чтобы их можно было использовать в линейных моделях.
6.3.1. Бинарное кодирование
Один из наиболее популярных подходов к кодированию категориальных признаков — бинарное кодирование.
Далее будут использоваться следующие обозначения. Пусть j-ый признак — категориальный и принимает n
возможных значений:
c1, ..., cn.
Пусть также fj (x) — значение этого признака на объекте x. Чтобы закодировать данный признак, вводятся
n новых бинарных признаков:
b1(x), ..., bn(x),
причем значение бинарного признака bi равно единице только в том случае, если на данном объекте x значение
категориального признака fj (x) равно ci
:
bi(x) = [fj (x) = ci
].
В результате один категориальный признак заменяется n бинарными признаками.
6.3.2. Бинарное кодирование (пример)
Пусть в качестве признака рассматривается цвет, причем он может принимать три значения: синий, зеленый
или красный. Дано три объекта x1, x2, x3, на которых значения категориального признака:
fj (x1) = синий, fj (x2) = красный, fj (x3) = синий.
Поскольку категориальный признак принимает 3 значения, потребуется 3 бинарных признака, чтобы его
закодировать. В результате получается следующая матрица (каждому объекту соответствует своя строка, а
каждому столбцу — свое значение признака):


1 0 0
0 0 1
1 0 0


6.3.3. Бинарное кодирование: новые значения
Часто возникает следующая проблема. При кодирования тестовой выборки может встретиться объект, на
котором категориальный признак принимает новое (n + 1)-е значение, которое до этого не встречалось в
обучающей выборке. В этом случае логичным подходом будет не добавлять новый признак (поскольку это
сложно реализуется), а просто приравнять к нулю все существующие признаки. Действительно, по смыслу
бинарных признаков (принимает ли категориальный признак значение ci
, i ∈ {1, 2, ..., n}), каждый из них в
таком случае должен равняться нулю.
6
6.4. Несбалансированные данные
В этом разделе пойдет речь о том, что такое несбалансированные выборки, к каким проблемам они могут
привести, а также как бороться с такими проблемами.
6.4.1. Несбалансированная выборка
Пусть решается задача классификации с несбалансированной выборкой. Задача называется несбалансированной, если объектов одного класса существенно меньше, чем объектов остальных классов. Например, задача
бинарной классификации называется несбалансированной, если объектов одного из двух классов менее 10%.
Примеров задач с несбалансированными выборками довольно много:
• Предсказание резких скачков курса доллара. Если определение резкого скачка подразумевает сильные
изменения, то примеров таких изменений за всю историю — единицы, но при этом практически каждый
день — отрицательный пример, то есть пример, когда такого скачка не было. Выборка в этом случае
будет очень несбалансированной.
• Медицинская диагностика (больных, как правило, сильно меньше, чем здоровых)
• Обнаружение мошеннических транзакций (которых существенно меньше, чем обычных транзакций)
• Классификация текстов и так далее.
Основная проблема, связанная с несбалансированными выборками, состоит в том, что классификаторы минимизируют число неправильных ответов и никак не учитывают цены ошибок. Может возникнуть ситуация,
когда выгоднее отнести все объекты к большему классу, не пытаясь как-то выделить объекты маленького
класса. Другими словами, при работе с несбалансированными выборками классификаторы получаются очень
плохие с точки зрения точности или полноты.
6.4.2. Undersampling
Первый подход к работе с несбалансированными выборками — undersampling. Его основная идея состоит в
том, что часть объектов из большого класса выбрасываются из выборки. Пусть, например, есть три класса:
очень крупный, крупный и небольшой
Рис. 6.7: Несбалансированная выборка
В этом случае необходимо выкинуть большую часть 1го класса и половину объектов 3го класса. Размеры
классов примерно сравняются.
7
Рис. 6.8: Undersampling
При этом то, сколько именно объектов каждого класса выбрасывается — это гиперпараметр, который
имеет смысл настраивать по отложенной выборке или по кросс-валидации.
6.4.3. Oversampling
Второй подход, oversampling, противоположен предыдущему: в данном случае объекты маленьких классов
дублируются, чтобы выравнять соотношение классов.
Рис. 6.9: Oversampling
В предыдущем примере 5 раз необходимо продублировать объекты 2го класса, а также продублировать
случайную половину 3го класса. В этом случае размеры классов тоже выравняются. То, на сколько будет
увеличен каждый класс — тоже гиперпараметр.
Следует обратить внимание на одну особенность. Если задача решается на исходной выборке, то среднеквадратичная ошибка выглядит:
MSE(a, X) = 1
`
X
`
i=1
(a(xi) − yi)
2
.
Но если делается oversampling, то есть дублируются какие-нибудь объекты, некоторые слагаемые будут входить в эту сумму несколько раз. Таким образом, вместо реального дублирования объектов, можно выставить
соответствующие веса νi
:
MSE(a, X) = 1
`
X
`
i=1
νi(a(xi) − yi)
2
.
6.4.4. Стратификация
Еще одна проблема, с которой можно столкнуться при работе с несбалансированными выборками, заключается в том, что при проведении кросс-валидации исходная выборка разбивается на k блоков примерно
одинаковой длины. При этом, если выборка несбалансированная, может получиться ситуация, что в некоторые блоки объекты какого-то класса не попадут вообще. Такая ситуация крайне неприятна: при обучении на
этом блоке получается классификатор, который никогда не видел один из классов.
8
Чтобы с этим бороться необходимо использовать стратификацию, то есть делать так, чтобы распределение
классов в каждом блоке примерно совпадало с распределением классов в исходной выборке. В этом случае
будет гарантироваться, что объекты каждого из классов будут представлены в каждом из блоков разбиения.
6.5. Многоклассовая классификация
В этом разделе рассказывается, как решать задачи многоклассовой классификации с помощью линейных моделей. Как следует из названия, в задачах многоклассовой классификации K возможных классов. Требуется
научиться отличать каждый класс от всех остальных.
Рис. 6.10: Многоклассовая классификация
В случае бинарной классификации подход был простой — нужно было найти такой вектор весов w, что
выражение a(x) = signhw, xi определяло бы, какому классу этот объект относится.
6.5.1. ONE-VS-ALL
Этот метод можно применить к задаче многоклассовой классификации. Такой подход называется «один против всех». Как следует из названия, для каждого класса будет строиться свой бинарный классификатор.
Задачей этого классификатора будет отделение данного класса от всех остальных.
Рис. 6.11: ONE-VS-ALL
Формально говоря, будут решаться K задач бинарной классификации. Для каждой (например k-ой) из
этих задач будет весьма специфичная выборка:
X = (xi
, [yi = k])`
i=1,
9
в которой объекты xi остаются такими же, а ответы становятся бинарными. Будет построен некоторый линейный классификатор, который отделяет k-ый класс от всех остальных:
ak(x) = signhwk, xi.
Ранее уже было сказано, что уверенность классификатора в своем решении определяется значением скалярного произведения. Если знак скалярного произведения положительный, то чем больше его модуль, тем
больше классификатор уверен в том, что данный конкретный объект относится к данному классу. Поэтому
для построения многоклассового классификатора можно использовать следующий алгоритм:
a(x) = argmaxk∈1,...,Khwk, xi,
который будет возвращать тот класс k, для которого уверенность соответствующего классификатора (то есть
значение соответствующего скалярного произведения) больше всего.
6.5.2. Матрица ошибок
Для анализа того, насколько хорошо работает многоклассовый классификатор, удобно использовать матрицу
ошибок. Каждая строка этой матрицы соответствует тем объектам, которые классификатор отнес к тому или
иному классу, а каждый столбец соответствует объектам, которые на самом деле относятся к тому или иному
классу.
Например, на пересечении первой строки и второго столбца стоит число q12, которое показывает то, сколько объектов второго класса многоклассовый классификатор отнес к первому. Эта матрица позволяет понять,
какие классы перепутываются чаще всего. Также можно измерять уже известные метрики качества, например:
accuracy =
1
`
X
`
i=1
[a(xi) = yi
].
Кроме того, можно считать точность и полноту (а также F-меру) для задачи отделения того или иного класса
от всех остальных классов. Если точность и полнота будут таким образом вычислены для каждого из классов,
они могут быть позднее усреднены, чтобы получить агрегированные оценки.
