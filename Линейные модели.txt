

Мы начинаем урок, посвященный линейным моделям. В нем мы поговорим о том, как они устроены в задачах классификации и регрессии, как их обучать и с какими проблемами можно столкнуться при использовании этих моделей. А начнем мы этот урок с видео, в котором обсудим, как выглядят линейные модели в задачах регрессии. Давайте сначала вспомним некоторые обозначения, которые мы ввели в прошлом уроке. Буквой X красивая мы обозначаем пространство всех объектов, то есть все возможные объекты, для которых может понадобиться делать прогнозы. А буквой Y красивая обозначаем пространство ответов, то есть все возможные ответы, которые могут иметь наши объекты. Маленькой буквой x обозначаем сам объект, то есть то, для чего нужно делать предсказания. Объект описывается признаками, всего их d штук, и они как-то характеризуют этот объект с помощью чисел или чего-то другого, понятного компьютеру. Большой буквой X обозначается обучающая выборка, то есть наборы из l пар, объект xi-тая и ответ yi-тая на этом объекте. а(x) — это алгоритм или модель, то есть то, что делает предсказание, что предсказывает ответ y по объекту, по его признаковому описанию. Качество алгоритма a измеряется с помощью функционала ошибки Q, которая принимает на вход алгоритм и выборку, на которой измеряется качество этого алгоритма. Процесс обучения заключается в поиске такого алгоритма из семейства алгоритмов A красивое, который минимизирует функционал ошибки. Как я обещал, в этом видео мы обсуждаем задачу регрессии, то есть пространство ответов Y совпадает с множеством вещественных чисел. Ответом может быть любое вещественное число. Чтобы научиться решать задачу регрессии, нужно уметь отвечать на 3 вопроса: во-первых, как выглядит функционал ошибки, то есть как мы измеряем, насколько хорошо или плохо отрабатывает алгоритм на конкретной выборке; второе — это семейство алгоритмов, как оно устроено, как выглядит множество тех алгоритмов, из которых мы выбираем лучшие; и третье — это метод обучения, то есть как именно мы выбираем лучшие с точки зрения функционала ошибки алгоритм из семейства алгоритмов, из этого множества. В этом видео мы ответим на первые 2 вопроса, а о третьем будем мы говорить в следующих видео этого урока. Давайте для начала рассмотрим простой пример с предсказанием прибыли магазина. Пусть в этой задаче есть всего один признак — прибыль магазина в прошлом месяце, а предсказать нужно прибыль магазина в следующем месяце. Понятно, что прибыль — это вещественная переменная, то есть это задача регрессии. Если мы разместим точки обучающей выборки на таком графике, где по оси x находится признак, то есть прибыль в прошлом месяце, а по оси y находится целевая переменная или ответ, то есть прибыль в следующем месяце, то точки расположатся как-то так. Видно, что есть некоторая зависимость, чем больше была прибыль в прошлом месяце, тем больше будет прибыль и в следующем месяце. Можно провести прямую, то есть сказать, что зависимость более-менее линейная, и с помощью этой прямой пытаться предсказывать прибыль в следующем месяце по прибыли в предыдущем месяце. Видно, что в целом прямая угадывает тенденцию, она более-менее описывает зависимость между ответом и признаком. При этом, разумеется, она делает это неидеально, то есть в каждой точке есть некоторая ошибка — истинный ответ на каждом объекте несколько отклоняется от прогноза, но в среднем это ошибка не такая большая, возможно, она нас устроит. На самом деле понятно, что один признак — это не очень серьезно. Если признак всего один, мы можем, как это было сейчас в примере, просто нарисовать нашу выборку, зависимость ответа от признака, и пробовать руками восстановить зависимость. Гораздо сложнее и интереснее работать с многомерными выборками, которые описываются большим количеством признаков. В этом случае нарисовать выборку и понять, подходит ли там линейная модель или нет, нельзя. Можно лишь найти ее и посчитать ее качество и по нему как-то понять — хорошее оно получилось или нет, можно использовать здесь линейную модель или нельзя. Отмечу, что вообще нельзя придумать модель, которая идеально описывает ваши данные, идеально описывает то, как порождается ответ по признакам. Но при этом модели все равно бывают полезными, из них можно извлекать какую-то пользу, если ошибка, которую они допускают, не очень большая. Итак, мы подошли к тому, чтобы обсудить, как именно выглядит семейство алгоритмов в случае с линейными моделями. Линейная модель, линейный алгоритм для задачи регрессии выглядит вот так. Из чего он состоит? Мы берем все признаки объекта, здесь они обозначаются как xj-тая. xj-тая — это j-тый признак объекта, и складываем их с некоторыми весами в wj-тое, при j-том признаке стоит j-тый вес. Также мы прибавляем к этой сумме вес w0. Это свободный коэффициент, или еще его иногда называют сдвигом. Давайте обратим внимание, что сдвиг немножко портит вид модели, он делает его неоднородным. Чтобы устраниться, давайте добавим к данным еще один признак, константный, который на каждом объекте принимает значение 1. В этом случае вес при нем по смыслу будет совпадать со свободным коэффициентом или со сдвигом, и сам w0 будет больше не нужен, его роль будет играть вес при этом признаке. В этом случае признаков будет d + 1, и линейная модель будет выглядеть просто как сумма всех признаков с некоторыми весами. Обратите внимание, что по сути это скалярное произведение вектора весов на вектор признаков. Мы будем часто пользоваться этим обозначением в наших лекциях. Далее давайте обсудим, как измерять ошибку линейного алгоритма на обучающей выборке или на какой-то другой выборке. Давайте рассмотрим пример. Пусть у нас есть объект, (III) на котором равен 10. И посмотрим разные варианты того, что может предсказать наш алгоритм. Предположим, алгоритм от x выдает ответ: 11, этот ответ не совпадает с истинным ответом: 10 и отклоняется на 1. Наверное, это не очень сильное отклонение. Или, например, если ответ нашего алгоритма: 9. Его отклонение будет: −1, поскольку алгоритм ошибается в другую сторону, возможно, это тоже не очень плохо. А что, если алгоритм возвращает число 20? В этом случае отклонение от истины гораздо больше. Разница равна 10. Если же алгоритм возвращает 1, отклонение тоже большое, но в другую сторону. Оно равно −9. В общем-то здесь, понятно, проблема, по которой нельзя использовать отклонение, то есть а(x) − y, как некую меру ошибки. Меру ошибки, или функционал ошибки, мы хотим минимизировать. При этом минимизация отклонения приведет к тому, что алгоритм будет оптимально выдавать минус бесконечность на всех объектах, если мы захотим, чтобы отклонение было как можно меньше. Чтобы устранить проблему, первое, что приходит в голову — это взять модуль от этой разности, минимум модуля — это 0, и достигается он в том случае, если ответ алгоритма и истинный ответ совпадают. Это уже гораздо больше подходит нам, мы можем минимизировать модули отклонения ответов алгоритма от истинных ответов на всех объектах и тем самым настраивать наш алгоритм. Но у модуля есть большая проблема. Эта функция негладкая. У модуля нет производной в нуле, и из-за этого использование градиентных методов оптимизации может быть затруднительно. Чтобы решить и эту проблему давайте просто возведем в квадрат модуль. Квадрат разности — это все еще хорошая функция. Ее минимум равен 0 и достигается, если прогноз алгоритма и истинный ответ совпадают. И при этом квадрат является гладкой функцией, у него есть производная в каждой точке, поэтому его можно минимизировать теми методами градиентными, которые мы будем обсуждать далее. Мы приходим к функционалу ошибки, который называется среднеквадратичной ошибкой. В нем мы вычисляем квадрат отклонения ответа алгоритма от истинного ответа, а(xi-того) и от y-i-того. И суммируем, точнее усредняем, эти квадраты отклонений по всей обучающей выборке. Это и называется среднеквадратичной ошибкой. Обратите внимание, что подставляя сюда линейную модель, то есть вместо a(x) подставляя скалярное произведение w на xi-тое, мы получаем уже не функционал, а функцию, поскольку теперь наша ошибка зависит не от некой функции a(x), а от вектора весов w. И оптимизировать нужно именно по этому вектору весов, что уже гораздо проще. Итак, мы с вами обсудили, как выглядят линейные алгоритмы, или линейные модели, для задачи регрессии и договорились, что будем измерять их качества с помощью среднеквадратичного отклонения, среднеквадратичной ошибки. В следующем видео поговорим о том, как оптимизировать эту ошибку, как настраивать алгоритмы под этот функционал ошибки.

В этом видео мы поговорим о том, как обучать линейную регрессию, как настраивать ее параметры. В прошлый раз мы договорились, что измерять качество линейной модели мы будем с помощью среднеквадратичного функционала ошибки, который считает квадрат отклонения прогноза линейной модели от истинного ответа и усредняет эти квадраты отклонений по всем объектам обучающей выборки. Здесь параметрами являются веса при признаках. Всего у нас d признаков, весов, значит, тоже d, а значит у нас d неизвестных, d чисел, которые нам нужно настроить. При этом мы считаем, что среди признаков есть константный признак, значения которого на всех объектах равны 1, благодаря этому нам не нужно включать константные члены в нашу формулу. Но прежде чем мы перейдем к оптимизации этого функционала, давайте обсудим, как записать в матричном виде среднеквадратичную ошибку. Начнем мы с матрицы «объекты–признаки». Это матрица, в которой l строк, то есть столько, сколько объектов, и d столбцов, то есть столько, сколько признаков. В i-том j-том элементе этой матрицы записаны значения j-того признака на i-том объекте. Таким образом, мы получаем что в i-той строке этой матрицы записаны все признаки i-того объекта, а в j-том столбце этой матрицы записаны значения j-того признака на всех объектах. Также нам понадобится вектор ответов — это вектор y, i-тый элемент которого равен yi-тому, то есть истинному ответу на i-том объекте обучающей выборки. В этом случае мы можем записать в матричном виде среднеквадратичную ошибку, она будет выглядеть вот так. Обратите внимание, когда мы умножаем матрицу «объекты–признаки» X на вектор весов w, мы получаем вектор размера l, то есть такого размера, сколько у нас всего объектов, и i-тый элемент этого вектора — это и есть прогноз нашей модели, скалярное произведение вектора весов на значение признаков на i-том объекте. Вычитаем из этого вектора вектор y, получаем отклонение прогнозов алгоритма от истинных ответов, и, вычисляя евклидову норму, возводя ее в квадрат и после этого поделив на число объектов, получаем среднеквадратичную ошибку. Это то, что нам нужно минимизировать. Нам эта формула пригодится, например, для реализации на компьютере. Так очень удобно вычислять значение среднеквадратичной ошибки на всей выборке. Можно показать, что если взять градиент от этой функции, приравнять его к нулю, выразить вектор весов через все остальное, то можно получить аналитическое решение задачи минимизации среднеквадратичной ошибки. Оно будет выглядеть вот так. Чтобы найти оптимальный вектор весов, нужно умножить матрицу X транспонированное на X, обратить это произведение, умножить на матрицу X транспонированное и умножить на вектор ответов y. Конечно, очень хорошо, что решение записывается аналитически. В этом случае можно не заниматься оптимизацией, но у аналитического решения есть ряд очень серьезных проблем. Самая главная проблема состоит в том, что вам нужно обращать матрицу X транспонированное на X. Обращение это очень тяжелая операция. Матрица X транспонированное на X имеет размеры d на d, то есть число признаков на число признаков. Обращение такой матрицы требует порядка d в кубе операций, Если у вас тысячи или десятки тысяч признаков, обращение будет занимать очень много времени. Также при этом обращении могут возникнуть численные проблемы, если матрица X транспонированное на X устроена не очень хорошо. Поэтому гораздо более простым и удобным подходом является оптимизационный. Несмотря на то что решение можно записать аналитически, давайте все равно с помощью метода оптимизации искать его, а именно с помощью градиентного спуска. Можно показать, что среднеквадратичная ошибка — это выпуклая и гладкая функция. Из выпуклости следует, что у нее всего 1 минимум, а из гладкости следует, что в каждой ее точке можно посчитать градиент, и поэтому можно использовать градиентный спуск для оптимизации. Давайте подробно обсудим алгоритм градиентного спуска. Начинается он с того, что мы каким-то образом находим начальное приближение для вектора весов w с верхним индексом 0. Его можно искать самыми разными способами. Один из самых простых — это инициализировать все элементы вектора весов нулями. То есть w0... каждая компонента w0 — это ноль. Есть и другие подходы. Например, можно инициализировать случайными и не очень большими числами. Далее в цикле мы повторяем следующие операции. На t-той итерации цикла мы берем приближение с предыдущей итерации, то есть wt − 1, и вычитаем из него вектор градиента в этой точке, умноженный на некоторый коэффициент ηt, который называет шагом. Почему мы именно так изменяем вектор весов? Мы обсуждали в прошлом курсе, что градиент показывает в сторону наискорейшего возрастания функции, а антиградиент, то есть вектор градиента с минусом, показывает в сторону наискорейшего убывания. Таким образом, если мы хотим как можно сильнее уменьшить функционал ошибки Q, нам нужно изменять вектор весов именно в сторону антиградиента, что здесь и происходит. Коэффициент ηt (или шаг) нужен для того, чтобы регулировать, насколько далеко мы шагаем в сторону антиградиента. Дело в том, что оказывается оптимальным шагать не очень сильно, мы увидим с вами это чуть дальше. Эти градиентные шаги повторяются до тех пор, пока не наступит сходимость. Сходимость можно определять по-разному. В нашем случае мы ее определяем как ситуацию, в которой векторы весов от шага к шагу начали меняться не слишком сильно. То есть норма отклонения вектора весов на текущем шаге от вектора весов на предыдущем шаге, должна отличаться не более, чем на ε. В этом случае мы завершаем градиентный спуск. Если же изменение довольно большое, мы продолжаем его. Есть и другие подходы к определению сходимости. Например, можно сравнивать значение функционала ошибки между текущей итерацией и предыдущей, или использовать еще какие-то способы. Итак, мы с вами обсудили, как в матричном виде записать среднеквадратичный функционал ошибки для линейной регрессии, и выяснили, что у него есть аналитическое решение, которое тем не менее обладает рядом проблем, его довольно тяжело вычислить. Поэтому гораздо проще использовать градиентный спуск. Мы с вами обсудили, как он устроен и почему в нем шаг делается именно в сторону антиградиента. В следующем видео мы посмотрим, как выглядит применение градиентного спуска конкретно для задачи линейной регрессии.

В этом видео мы поговорим о том, как применять градиентный спуск для обучения линейной регрессии. И давайте начнем с простого примера, со случая, когда признак всего один. Эта ситуация называется парной регрессией. В этом случае линейная модель выглядит как a от х равняется w 1 умножить на x плюс w 0. То есть мы берем значение нашего единственного признака x, умножаем на некоторый вес, некоторый коэффициент w 1, и прибавляем свободный коэффициент w 0, который также называется сдвигом. Получается, что у нашей модели есть два параметра: w 1 и w 0. Их нужно настраивать. Функционал ошибки возьмем среднеквадратичный, то есть посчитаем квадраты отклонения прогноза модели от истинного ответа и усредним по всем объектам. Давайте рассмотрим, как будет работать в случае с парной регрессией градиентный спуск на примере конкретной выборки. Например, это может быть задача предсказания прибыли магазина в следующем месяце на основе его прибыли в предыдущем месяце. Выборка выглядит вот так. По оси x отложено значение единственного признака, по оси y отложено значение ответа. Если нарисовать функционал качества в осях w 0 и w 1, он будет выглядеть как-то так. То есть это некоторая функция параболического вида, у нее где-то есть минимум. Напомню, градиентный спуск заключается в том, что мы как-то инициализируем вектор весов и дальше до сходимости повторяем градиентный шаг. То есть вычитаем из текущего приближения вектора весов градиент функционала ошибки в этой точке с некоторым коэффициентом в этой точке [INAUDIBLE]. Сходимость наступает, когда вектор весов перестает меняться слишком сильно от одной итерации к другой. Чтобы запустить градиентный спуск, нам нужно вычислить градиент, то есть вектор частных производных функционала ошибки по всем его параметрам. У нас параметра два, w 1 и w 0. Мы не будем вдаваться в математические выкладки, можно показать, что частные производные записываются вот так. Можете проверить дома, что это действительно правда. Итак, чтобы посмотреть, как работает градиентный спуск на нашей выборке, будем рисовать две картинки. На левой картинке мы изображаем пространство параметров. По оси x отложен параметр w 0, по оси y параметр — w 1. Точка в этом пространстве обозначает конкретную модель. Выбирая конкретные места, мы получаем конкретную линейную регрессию. На правом графике мы изображаем нашу выборку в осях «признак — ответ» и алгоритм, который настроен, который соответствует точке на левом графике. Итак, если мы возьмем начальное приближение случайно, возьмем в его качестве некоторую точку в окрестности нуля, то получим некоторый не очень хороший алгоритм. Он совершенно не соответствует тому, какая зависимость есть в нашей выборке. Сделаем первый градиентный шаг. Он сдвинется вверх и немножко вправо, и мы видим, что после даже первого градиентного шага алгоритм гораздо больше соответствует истинной зависимости. Направление нашей прямой уже более или менее угадывает общую тенденцию в данных. Сделаем еще несколько градиентных шагов. Наша точка в пространстве параметра будет двигаться в том же направлении, а наша прямая, наш алгоритм, будет все ближе и ближе к нашему облаку точек, к нашему облаку объектов. После того, как мы сделаем 100 итераций, наша точка в пространстве параметров немножко завернет, а сам алгоритм будет уже очень неплохо апроксимировать, неплохо приближать данные. Видно, что модель после сотой итерации уже довольно неплохая. После того, как мы сделаем тысячу итераций, точка в пространстве параметров, то есть набор параметров, сдвинется еще сильнее в том же направлении и алгоритм станет еще лучше описывать данные. После двух тысяч итераций мало что изменится. Видно, что уже наступила сходимость, и мы получили довольно неплохой алгоритм, который соответствует зависимости между признаком и ответом. При этом, если посмотреть на график того, как менялось значение функционала ошибки по мере итерации, мы увидим, что это изменение было монотонным, начиналось оно в довольно высокой точки, затем уменьшалось, и в какой-то момент вышло на асимптоту. Очень важно в градиентном спуске понимать, как выбрать размер шага [INAUDIBLE]. Давайте немножко поговорим об этом. Вообще, нет никаких конкретных правил, конкретных рекомендаций, каким именно выбрать шаг для данной задачи. Выбор шага это искусство, но при этом есть некоторые соображения, которые могут помочь. Если взять длину шага слишком маленькой, то градиентный спуск будет очень не спеша, но верно шагать в сторону минимума, как на этой картинке. Видно, что шаги по мере приближения к минимуму становятся все более и более маленькими, нужно довольно много итераций, чтобы градиентный спуск сошелся с таким размером шага. Если же взять размер шага очень большим, то, конечно, градиент будет показывать в сторону минимума, но поскольку мы шагаем по нему слишком далеко, есть риск, что мы будем перепрыгивать точку минимума, и, более того, есть риск расхождения, то есть градиентный спуск будет уходить все дальше и дальше от точки минимума, что и происходит на этой картинке. Можно заметить, что если мы еще находимся очень далеко от точки минимума, то нет ничего плохого в том, чтобы делать длинные шаги, чтобы далеко шагать в сторону антиградиента. Если же мы уже сделали много итераций градиентного спуска и есть подозрения, что находимся близко к точке минимума, то шаги должны быть аккуратными, чтобы мы не перескочили минимум, чтобы мы не начали шагать не в ту сторону. Таким образом, возникает идея делать шаг переменным. Чем больше итераций мы сделали, тем меньше должен быть размер шага. Например, можно в этом случае для размера шага [INAUDIBLE] взять формулу k поделить на t, где t это номер текущей итерации, а k — некоторая константа. видно, что чем больше число итераций, тем меньше будет шаг, а константу k нужно как-то подбирать в зависимости от задачи, например, пробовать разные значения и посмотреть, когда сходимость есть, а когда нет. В случае с многомерной линейной регрессией подход будет тот же самый, нужно только по-другому расчитать градиент. Функционал в случае с многомерной линейной регрессией, как мы уже выяснили, записывается в матричном виде. Это будет норма, квадрат нормы отклонения вектора X w, то есть вектора прогнозов, от вектора y, то есть вектора истинных ответов. И потом еще это делится на l, на размер выборки. Нужно минимизировать этот функционал ошибки. Можно показать, что градиент этого функционала в точке w вычисляется по вот такой формуле. Нужно взять матрицу X, то есть матрицу «объекты — признаки», транспонировать ее, умножить на вектор отклонений X w — y, то есть на вектор ошибок алгоритма на каждом объекте обучения, и потом умножить все это на скаляр 2 поделить на l. Именно вдоль этого вектора нужно шагать на каждом шаге градиентного спуска. Итак, мы с вами обсудили, как будет выглядеть градиентный спуск для парной, то есть одномерной, и многомерной линейной регрессии, обсудили важность выбора шага. А в следующем видео мы поговорим о модификации градиентного спуска, стохастическом градиентном спуске, который хорошо подходит для настройки линейной регрессии.

В этом видео мы поговорим о стохастическом градиентном спуске, который особенно хорошо подходит для обучения линейных моделей. Итак, мы уже знаем, как работает обычный градиентный спуск. Мы начинаем с некоторой инициализации вектора весов, например, нулями или другими значениями, и дальше повторяем в цикле градиентные шаги. Градиентный шаг состоит в том, что мы вычитаем из текущего приближения вектора весов w (t − 1) вектор градиента, с некоторым коэффициентом ηt. Повторяя эти шаги до тех пор, пока не наступит сходимость, то есть пока вектор весов не начнет меняться слишком слабо. Давайте внимательнее посмотрим на то, как устроен градиентный шаг. Вектор градиента в векторной форме выглядит вот так. Если расписать j-ю компоненту этого вектора, то получим следующую формулу. В ней стоит суммирование по всем объектам обучающей выборки, по i от 1 до l, где мы суммируем следующие слагаемые, которые, по сути, показывают, как надо изменить j-й вес, чтобы как можно сильнее улучшить качество на объекте xi. А вся сумма показывает, как нужно изменить j-й вес, чтобы улучшить качество на всей обучающей выборке. Собственно, в этой формуле и состоит один из главных недостатков градиентного спуска. Здесь стоит суммирование по всей обучающей выборке. Если выборка большая, то один градиентный шаг будет занимать слишком много времени. Так мы приходим к модификации градиентного спуска, который называется стохастическим градиентным спуском. Его главная особенность в том, что на одной итерации мы вычитаем не вектор градиента, вычисленный по всей выборке, а делаем следующее. Мы случайно выбираем один объект из обучающей выборки, например, xi, и дальше вычисляем градиент функционала только на этом объекте, то есть градиент только одного слагаемого в функционале ошибки, и вычитаем именно этот градиент из текущего приближения вектора весов. Очень показательно посмотреть на график сходимости для градиентного спуска и стохастического градиентного спуска. В градиентном спуске мы стараемся на каждую итерацию уменьшить ошибку на всей выборке, и поэтому график получается гладким. По мере увеличения числа итераций ошибка уменьшается монотонно, поскольку мы уменьшаем ее на всей выборке. В случае же со стохастическим градиентным спуском, мы уменьшаем на каждую итерацию ошибку только на одном объекте, но при этом мы можем увеличить ее на другом объекте, поэтому график получается пилообразный. Мы на какой-то итерации можем увеличивать ошибку, но при этом в целом он уменьшается. И рано или поздно мы выходим на довольно неплохое качество, на довольно низкую ошибку. Итак, у стохастического градиентного спуска есть много преимуществ. Во-первых, в нем гораздо быстрее вычисляется один шаг, один градиентный шаг. Так же ему не требуется хранение всей обучающей выборки в памяти. Мы можем считывать по одному объекту из выборки и для каждого следующего объекта делать градиентный шаг. За счет этого стохастический градиентный спуск позволяет обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. Так же он подходит для онлайн обучения, ситуации, в которой мы получаем за каждый шаг только один объект, и должны как-то изменить модель, чтобы учесть этот объект. Итак, мы обсудили, что градиентный спуск требует суммирование по всем объектам обучающей выборки на каждой итерации, что может быть проблемой, если выборка большая. Стохастический градиентный спуск решает эту проблему, используя лишь один объект обучающей выборки на каждой своей итерации. При этом он имеет много преимуществ и позволяет, например, обучать линейные модели на очень больших выборках, которые не помещаются в память компьютера. В следующем видео мы поговорим о том, как применять линейные модели в задачах классификации.

В этом видео мы поговорим про линейную классификацию: то есть как применять линейные модели к задачам классификации. И будем говорить о самом простом виде классификации — бинарной классификации, где ответы принимают значения из множества −1 и +1, то есть всего 2 возможных значения. Как вы помните, чтобы работать с той или иной моделью, нужно уметь отвечать на 3 вопроса: первый — это как мы измеряем качество, как устроен функционал ошибки; второй — как устроено семейство алгоритмов, то есть то множество алгоритмов, из которого мы выбираем наилучший с точки зрения функционала; и третий — это как мы обучаем алгоритм, то есть выбираем лучший из семейства с точки зрения функционала ошибки. В этом видео мы поговорим о семействе алгоритмов, а в следующем — о том, как измерять их ошибки и как обучать эти алгоритмы. Мы уже говорили про линейную регрессию. Линейные классификаторы устроены очень похоже. В линейной регрессии мы складывали все признаки с весами, при этом вес при j-том признаке обозначали как wj-тое, и после этого суммирования проявляли еще свободный коэффициент w0, который также называется сдвигом. В случае с регрессией нас эта формула полностью устраивала, поскольку она принимала вещественные значения, теперь же алгоритм должен возвращать бинарные значения: −1 или +1. Чтобы добиться этого, можно просто взять знак от этого выражения, именно это и будет видом линейного классификатора. Заметим, что формула не очень однородная, в ней есть свободный коэффициент, чтобы убрать его, давайте просто добавим еще один признак выборки, константный признак, который на каждом объекте принимает значение 1, единичный признак. В этом случае свободный коэффициент уже не нужен, его роль будет выполнять вес при этом константном признаке, и формула приобретает такое значение. Заметим, что по сути такая взвешенная сумма признаков — это скалярное произведение вектора весов на вектор признаков, и значит итоговый вид линейного классификатора — это знак скалярного произведения w на x, этой формулой мы и будем пользоваться дальше. Давайте разберемся, какой геометрический смысл у линейного классификатора. В случае с линейной регрессией мы обсуждали, что это по сути приближение зависимости ответа от признаков с помощью прямой или гиперплоскости. Что же это будет в случае с классификацией? Для этого давайте запишем то, что стоит под функцией знака — скалярное произведение w на x, и приравняем к 0, получим такое уравнение. Давайте нарисуем вектор весов w и будем искать все такие точки x, которые удовлетворяют этому уравнению, то есть все такие точки, для которых скалярное произведение этой точки, этого вектора на w = 0. Равенство нулю скалярного произведения означает, что угол между этими векторами = 90 градусов, то есть что они перпендикулярны. Получается, что точки, удовлетворяющие этому уравнению — это все векторы, ортогональные вектору весов. Из аналитической геометрии известно, что это множество представляет собой плоскость. Получается, что уравнение задает плоскость, более того, с одной стороны от этой плоскости значение скалярного произведения будет больше 0, а с другой стороны от плоскости — меньше 0. Получается, что линейный классификатор проводит гиперплоскость в пространстве признаков, и все объекты, которые с одной стороны, относят к классу +1, а те, которые с другой стороны — к классу −1. В случае с двумя признаками это выглядит как-то так: у нас есть выборка, мы проводим разделяющую прямую, и все объекты, которые с одной стороны, относим к классу −1, все, которые с другой стороны, относим к классу +1. Заметим, что линейные классификаторы вычисляют значение скалярного произведения, которое имеет вещественное значение, а затем берет только знак, отбрасывая часть информации. При этом, наверное, само значение скалярного произведения тоже имеет смысл. Действительно, оказывается, что если мы возьмем модуль этого скалярного произведения и отнормируем его, то есть поделим на норму вектора весов, то это выражение будет равно расстоянию от точки x до гиперплоскости, которая задается вектором нормали, вектором весов w. Получается, что линейный классификатор сначала измеряет расстояние от точки до гиперплоскости со знаком и дальше смотрит лишь на знак, то есть на то, с какой стороны от гиперплоскости лежит эта точка. Так мы приходим к очень важному понятию в линейной классификации — к понятию отступа. Отступом называется выражение вида: скалярное произведение вектора весов на объект, умноженное на истинный ответ на этом объекте, который, напомню, равен +1 и −1. Какой смысл у этого выражения? Давайте обратим внимание: если скалярное произведение имеет положительный знак и истинный ответ равен +1 — это верная классификация и произведение скалярного произведения на истинный ответ будет больше 0. Если скалярное произведение меньше 0, и истинный ответ равен −1, то это тоже будет правильная классификация, и их произведение снова будет больше 0. Если же знак ответа и знак скалярного произведения противоположные, то классификация будет ошибочной и знак отступа будет меньше 0. Получается, что отступ — это некоторая величина, которая характеризует корректность ответа. Если отступ больше 0, то алгоритм дает корректный ответ, если отступ меньше 0 — алгоритм дает некорректный ответ. При этом само абсолютное значение отступа свидетельствует о расстоянии от точки до разделяющей гиперплоскости. Принято считать, что если точка находится рядом с разделяющей гиперплоскостью, то классификация неуверенная, наш алгоритм сомневается, к какому классу относить ее, если же точка находится далеко от разделяющей гиперплоскости, то классификация уверенная, при этом, если алгоритм прав, то он просто уверен в этом, все хорошо, если же алгоритм ошибается, и при этом отступ по модулю очень большой, это означает, что алгоритм очень сильно ошибается в классификации этого объекта, возможно, этот объект является выбросом и никак не вписывается в нашу модель, или же алгоритм не подходит для решения этой задачи. Итак, мы с вами обсудили, что линейный классификатор по сути строит гиперплоскость в пространстве признаков и с ее помощью разделяет 2 класса. Также мы ввели понятие отступа, знак которого позволяет понять — корректный ответ дает классификатор или нет на этом объекте, а абсолютное значение отступа говорит об уверенности классификатора в этом объекте. В следующем видео мы поговорим о том, как измерять качества, как измерять ошибку линейного классификатора и как его настраивать.

В этом видео мы поговорим о том, как измерять ошибку в задачах классификации и как обучать линейные классификаторы. В прошлый раз мы выяснили, что в задачах бинарной классификации линейный классификатор строит гиперплоскость, которая пытается разделить два класса. При этом те объекты, которые оказываются слева от нее, она относит к одному классу, а те, которые справа от нее, — к другому классу. В случае с регрессией измерить качество было довольно просто. Прогноз и ответ — это вещественные числа. Их бесконечно много, и мы требовали, чтобы они были как можно ближе друг к другу. При этом есть много способов измерить сходство двух вещественных чисел. Это квадратичное отклонение или абсолютное отклонение. Можно придумать и другие подходы к измерению сходства чисел. В случае с классификацией возникает вполне естественный подход. У нас ответов конечное число. Соответственно, можем требовать точного совпадения класса, предсказанного алгоритмом A(Xi), и истинного класса Yi. Соответственно, функционал, который мы получаем, — это доля неправильных ответов, доля ошибочных ответов. Он записывается вот так. Это сумма индикаторов того, что предсказанный класс A(Xi) не совпал с истинным классом Yi. И все это усредняется по всей обучающей выборке. Давайте вспомним, что в прошлый раз мы изучали понятие отступа, который позволяет понять, ошибается или нет алгоритм на данном объекте. Отступ на этом объекте задается как произведение истинного ответа Yi на скалярное произведение вектора весов W на вектор признаков Xi. Если отступ меньше нуля, то алгоритм ошибается на данном объекте. Соответственно, наш функционал долю неправильных ответов можно переписать, как среднее значение индикатора того, что отступ на (i) объекте меньше нуля. Давайте посмотрим, как выглядит функция, которая стоит под знаком суммы. Индикатор того, что отступ меньше нуля. По оси "Икс" отложим отступ Mi, отступ на этом объекте, по оси "Игрек" — значение функции потерь, значение индикатора. Мы видим, что эта функция пороговая. Она равна единице, если отступ меньше нуля, и нулю, если отступ больше нуля. Эта функция является разрывной, у нее разрыв в нуле. Из-за этого ее нельзя оптимизировать градиентными методами. Конечно, можно воспользоваться методами негладкой оптимизации, которые мы изучали в прошлом курсе, но они довольно сложные в реализации и не дают гарантии сходимости к локальному оптимуму. Поэтому давайте попробуем как-то изменить задачу, чтобы она стала гладкой. Для этого возьмем индикатор того, что отступ меньше нуля, нашу пороговую функцию потерь. Оценим сверху этот индикатор некоторой гладкой функцией "L с волной", которая также зависит от отступа M. То есть это должна быть такая функция, которая больше или равна единице, если отступ отрицательный, и больше или равна нуля, если отступ положительный. Далее, используя данную верхнюю оценку "L с волной", мы можем оценить весь функционал ошибки, весь функционал доли неверных ответов. Верхняя оценка на этот функционал будет выглядеть так: это среднее значение нашей гладкой функции потерь "L с волной" по всей обучающей выборке. Обратите внимание: в этом случае мы будем минимизировать не долю неправильных ответов, а среднее значение нашей гладкой функции потерь "L с волной". При этом мы надеемся, что если мы приведем к нулю данное среднее значение гладкой функции, то при этом прижмется к нулю и то, что она оценивает сверху, прижмется к нулю доля неправильных ответов. Но при этом, конечно же, нет никаких гарантий, что, минимизируя верхнюю оценку, мы будем точно минимизировать и то, что она оценивает, то есть долю неправильных ответов. Но при этом мы получаем очень удобную, хорошую гладкую задачу минимизации. Давайте рассмотрим несколько примеров таких гладких оценок. Например, это может быть логистическая функция потерь L(M), которая записывается как логарифм, под которым стоит единица плюс экспонента от минус отступа. Она используется в логистической регрессии, которую вы будете изучать позже в нашем курсе. Другие примеры — это экспоненциальная функция потерь или кусочно-линейная, которые используются в методе опорных векторов. Вот графики этих функций. Видно, что они все, действительно, оценивают сверху пороговую функцию потерь. При этом все они делают это по-разному. Какие-то имеют экспоненциальный рост, какие-то более медленный темп роста при уменьшении отступа. Давайте возьмем для примера логистическую функцию потерь и запишем функционал для нее. Он будет выглядеть вот так. Мы усредняем значение данной функции. Этот функционал будет гладким. Чтобы понять, как его оптимизировать, давайте поставим вместо отступа его определение. То есть Yi истинный ответ, умноженный на скалярное произведение вектора весов на вектор признаков Xi. Видно, что мы получили гладкий, хороший функционал, у которого легко посчитать градиенты по вектору весов W и осуществлять градиентный спуск или пользоваться любым другим вашим любимым методом оптимизации. Итак, что мы делаем при решении задачи классификации, при обучении линейного классификатора? Мы оцениваем сверху долю неправильных ответов, наш базовый функционал ошибки, с помощью некоторой гладкой функции потерь, например, логистической. И далее минимизируем эту гладкую функцию потерь с помощью любого метода оптимизации — стохастического градиентного спуска, градиентного спуска или чего-то еще. И при этом надеемся, что минимизации данного функционала будет также приводить к минимизации доли неправильных ответов. Кстати, обратите внимание: в случае с логистической функцией потерь, даже если все отступы стали больше нуля, все равно алгоритм градиентной оптимизации будет стремиться увеличивать отступы, то есть увеличивать уверенность классификатора в этих ответах. Это довольно хорошее свойство. Итак, мы с вами выяснили, что в задачах классификации есть вполне логичный функционал потерь — доля ошибок, при этом он негладкий, и нужно его оценивать сверху. И далее классификатор настраивается путем минимизации гладкой аппроксимации функционала ошибки. На этом наш урок про линейные методы заканчивается, и заканчивается первый модуль курса. А следующий модуль мы начнем с того, что обсудим проблему переобучения и методы борьбы с ней.

Линейные модели
2.1. Линейные модели в задачах регрессии
Данный урок будет посвящен линейным моделям. Речь пойдет о задачах классификации и регрессии, как
их обучать, и с какими проблемами можно столкнуться при использовании этих моделей. В этом блоке мы
обсудим, как выглядят линейные модели в задачах регрессии.
2.1.1. Повторение обозначений из прошлого урока
Для начала необходимо напомнить некоторые обозначения, которые были введены на прошлом уроке.
• X — пространство объектов
• Y — пространство ответов
• x = (x
1
, ..., xd
) — признаковое описание объекта
• X = (xi
, yi)
`
i=1 — обучающая выборка
• a(x) — алгоритм, модель
• Q(a, X) — функционал ошибки алгоритма a на выборке X
• Обучение: a(x) = argmina∈A Q(a, X)
Напомним, что в задаче регрессии пространство ответов Y = R. Чтобы научиться решать задачу регрессии,
необходимо задать:
• Функционал ошибки Q: способ измерения того, хорошо или плохо работает алгоритм на конкретной
выборке.
• Семейство алгоритмов A: как выглядит множество алгоритмов, из которых выбирается лучший.
• Метод обучения: как именно выбирается лучший алгоритм из семейства алгоритмов.
2.1.2. Пример задачи регрессии: предсказание прибыли магазина
Пусть известен один признак — прибыль магазина в прошлом месяце, а предсказать необходимо прибыль
магазина в следующем. Поскольку прибыль — вещественная переменная, здесь идет речь о задаче регрессии.
Прибыль в прошлом месяце
Прибыль в текущем месяце
Рис. 2.1: Точки обучающей выборки.
1
По этому графику можно сделать вывод о существовании зависимости между прибылью в следующем и
прошлом месяцах. Если предположить, что зависимость приблизительно линейная, ее можно представить в
виде прямой на этом графике. По этой прямой и можно будет предсказывать прибыль в следующем месяце,
если известна прибыль в прошлом.
В целом такая модель угадывает тенденцию, то есть описывает зависимость между ответом и признаком.
При этом, разумеется, она делает это не идеально, с некоторой ошибкой. Истинный ответ на каждом объекте
несколько отклоняется от прогноза.
Один признак — это не очень серьезно. Гораздо сложнее и интереснее работать с многомерными выборками, которые описываются большим количеством признаков. В этом случае нарисовать выборку и понять,
подходит или нет линейная модель, нельзя. Можно лишь оценить ее качество и по нему уже понять, подходит
ли эта модель.
Следует отметить, что вообще нельзя придумать модель, которая идеально описывает ваши данные, то
есть идеально описывает, как порождается ответ по признакам.
2.1.3. Описание линейной модели
Далее обсудим, как выглядит семейство алгоритмов в случае с линейными моделями. Линейный алгоритм в
задачах регрессии выглядит следующим образом:
a(x) = w0 +
X
d
j=1
wjx
j
,
где w0 — свободный коэффициент, x
j — признаки, а wj — их веса.
Если добавить (d + 1)-й признак, который на каждом объекте принимает значение 1, линейный алгоритм
можно будет записать в более компактной форме
a(x) = X
d+1
j=1
wjx
j = hw, xi,
где используется обозначение hw, xi для скалярного произведения двух векторов.
В качестве меры ошибки не может быть выбрано отклонение от прогноза Q(a, y) = a(x) − y, так как в
этом случае минимум функционала не будет достигаться при правильном ответе a(x) = y. Самый простой
способ — считать модуль отклонения:
|a(x) − y|.
Но функция модуля не является гладкой функцией, и для оптимизации такого функционала неудобно использовать градиентные методы. Поэтому в качестве меры ошибки часто выбирается квадрат отклонения:
(a(x) − y)
2
.
Функционал ошибки, именуемый среднеквадратичной ошибкой алгоритма, задается следующим образом:
Q(a, x) = 1
`
X
`
i=1
(a(xi) − yi)
2
В случае линейной модели его можно переписать в виде функции (поскольку теперь Q зависит от вектора, а
не от функции) ошибок:
Q(w, x) = 1
`
X
`
i=1
(hw, xii − yi)
2
.
2.2. Обучение модели линейной регрессии
В этом блоке речь пойдет о том, как обучать модель линейной регрессии, то есть как настраивать ее параметры. В прошлый раз было введено следующее выражение для качества линейной модели на обучающей
выборке:
Q(w, x) = 1
`
X
`
i=1
(hw, xii − yi)
2 → min
w
.
Следует напомнить, что в число признаков входит также постоянный признак, равный 1 для всех объектов,
что позволяет исключить постоянную составляющую в последнем соотношении.
2
2.2.1. Переход к матричной форме записи
Прежде, чем будет рассмотрена задача оптимизации этой функции, имеет смысл переписать используемые
соотношения в матричной форме. Матрица «объекты–признаки» X составлена из признаковых описаний всех
объектов из обучающей выборки:
X =


x11 ... x1d
... ... ...
x`1 ... x`d


Таким образом, в ij элементе матрицы X записано значение j-го признака на i объекте обучающей выборки.
Также понадобится вектор ответов y, который составлен из истинных ответов для всех объектов:
y =


y1
...
y`

 .
В этом случае среднеквадратичная ошибка может быть переписана в матричном виде:
Q(w, X) = 1
`
kXw − yk
2 → min
w
.
Эта формула пригодится, в частности, при реализации линейной регрессии на компьютере.
2.2.2. Аналитический метод решения
Можно найти аналитическое решение задачи минимизации:
w∗ = (XT X)
−1XT
y.
Основные сложности при нахождении решения таким способом:
• Для нахождения решения необходимо вычислять обратную матрицу. Операция обращения матрицы
требует, в случае d признаков, выполнение порядка d
3 операции, и является вычислительно сложной
уже в задачах с десятком признаков.
• Численный способ нахождения обратной матрицы не может быть применен в некоторых случаях (когда
матрица плохо обусловлена).
2.2.3. Оптимизационный подход к решению
Другой, несколько более удобный, способ найти решение — использовать численные методы оптимизации.
Несложно показать, что среднеквадратическая ошибка — это выпуклая и гладкая функция. Выпуклость
гарантирует существование лишь одного минимума, а гладкость — существование вектора градиента в каждой
точке. Это позволяет использовать метод градиентного спуска.
При использовании метода градиентного спуска необходимо указать начальное приближение. Есть много
подходов к тому, как это сделать, в том числе инициализировать случайными числами (не очень большими).
Самый простой способ это сделать — инициализировать значения всех весов равными нулю:
w
0 = 0.
На каждой следующей итерации, t = 1, 2, 3, ..., из приближения, полученного в предыдущей итерации w
t−1
,
вычитается вектор градиента в соответствующей точке w
t−1
, умноженный на некоторый коэффициент ηt,
называемый шагом:
w
t = w
t−1 − ηt∇Q(w
t−1
, X).
Остановить итерации следует, когда наступает сходимость. Сходимость можно определять по-разному. В данном случае разумно определить сходимость следующим образом: итерации следует завершить, если разница
двух последовательных приближений не слишком велика:
kw
t − w
t−1
k < ε.
Подробно метод градиентного спуска обсуждался в прошлом курсе этой специализации.
3
2.3. Градиентный спуск для линейной регрессии
2.3.1. Случай парной регрессии
В случае парной регрессии признак всего один, а линейная модель выглядит следующим образом:
a(x) = w1x + w0,
где w1 и w0 — два параметра.
Среднеквадратичная ошибка принимает вид:
Q(w0, w1, X) = 1
`
X
`
i=1
(w1xi + w0 − yi)
2
.
Для нахождения оптимальных параметров будет применяться метод градиентного спуска, про который уже
было сказано ранее. Чтобы это сделать, необходимо сначала вычислить частные производные функции ошибки:
∂Q
∂w1
=
2
`
X
`
i=1
(w1xi + w0 − yi)xi
,
∂Q
∂w0
=
2
`
X
`
i=1
(w1xi + w0 − yi).
2.3.2. Демонстрация градиентного спуска в случае парной регрессии
Следующие два графика демонстрируют применение метода градиентного спуска в случае парной регрессии. Справа изображены точки выборки, а слева — пространство параметров. Точка в этом пространстве
обозначает конретную модель.
Рис. 2.2: Демонстрация метода градиентного спуска.
4
График зависимости функции ошибки от числа произведенных операции выглядит следующим образом:
0 20 40 60 80 100
0
50
100
150
200
250
300
номер итерации
ошибки
Рис. 2.3: Ошибка в зависимости от номера итерации
2.3.3. Выбор размера шага в методе градиентного спуска
Очень важно при использовании метода градиентного спуска правильно подбирать шаг. Каких-либо конкретных правил подбора шага не существует, выбор шага — это искусство, но существует несколько полезных
закономерностей.
w1
w2
w3
w4
w5
w1
w3
w5
w7
w2
w4
w6
Рис. 2.4: Случаи маленького и большого шага
Если длина шага слишком мала, то метод будет неспеша, но верно шагать в сторону минимума. Если же
взять размер шага очень большим, появляется риск, что метод будет перепрыгивать через минимум. Более
того, есть риск того, что градиентный спуск не сойдется.
Имеет смысл использовать переменный размер шага: сначала, когда точка минимума находится еще далеко, двигаться быстро, а позже, спустя некоторое количество итерации — делать более аккуратные шаги.
Один из способов задать размер шага следующий:
ηt =
k
t
,
где k — константа, которую необходимо подобрать, а t — номер шага.
2.3.4. Случай многомерной линейной регрессии
В случае многомерной линейной регрессии используется тот же самый подход — необходимо решать задачу
минимизации:
Q(w, X) = 1
`
kXw − yk
2 → min
w
,
где kxk — норма вектора x. Формула для вычисления градиента принимает следующий вид:
∇wQ(w, X) = 2
`
XT
(Xw − y)
5
Стоит отметить, что вектор Xw − y, который присутствует в данном выражении, представляет собой вектор
ошибок.
2.4. Стохастический градиентный спуск
В этом блоке речь пойдет о стохастическом градиентном спуске, который особенно хорошо подходит для
обучения линейных моделей.
2.4.1. Недостатки обычного метода градиентного спуска
В обычном методе градиентного спуска на каждом шаге итерации следующее приближение получается из
предыдущего вычитанием вектора градиента, умноженного на шаг ηt:
w
t = w
t−1 − ηt∇Q(w
t−1
, X).
При этом выражение для градиента в матричной форме имеет вид:
∇wQ(w, X) = 2
`
XT
(Xw − y)
Выражение для j-ой компоненты градиента, таким образом, содержит суммирование по всем объектам обучающей выборки:
∂Q
∂wj
=
2
`
X
`
i=1
x
j
i
(hw, xii − yi).
В этом и состоит основной недостаток метода градиентного спуска — в случае большой выборки даже одна
итерация метода градиентного спуска будет производиться долго.
2.4.2. Стохастический градиентный спуск
Идея стохастического градиентного спуска основана на том, что в сумме в выражении для j-компоненты
градиента i-ое слагаемое указывает то, как нужно поменять вес wj , чтобы качество увеличилось для i-го
объекта выборки. Вся сумма при этом задает, как нужно изменить этот вес, чтобы повысить качество для всех
объектов выборки. В стохастическом методе градиентного спуска градиент функции качества вычисляется
только на одном случайно выбранном объекте обучающей выборки. Это позволяет обойти вышеупомянутый
недостаток обычного градиентного спуска.
Таким образом, алгоритм стохастического градиентного спуска следующий. Сначала выбирается начальное приближение:
w
0 = 0
Далее последовательно вычисляются итерации w
t
: сначала случайным образом выбирается объект xi из
обучающей выборки X и вычисляется вектор градиента функции качества на этом объекте, а следующее
приближение получается из предыдущего вычитанием умноженного на шаг ηt полученного вектора:
w
t = w
t−1 − ηt∇Q(w
t−1
, {xi}).
Итерации прекращаются при достижении определенного условия, например:
kw
t − w
t−1
k < ε.
2.4.3. Сходимость стохастического градиентного спуска
Показательно посмотреть на графики сходимости градиентного спуска и стохастического градиентного спуска. В обычном градиентном спуске на каждом шаге уменьшается суммарная ошибка на всех элементах обучающей выборки. График в таком случае обычно получается монотонным.
6
0 20 40 60 80 100
0
50
100
150
200
250
300
номер итерации
ошибки
Рис. 2.5: Ошибка в зависимости от номера итерации
Напротив, в стохастическом методе весовые коэффициенты меняются таким образом, чтобы максимально
уменьшить ошибку для одного случайно выбранного объекта. Это приводит к тому, что график выглядит
пилообразным, то есть на каждой конкретной итерации полная ошибка может как увеличиваться, так и
уменьшаться. Но в итоге с ростом номера итерации значение функции уменьшается.
2.4.4. Особенности стохастического градиентного спуска
Стохастический градиентный спуск (SGD) обладает целым рядом преймуществ. Во-первых, каждый шаг выполняется существенно быстрее шага обычного градиентного метода, а также не требуется постоянно хранить
всю обучающую выборку в памяти. Это позволяет использовать для обучения выборки настолько большие,
что они не помещаются в память компьютера. Стохастический градиентный спуск также можно использовать
для онлайн-обучения, то есть в ситуации, когда на каждом шаге алгоритм получает только один объект и
должен учесть его для коррекции модели.
2.5. Линейная классификация
2.5.1. Задача бинарной классификации
В этом разделе рассматривается задача линейной классификации, то есть применение линейных моделей к
задаче классификации. Речь пойдет о самом простом виде классификации — бинарной классификации. В
случае бинарной классификации множество возможных значений ответов состоит из двух элементов:
Y = {−1, +1}.
Как уже было сказано, чтобы работать с той или иной моделью нужно:
• Выбрать функционал (функцию) ошибки, то есть задать способ определения качества работы того или
иного алгоритма на обучающей выборке.
• Построить семейство алгоритмов, то есть множество алгоритмов, из которого потом будет выбираться
наилучший с точки зрения определенного функционала ошибки.
• Ввести метод обучения, то есть определить способ выбора лучшего алгоритма из семейства.
2.5.2. Линейный классификатор
Ранее была рассмотрена задача линейной регрессии. В этом случае алгоритм представлял собой линейную
комбинацию признаков с некоторыми весами и свободным коэффициентом.
Линейные классификаторы устроены похожим образом, но они должны возвращать бинарные значения,
а следовательно требуется также брать знак от получившегося выражения:
a(x) = sign

w0 +
X
d
j=1
wjx
j

 .
7
Как и раньше, добавлением еще одного постоянного для всех объектов признака можно привести формулу к
более однородному виду:
a(x) = signX
d+1
j=1
wjx
j = signhw, xi
2.5.3. Геометрический смысл линейного классификатора
Выражение hw, xi = 0 является уравнением некоторой плоскости в пространстве признаков.
y
z
x
~w
Рис. 2.6: Геометрический смысл линейного классификатора
При этом для точек по одну сторону от этой плоскости скалярное произведение hw, xi будет положительным, а с другой — отрицательным.
Таким образом, линейный классификатор проводит плоскость в пространстве признаков и относит объекты по разные стороны от нее к разным классам.
Согласно геометрическому смыслу скалярного произведения, расстояние от конкретного объекта, который
имеет признаковое описание x, до гиперплоскости hw, xi = 0 равно
|hw,xi|
kwk
. С этим связано такое важное
понятие в задачах линейной классификации как понятие отступа:
Mi = yihw, xii.
Отступ является величиной, определяющей корректность ответа. Если оступ больше нуля Mi > 0, то классификатор дает верный ответ для i-го объекта, в ином случае — ошибается.
Причем чем дальше отступ от нуля, тем больше уверенность как в правильном ответе, так и в том,
что алгоритм ошибается. Если отступ для некоторого объекта отрицательный и большой по модулю, это
значит, что алгоритм неправильно описывает данные: либо этот объект является выбросом, либо алгоритм
не пригоден для решения данной задачи.
2.6. Функции потерь в задачах классификации
2.6.1. Пороговая функция потерь
В случае линейной классификации естественный способ определить качество того или иного алгоритма —
вычислить для объектов обучающей выборки долю неправильных ответов:
Q(a, x) = 1
`
X
`
i=1
[a(xi) 6= yi
]
8
С помощью введенного ранее понятия отступа можно переписать это выражение для случая линейной классификации в следующем виде:
Q(a, x) = 1
`
X
`
i=1

yihw, xii < 0

=
1
`
X
`
i=1

Mi < 0

Функция, стоящая под знаком суммы, называется функцией потерь. В данном случае это пороговая функция
потерь, график которой в зависимости от отступа выглядит следующим образом:
Mi
0
1
Рис. 2.7: График пороговой функции потерь
Такая функция является разрывной в точке 0, что делает невозможным применение метода градиентного
спуска. Можно, конечно, использовать методы негладкой оптимизации, о которых шла речь в прошлом курсе,
но они сложны в реализации.
2.6.2. Оценка функции потерь
Используя любую гладкую оценку пороговой функции:

Mi < 0

≤ L˜(Mi)
можно построить оценку Q˜(a, X) для функционала ошибки Q(a, X):
Q(a, X) ≤ Q˜(a, X) = 1
`
X
`
i=1
L˜(Mi).
В этом случае минимизировать нужно будет не долю неправильных ответов, а некоторую другую функцию,
которая является оценкой сверху:
Q(a, X) ≤ Q˜(a, X) = 1
`
X
`
i=1
L˜(Mi) → min
a
.
Здесь используется предположение, что в точке минимума этой верхней оценки число ошибок также будет
минимально. Строго говоря, это не всегда так.
2.6.3. Примеры оценок функции потерь
Примерами таких оценок функции потерь являются:
• Логистическая функция потерь (используется в логистической регрессии, о которой пойдет речь позже
в данном курсе):
L˜(M) = log2

exp(−M)

• Экспоненциальная функция потерь:
L˜(M) = exp(−M)

• Кусочно-линейная функция потерь (используется в методе опорных векторов):
L˜(M) = max(0, 1 − M)
Mi
0
1
2
Рис. 2.8: Графики различных функций потерь: пороговая (красная линия), экспоненциальная (синяя), логистическая (оранжевая) и кусочно-линейная (серая).
2.6.4. Логистическая функция потерь
В случае логистической функции потерь функционал ошибки имеет вид:
Q˜(a, X) = 1
`
X
`
i=1
ln
exp(−Mi)

=
1
`
X
`
i=1
ln
exp(−yihw, xii)

.
Получившееся выражение является гладким, а, следовательно, можно использовать, например, метод градиентного спуска.
Следует обратить внимание, что в случае, если число ошибок стало равно нулю, все равно в ходе обучения
алгоритма линейной классификации будут увеличиваться отступы, то есть будет увеличиваться уверенность
в полученных результатах
