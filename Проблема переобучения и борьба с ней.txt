

Мы начинаем урок, посвящённый проблеме переобучения и вопросу оценивания качества алгоритмов. По итогам этого урока вы будете понимать, как оценить качество алгоритма на новых неизвестных данных, а также как сравнить много алгоритмов и выбрать из них лучший. А начнём урок мы с того, что разберёмся с тем, что такое переобучение, и почему это очень плохо. Давайте рассмотрим простой пример. Допустим, мы решаем задачу классификации и построили некоторый алгоритм, например, линейный классификатор, и измеряем долю ошибок на обучающей выборке. Допустим, она получилась 0.2, то есть мы допускаем ошибку на двадцати процентах объектов обучающей выборки. Предположим, что нас это устроило, и мы используем этот алгоритм дальше. Но как понять из того, что у него небольшая доля ошибок на обучении, извлёк ли он закономерности, может ли он хорошо работать на новых данных? На самом деле, никаких гарантий нет. Легко может оказаться, что мы возьмём новую выборку, применим к ней наш уже обученный алгоритм и получим, что доля ошибок на новой выборке равна 0.9, то есть алгоритм ошибается на 90 % объектов. Это никуда не годится. Значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из него закономерности и применить эти знания для классификации новых объектов. Но при этом, заметьте, что мы получили хорошее качество на обучении. То есть алгоритм как-то смог подогнаться под обучение, не извлекая из него закономерностей. Эта проблема и называется переобучение. Чтобы чуть лучше понять, в чём заключается переобучение, давайте рассмотрим классический пример про линейную регрессию. Итак, рассмотрим некоторую выборку. Объекты выборки обозначены синими точками, это одномерная выборка и сдача регрессии. По оси x отложено значение признака, по оси y — значение ответа. Истинная зависимость между ответом и признаком выглядит как зелёная кривая. Видно, что это такая нелинейная зависимость с двумя экстремумами. И давайте будем пробовать разные модели, с помощью которых будем пытаться предсказывать ответы. И начнём мы с константной регрессии, то есть алгоритм a(x) будет иметь вид w0, где w0 — некоторая константа. Настроив эту модель под данные, мы получим некоторую красную горизонтальную прямую, которая видно, что никуда не годится: она довольно плохо обобщает информацию. Эта проблема называется недообучением. Мы не смогли построить хороший алгоритм из-за того, что семейство алгоритмов слишком простое, оно не может уловить закономерности. Понятно, что решением является усложнение семейства алгоритмов. Хорошо, давайте рассмотрим линейную регрессию, то есть алгоритмы вида w0 + w1 * x. Настроив такой алгоритм под нашу выборку, мы всё ещё недообучимся. Видно, что получилось чуть лучше, но красная прямая всё ещё довольно плохо описывает наши данные, потому что она является линейной, а закономерность является нелинейной. Хорошо, давайте возьмём многочлен третьей степени. То есть алгоритм вида w0 + w1 * x + w2 * x² + w3 * x³, — многочлен третьей степени. Настроив его на нашу выборку, мы увидим, что полученный алгоритм, то есть красная кривая, очень хорошо приближает истинную зависимость. Скорее всего, нас устраивает такая модель. Мы её и оставим, будем ей пользоваться. Но при этом, смотрите, совпадение между красными и зелёными кривыми неидеальное. Что если ещё чуть-чуть усложнить алгоритм? Может, мы получим ещё более качественную модель. Хорошо, давайте возьмём многочлен девятой степени. И в этом случае мы получим вот такую закономерность. Видно, что восстановленная зависимость, красная кривая, — очень плохая. Да, она даёт идеальные ответы на всех объектах обучающей выборки, она проходит через все синие точки. Но при этом в любой другой точке ответ никуда не годится. Эти ответы никак не соответствуют истинной зелёной зависимости. Это является переобучением. Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие ответы на новых точках. Итак, мы выяснили, что недообучение — это проблема, в которой алгоритм имеет плохое качество и на обучающей выборке, и на новых данных. А переобучение — это проблема, при которой алгоритм имеет хорошее качественной обучение, но плохое качество о новых данных. При этом с недообучением понятно как бороться: нужно усложнять семейство алгоритмов, брать более сложные алгоритмы, например, многочлены высокой степени вместо линейных. А вот с переобучением всё сложнее. Дело в том, что хороший алгоритм, который хорошо обобщает информацию, будет иметь хорошее качественное обучение. Переобученный алгоритм тоже будет иметь хорошее качество на обучающей выборке. Отличаются они только по качеству на новых данных. Хороший алгоритм будет хорошо работать в новых данных, а переобученный — плохо. Получается, что, имея лишь обучающую выборку, а мы имеем лишь её в момент настройки алгоритма, мы не можем понять, переобучился он или нет. Нам нужна какая-то дополнительная информация или дополнительные данные, чтобы выявить переобучение. Мы приходим к нескольким подходам к выявлению переобучения. Например, можно откладывать часть выборки, не использовать её при обучении, и дальше уже обученный алгоритм проверять на этой отложенной выборке. Или, например, есть кросс-валидация — это усложнённая версия отложенной выборки, о которой мы будем говорить в этом уроке. Также есть некоторые меры сложности модели, которые позволяют без дополнительной выборки понять, получилась ли модель слишком сложной или нет. Об этом мы и поговорим в следующем видео. И в качестве небольшой затравки давайте посмотрим, что получилось, когда мы настраивали многочлен девятой степени. Заметьте, что, по сути, обучение такого многочлена — это обучение линейной регрессии над признаками x, x в квадрате, и так далее, до x в девятой степени, то есть над девятью признаками. И если посмотреть на веса модели, которая получилась, окажется, что порядок весов очень большой — это миллионы и десятки миллионов. Если же посмотреть на порядок весов в модели третьей степени (в многочлене третьей степени), которая хорошо подходила под данные, можно увидеть, что там порядок гораздо ниже. Таким образом, наверное, абсолютные значения весов как-то говорят о том, насколько сложная модель у нас получилась. Итак, мы с вами выяснили, что переобучение — это проблема, которая состоит в излишней подгонке алгоритма под обучающую выборку, из-за чего страдает его качество на новых данных. Также мы выяснили, что одним из симптомов переобучения линейных моделей являются большие веса в этих моделях, что мы будем использовать в следующем уроке, когда будем говорить про регуляризацию — способ борьбы с переобучением в линейных методах.

В этом видео мы поговорим про регуляризацию — способ борьбы с переобучением в линейных моделях. В прошлый раз мы с вами убедились, что мерой сложности или симптомом переобученности линейной модели являются большие веса при признаках. Например, когда мы пытались обучить полином 9-й степени под вот такую выборку, мы получали переобученную модель, коэффициенты которой были огромными — миллионы и десятки миллионов. Еще одна ситуация, в которой можно столкнуться с переобучением — это мультиколлинеарность. Так называется проблема, при которой признаки выборки являются линейно зависимыми, то есть есть некоторый вектор значений признака на всех объектах, который выражается через векторы других признаков. Или, иными словами, это означает, что существуют такие веса α1, ..., αd, что какой бы объект обучающей выборки xi мы не взяли, оказывается, что если мы просуммируем с этими коэффициентами все значения признаков на этом объекте xi, получим 0. Это, по сути, есть определение линейной зависимости. Более компактно это можно записать как равенство нулю скалярного произведения вектора коэффициентов α на вектор признаков xi. Итак, в чем проблема мультиколлинеарности? Давайте представим, что мы решаем некоторую оптимизационную задачу, например минимизируем среднеквадратичную ошибку, то есть средний квадрат отклонения прогноза от истинного ответа yt. И нашли оптимальную точку w* — точку, на которой достигается минимум этого функционала. Хорошо, а теперь давайте возьмем этот оптимальный вектор весов w* и прибавим к нему тот вектор коэффициентов α из определения линейной зависимости с некоторым множителем t, скалярным множителем. И давайте посмотрим, как будет выглядеть прогноз алгоритма с этим новым модифицированным вектором весов на некотором объекте x. Для этого нужно посчитать скалярное произведение вектора w* + tα на вектор x. По правилам скалярного произведения это выражение распадается на сумму двух скалярных произведений. Первое — это w* умножить на x, второе — это α умножить на x с некоторым скалярным множителем t. Но при этом давайте вспомним, что α умножить на x скалярное — это 0, просто по определению линейной зависимости. Получаем, что прогноз нашего модифицированного алгоритма равен w* умножить на x, то есть прогнозу исходного оптимального алгоритма. Значит, мы получили новый алгоритм с новым векторов весов, который во всем совпадает с исходным алгоритмом. Получается, что и значение функционала качества, функционала ошибки на этом алгоритме будет такое же — он тоже будет оптимальным. Итак, в случае с мультиколлинеарностью у нас бесконечно много оптимальных алгоритмов, при этом многие из них будут иметь очень большие значения весов, но далеко не все из них хорошо обобщают информацию, обладают хорошей обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением. Итак, мы выяснили, что симптомом переобучения являются большие веса в линейной модели — давайте будем штрафовать за это модель, чтобы бороться с переобучением. Делать это будем с помощью регуляризатора. Итак, допустим, есть некоторый функционал ошибки Q, которому на вход подаются, напомню, векторы весов w и выборка x. Будем прибавлять к нему квадратичный регуляризатор, то есть L2 — норму вектора весов, или просто сумму квадратов весов. И теперь заменим функционал ошибки на следующий: он будет представлять собой сумму исходного функционала Q и регуляризатора с некоторым коэффициентом λ. И будем минимизировать эту сумму. Ее минимизация приведет к тому, что мы хотим одновременно сделать ошибку на обучающей выборке как можно меньше, то есть минимизировать Q, но и при этом не слишком сильно увеличить веса при признаках, то есть не слишком сильно увеличить норму весов w. При этом у нас появляется новый параметр в модели — коэффициент регуляризации λ, который стоит перед своим регуляризатором. Чем больше мы делаем λ, тем менее сложные модели будут получаться. Если мы будем увеличивать λ все сильнее и сильнее, то в какой-то момент окажется, что оптимально просто занулить все веса, сделать их нулевыми. То есть слишком большая λ приведет к слишком простой константной модели. В то же время если λ делать маленькой, то есть риск переобучения, риск, что модель окажется слишком сложной. Таким образом, нужно искать некоторый баланс — выбирать λ такой, что, с одной стороны, она не допускает переобучения, с другой — позволяет делать модель достаточно сложной, чтобы уловить все закономерности в данных. Обычно λ подбирается по кросс-валидации, о которой будем говорить в следующем видео. А пока давайте выясним, какой смысл имеет добавление регуляризатора. Оказывается, что наша новая задача — Q + λ умножить на регуляризатор, и это мы минимизируем — эквивалентна условной задаче оптимизации, которая выглядит следующим образом. Мы минимизируем исходный функционал ошибки Q при ограничении. А ограничение состоит в том, что норма вектора весов не должна превосходить некоторую константу C. Получается, что мы решаем исходную задачу, но при этом ограничиваем по норме векторы весов, ровно то, что мы и хотели делать — штрафовать за слишком большую норму весов. Геометрически это означает, что если у нас есть некоторый функционал ошибки, который выпуклый и его линии уровня выглядят как-то вот так, то без регуляризатора мы бы просто искали минимум этого функционала — находили минимальную точку. После же добавления регуляризатора мы требуем, чтобы и решение находилось внутри некоторой круглой области с центром в 0. И теперь мы находим такое решение, которое находится внутри этой области и при этом как можно ближе к оптимальному решению без регуляризатора. Пока что мы говорили только про L2-регуляризатор — сумму квадратов весов. Он штрафует за сложность модели, и позволяет бороться с переобучение, и при этом является гладким и выпуклым, то есть его добавление к функционалу не будет усложнять процесс оптимизации, например, градиентный спуск. Но также есть L1-регуляризатор, который представляет собой L1-норму вектора весов, или просто сумму модулей весов. Он не является гладким — модуль не имеет производной в 0, то есть оптимизация функционала с таким регуляризатором будет затруднительна, но при этом такой регуляризатор обладает очень интересным свойством. Если использовать его, то часть весов в итоговом векторе весов будут нулевыми, то есть он производит отбор признаков — использует в модели не все признаки, а только самые важные из них. Это очень интересное свойство, которое часто пригождается на практике. Итак, мы обсудили, что большие веса в линейных моделях — это симптом переобучения. И для борьбы с этим переобучением можно пытаться «задавить» симптом, то есть штрафовать за слишком большие значения весов. Это можно делать с помощью L2-регуляризации, которая является самым частым выбором и штрафует за сложность модели. Или с помощью L1-регуляризации, которая чуть сложнее при оптимизации, но при этом позволяет отбирать признаки. В следующем видео мы поговорим про то, что такое кросс-валидация, и как оценивать качество алгоритма на новых данных.

В этом видео мы поговорим о том, как оценивать качество алгоритмов, как понимать, насколько хорошо алгоритм будет работать на новых данных. Как мы уже выясняли, например, переобучение сложно поймать только по обучающей выборке, и хороший алгоритм, который хорошо обобщает, и переобученный, будут показывать хорошее качество на обучении. И нужны какие-то дополнительные данные, дополнительная информация, чтобы понять, переобучился алгоритм или нет. Да, для этого еще можно использовать меры переобученности, например, регуляризатор — норму весов, но при этом все равно они не говорят о том, насколько хорошо алгоритм будет работать на новых данных. В этом видео мы попробуем понять, как предсказать, как понять, насколько хорошо он будет работать. То есть, например, какая у новых данных у алгоритма будет доля ошибок, если это классификация, или среднеквадратичная ошибка, если это задача регрессии. Понятно, что по обучающей выборке их оценивать нельзя, алгоритм подгонялся под обучающую выборку и, скорее всего, на ней значение качества будет неплохое. Самая простая идея того, как оценивать качество алгоритма, это построение отложенной выборки. Мы берем все данные, которые у нас есть, и разбиваем на две части. При этом первая выступает в качестве обучающей выборки, на нее мы настраиваем алгоритм, вторая выступает в качестве тестовой выборки, то есть на ней мы измеряем качество алгоритма, обученного на первой части. При этом мы измеряем качество как угодно, либо это среднеквадратичная ошибка, либо доля ошибок, либо что-то еще, в зависимости от специфики задачи. При этом сразу встает вопрос о том, в каких пропорциях разбивать данные на обучение и на тест. Если взять тестовую выборку слишком маленькой, отложенную выборку слишком маленькой, то, с одной стороны, обучающая выборка будет репрезентативной, и ее размер будет почти совпадать с размером настоящей обучающей выборки. Но, с другой, контрольная выборка, тестовая выборка, окажется слишком маленькой, в ней будет слишком мало объектов, чтобы надежно оценить качество, скорее всего, оценка качества будет зашумленной. Если же взять отложенную выборку слишком большой, то оценка по ней будет надежной, но, с другой стороны, обучение будет слишком маленьким, сильно меньше, чем настоящее обучение, и, например, мы можем увидеть качество очень небольшим, но из-за того, что обучения мало, что данных было слишком мало для обучения. Поэтому можно искать опять же какой-то баланс. Здесь нет конкретных советов, обычно берут разбиение в соотношении 70 к 30 или 80 к 20, где 70 и 80, соответственно, это размер обучения. Так же, например, есть подход, в котором размер обучающей выборки составляет 0,632 от общего размера данных. Преимуществом отложенной выборки является то, что обучать алгоритм нужно всего лишь один раз, на обучающей выборке. Но при этом результат очень сильно зависит от разбиения. Рассмотрим простой пример. Допустим, мы предсказываем стоимость жилья по некоторым характеристикам. И есть особая категория жилья, двухэтажные квартиры. Если вдруг окажется, что все двухэтажные квартиры, а их очень немного, попали в отложенную выборку, то мы увидим на них очень плохое качество, поскольку алгоритм не видел их на обучении, он ничего не знает о таких ситуациях и будет плохо предсказывать для них. При этом мы никогда не узнаем, что если бы хотя бы один такой объект оказался в обучении, то качество было бы гораздо лучше. Таким образом, результат измерения качества по отложенной выборке сильно зависит от того, как мы выбираем отложенную выборку, это не очень хорошо. Чтобы решить проблему, сразу приходит в голову следующий подход. Давайте много раз, n раз, разобьем все наши данные на обучение и тест, то есть много раз сгенерируем отложенную выборку. При этом каждый раз будем обучаться по обучающей выборке, измерять качество на отложенной выборке. Поскольку процедура повторяется n раз, мы получим n показателей качества, усредним их и получим итоговую оценку. Да, возможно, это уже решает проблему, но при этом, поскольку разбиения случайные, все еще нет гарантий, что каждый объект хотя бы раз побывает в обучении. Нужен более системный подход. Таким подходом является кросс-валидация. В ней предлагается следующее. Возьмем всю выборку и разобьем на k блоков примерно одинакового размера. И дальше каждый блок по очереди будет выступать в качестве тестового. Итак, сначала возьмем первый блок в качестве тестового, а все остальные в качестве обучения. Обучим алгоритм на обучающей выборке, измерим качество на тестовом блоке, запомним его. Далее возьмем второй блок в качестве тестового, все остальные сольем в обучающую выборку, обучимся и измерим качество, и так далее. Каждый блок побывает один раз тестовым, получим k показателей качества. Усредним их и получим оценку качества по кросс-валидации. При этом в кросс-валидации снова есть параметр, который нужно как-то выбирать, это число блоков k. Здесь ситуация примерно та же, что и с отложенной выборкой, если блоков мало, например, 3, то, с одной стороны, тестовая выборка при каждом разбиении на обучение и контроль, будет большой, то есть оценка по ней будет надежной, устойчивой, но при этом обучение окажется меньше, чем на самом деле, и есть риск, что оценка будет смещенной. Если же блоков мы берем много, то, с одной стороны, оценки ненадежные, тестовая выборка всегда маленькая, С другой стороны, оценки несмещенные, поскольку обучающая выборка всегда большая. Снова нет конкретных рекомендаций, каким выбирать k, обычно его берут равным трем, пяти или десяти, при этом, чем больше у вас данных, тем, как правило, меньше нужно больше блоков, потому что много блоков нужно, чтобы обучение было побольше, если у вас данных и так много, то даже удаление одной трети от всей выборки не приведет к тому, что у вас данных станет мало для обучения. При этом заметьте, что в кросс-валидации вам нужно обучать алгоритм k раз, поэтому опять же, если обучение алгоритма очень трудоемкое, очень много требует времени, то нужно брать k поменьше. Еще один совет, который относится ко всем этим способам. Всегда перемешивайте выборку перед тем, как делать отложенную выборку или кросс-валидацию. Дело в том, что в файле с данными выборка может быть отсортирована по какому-то неслучайному признаку. Например, сначала могут идти все мальчики, а потом все девочки. И если вы не перемешаете выборку и просто разобьете в соотношении 50 к 50, то получится, что в обучении у вас есть только мальчики, в контроле — только девочки, и, скорее всего, алгоритм будет показывать очень плохое качество, и вы долго будете пытаться понять, почему. Но при этом есть ситуации, в которых выборку нельзя перемешивать и нужно вполне понятным способом разбивать ее на обучение и контроль. Например, если вы строите алгоритм, который будет предсказывать погоду на следующие дни, понятно, что в момент, когда вы будете применять модель, у вас будет информация только о прошлом, и на основе нее нужно будет предсказывать будущее. Поэтому и когда вы будете разбивать выборку на обучение и тест, вам нужно следить, чтобы в обучении были дни, которые идут перед днями в тесте, иначе обучение будет заглядывать в будущее, и качество будет получаться завышенным. Итак, мы обсудили, что для грамотного оценивания качества алгоритма, нужно использовать данные не из обучающей выборки, для этого можно, например, делать отложенную выборку, или же оценивать качество по кросс-валидации. В следующем видео мы поговорим о том, как использовать эти подходы, чтобы сравнивать модели или выбирать гиперпараметры в них.

В этом видео мы поговорим о том, как выбирать гиперпараметры и сравнивать разные алгоритмы с помощью уже изученных нами схем — отложенной выборки или кросс-валидации. Давайте начнем с того, что разберемся, что такое гиперпараметры. Так называются те параметры алгоритмов, которые нельзя настраивать по обучающей выборке. Простым примером гиперпараметра является параметр регуляризации, поскольку регуляризатор штрафует модель и не дает ей слишком сильно подогнаться под обучающую выборку, понятно, что с точки зрения ошибки на обучение оптимально выставить параметр регуляризации в 0, то есть выключить регуляризатор. Другой пример гиперпараметра — это, например, степень полинома, с помощью которого мы описываем данные. В нашем примере про переобучение с точки зрения обучающей выборки оптимально было брать полином в степени 9, поскольку он проходил через через все точки обучения, давал нулевую ошибку на обучение. Но при этом понятно, что обобщающая способность у него была никакая. Более общая задача — это сравнение разных алгоритмов, например, сравнение качества алгоритмов, настроенных с разными значениями гиперпараметров. Или, предположим, вы можете настраивать алгоритмы на среднеквадратичную ошибку и на среднеабсолютную ошибку и пытаться понять, что из этого лучше. Или выбирать типы регуляризации: L2 или L1 — и тоже как-то сравнивать алгоритмы, обученные с разными видами регуляризации. Или сравнивать разные классы моделей, например, линейные модели и решающие деревья, которые будем изучать в следующем модуле. Всё это называется сравнением алгоритмов. Понятно, что для этого нужно использовать либо обучающую... либо отложенную выборку, либо кросс-валидацию, но при этом нужно соблюдать осторожность. Вот почему: давайте рассмотрим пример, в котором мы сравниваем тысячу разных типов алгоритмов с помощью отложенной выборки. Каждый их них мы обучаем на обучающей выборке, измеряем качество на отложенной выборке и дальше выбираем из них лучшие по качеству на отложенной выборке. При этом заметьте, что отложенная выборка, по сути, превратилась в обучающую. У нас было большое семейство алгоритмов, и мы из них выбрали лучшие отложенные выборки. По сути, мы подогнались под нее, и у нас снова появился риск переобучения под отложенную выборку. Чтобы бороться с этим, нужно немножко усовершенствовать нашу схему оценивания качества. Разобьем все данные на три части: на обучение, валидацию и контроль. Каждый из нашей тысячи алгоритмов будем обучать на обучающей выборке и измерять качество на валидационной выборке. Получим тысячу показателей качества и по ним выберем лучший из этой тысячи алгоритмов — тот, который допускает наименьшую ошибку. После того, как лучший алгоритм выбран, мы измерим его качество на контрольной выборке и проверим его на адекватность, то есть что оно устраивает нас. По сути, именно контрольная выборка будет играть роль новых данных. Например, можно проверять, что доля ошибки не слишком большая и отличается от одной второй, то есть от случайного угадывания, от подбрасывания монетки. Или что среднеквадратичная ошибка лучше, чем у константного алгоритма. Если же в вашей схеме предпочтительней использовать кросс-валидацию, нужно разбить выборку на две части. Одна — это контрольная, на которой будет измеряться качество итогового алгоритма, а другая — та, на которой будет делаться кросс-валидация. То есть по стандартной схеме разбивается на K блоков, каждый блок по очереди выступает в качестве контрольного, на нём измеряется качество, а алгоритмы обучены по всем остальным блокам. После того как по кросс-валидации выбран лучший из множества алгоритм, его адекватность измеряется на контрольной выборке. Итак, мы выяснили, что для выбора гиперпараметров или сравнения алгоритмов нужно использовать стандартные схемы: отложенную выборку или кросс-валидацию. Но при этом, если вы сравниваете очень много разных моделей, есть риск переобучения, и чтобы его избежать, нужно выделять контрольную выборку, на которой вы проверяете итоговый алгоритм на адекватность. На этом урок про сравнение моделей заканчивается, и вы узнали много нового. Например, как использовать регуляризацию, чтобы бороться с переобучением линейных моделей, или как строить схему проверки качества, которая позволит понять, насколько хорошо алгоритм будет работать на новых данных.

Проблема переобучения и борьба с
ней
3.1. Проблема переобучения
3.1.1. Пример: проблема переобучения в задачах классификации
Допустим при решении задачи классификации был построен некоторый алгоритм, например линейный классификатор, причем доля ошибок на объектах из обучающей выборки была равна 0.2, и такая доля ошибок
является допустимой.
Но поскольку алгоритм не обладает обобщающей способностью, нет никаких гарантий, что такая же
доля ошибок будет для новой выборки. Вполне может возникнуть ситуация, что для новой выборки ошибка
станет равной 0.9. Это значит, что алгоритм не смог обобщить обучающую выборку, не смог извлечь из
нее закономерности и применить их для классификации новых объектов. При этом алгоритм как-то смог
подогнаться под обучающую выборку и показал хорошие результаты при обучении без извлечения истинной
закономерности. В этом и состоит проблема переобучения.
3.1.2. Пример: проблема переобучения в задачах линейной регрессии
Глубже понять проблему переобучения можно на данном примере. На следующем графике изображена истинная зависимость и объекты обучающей выборки:
0 1 2 3 4 5 6 7 8 9
4
2
0
2
4
Рис. 3.1: Истинная зависимость (зеленая линия) и элементы обучающей выборки (изображены синими точками).
Видно, что истинная зависимость является нелинейной и имеет два экстремума.
1
В модели a(x) = w0, после того, как она будет настроена под данные, на графике получается некоторая
горизотальная кривая, которая довольно плохо обобщает информацию об объектах из выборки.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.2: Модель a(x) = w0.
Имеет место недообучение. Хороший алгоритм не был построен, поскольку семейство алгоритмов слишком
мало и с его помощью невозможно уловить закономерность.
В линейной регрессии используется семейство алгоритмов a(x) = w0 + w1x.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.3: Модель a(x) = w0 + w1x.
В этом случае также будет иметь место недообучение. Получилось лучше, но прямая тоже плохо описывает
данные.
Если семейство алгоритмов — множество многочленов 4-ей степени:
a(x) = w0 + w1x + w2x
2 + ... + w4x
4
,
то после обучения получившаяся кривая будет достаточно хорошо описывать и обучающую выборку, и истинную зависимость.
2
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.4: Модель a(x) = w0 + w1x + w2x
2 + ... + w4x
4
.
В таком случае качество алгоритма хорошее, но нет идеального совпадения. Встает вопрос, а можно ли
добиться совпадения увеличением сложности алгоритма.
При использовании многочленов 9-ой степени уже имеет место переобучение.
0 1 2 3 4 5 6 7 8 9
10
5
0
5
10
Рис. 3.5: Модель a(x) = w0 + w1x + w2x
2 + ... + w9x
9
.
Восстановленная зависимость дает идеальные ответы на всех объектах обучающей выборки, но при этом в
любой другой точке сильно отличается от истинной зависимости. Такая ситуация называется переобучением.
Алгоритм слишком сильно подогнался под обучающую выборку ценой того, что он будет давать плохие
ответы на новых точках.
3.1.3. Недообучение и переобучение
Таким образом, недообучение — ситуация, когда алгоритм плохо описывает и обучающую выборку, и новые
данные. В этом случае алгоритм необходимо усложнять.
В случае переобучения, данные из обучающей выборки будут описываться хорошо, а новые данные плохо.
Выявить переобучение, используя только обучающую выборку, невозможно, поскольку и хорошо обученный,
и переобученный алгоритмы будут хорошо ее описывать. Необходимо использовать дополнительные данные.
Существуют несколько подходов к выявлению переобучения:
• Отложенная выборка. Часть данных из обучающей выборки не участвуют в обучении, чтобы позже
проверять на ней обученный алгоритм.
• Кросс-валидация, несколько усложненный метод отложенной выборки. (Об этом способе речь пойдет
позже.)
3
• Использовать меры сложности модели. Об этом пойдет речь далее.
3.2. Регуляризация
В этом разделе речь пойдет о регуляризации — способе борьбы с переобучением в линейных моделях.
3.2.1. «Симптомы» переобучения. Мультиколлинеарность.
Мерой сложности, то есть «симптомом» переобученности модели, являются большие веса при признаках.
Например, в предыдущем разделе при обучении модели
a(x) = w0 + w1x + w2x
2 + ... + w9x
9
веса оказывались огромными:
a(x) = 0.5 + 12458922x + 43983740x
2 + ... + 2740x
9
.
Другая ситуация, в которой можно встретиться с переобучением — мультиколлинеарность. Так называется
проблема, при которой признаки в выборке являются линейно зависимыми. Другими словами, существуют
коэффициенты α1, ..., αd такие, что для любого объекта xi из выборки выполняется:
α1x
1
i + ... + αdx
d
i = 0.
Более компактно последнее выражение можно переписать в виде:
hα, xii = 0.
Допустим, было найдено решение задачи оптимизации:
w∗ = argminw
1
`
X
`
i=1

hw, xii − yi
2
Другой вектор весов, полученный сдвигом в направлении вектора α:
w1 = w∗ + tα,
так как для элементов x выборки выполняется:
hw∗ + tα, xi = hw∗, xi + thα, xi = hw∗, xi,
также будет являться решением задачи оптимизации. Другими словами, он будет также хорошо описывать
данные в выборке, как и исходный алгоритм. Фактически, решениями задачи оптимизации являются бесконечное множество алгоритмов, но многие из них имеют большие веса, и далеко не все обладают хорошей
обобщающей способностью. Поэтому здесь тоже легко столкнуться с переобучением.
3.2.2. Регуляризация
Выше было продемонстрировано, что если веса в линейной модели большие, существует высокий риск переобучения. Чтобы бороться с этим, минимизируется уже не выражение для функционала ошибки Q(a, X), а
новый функционал, получаемый прибавлением регуляризатора. Самый простой регуляризатор — квадратичный регуляризатор:
kwk
2 =
X
d
j=1
w
2
j
.
В этом случае имеет место следующая задача оптимизации:
Q(w, X) + λkwk
2 → min
w
.
Таким образом, при обучении будет учитываться также то, что не следует слишком сильно увеличивать веса
признаков.

3.2.3. Коэффициент регуляризации
Введенный выше коэффициент λ, который стоит перед регуляризатором, называется коэффициентом регуляризации. Чем больше λ, тем ниже сложность модели. Например, при очень больших его значениях оптимально
просто занулить все веса. В то же время при слишком низких значениях λ высок риск переобучения, то есть
модель становится слишком сложной.
Поэтому нужно найти некоторое оптимальное значение λ, достаточно большое, чтобы не допустить переобучения, и не очень большое, чтобы уловить закономерности в данных. Обычно λ подбирается на кроссвалидации, о которой пойдет речь в следующем разделе.
3.2.4. Смысл регуляризации
Чтобы понять смысл регуляризации, вместо задачи оптимизации с квадратичным оптимизатором нагляднее
рассмотреть задачу условной оптимизации:
(
Q(w, X) → min
w
kwk
2 ≤ C
Добавление регуляризатора вводит требование, чтобы решение задачи минимизации искалось в некоторой
круглой области с центром в нуле.
W1
W2
W∗
Рис. 3.6: Геометрический смысл условной регуляризации. Красная точка — настоящий оптимум функции,
красные линии — линии уровня функции, черная точка — оптимум функции при введенном ограничении.
Таким образом, решение задачи с регуляризатором не будет характеризоваться слишком большими значениями весовых коэффициентов.
3.2.5. Виды регуляризаторов
Рассмотренный выше квадратичный регуляризатор (L2-регуляризатор) является гладким и выпуклым, что
позволяет использовать градиентный спуск.
Также существует L1-регуляризатор:
kwk1 =
X
d
j=1
|wj |,
который представляет собой L1-норму вектора весов. Он уже не является гладким, а также обладает интересным свойством. Если применять такой регуляризатор, некоторые веса оказываются равными нулю. Другими
словами, такой регуляризатор производит отбор признаков и позволяет использовать в модели не все признаки, а только самые важные из них.
5
3.3. Оценка качества алгоритмов. Кросс-валидация
В этом разделе речь пойдет об оценке качества алгоритмов и о том, как понять, как поведет себя алгоритм
на новых данных.
3.3.1. Выявление переобучения
Уже было сказано, что переобучение сложно выявить, используя только обучающую выборку: и хороший, и
переобученный алгоритмы будут показывать хорошее качество на объектах обучающей выборки. Рассмотренные в предыдущем разделе меры переобученности (значения регуляризаторов), безусловно, можно применять,
но они не дают ответа на вопрос, насколько хорошо алгоритм поведет себя на новых данных, то есть какая
у него будет доля ошибок на новых данных.
3.3.2. Отложенная выборка
Самый простой способ оценить качество алгоритма — использование отложенной выборки. В этом случае
следует разбить выборку на две части: первая из двух частей будет использоваться для обучения алгоритма,
а вторая, тестовая выборка, — для оценки его качества, в том числе для нахождения доли ошибок в задаче
классификации, MSE (среднеквадратичной ошибки) в задаче регрессии и других мер качества в зависимости
от специфики задачи.
Естественный вопрос — о том, в какой пропорции производить разбиение. Если взять тестовую выборку
слишком маленькой, оценка качества будет ненадежной, хотя обучающая выборка будет почти совпадать
с полной выборкой. В противоположенном случае, если отложенная часть будет большой, оценка качества
будет надежной, но низкое качество алгоритма может свидетельствовать о недостаточном объёме первой,
обучающей, части выборки. Обычно выборку разбивают в соотношениях 70/30, 80/20 или 0.632/0.368.
Преимуществом отложенной выборки является то, что обучать алгоритм приходится всего лишь один раз,
но при этом результат сильно зависит от того, как было произведено разбиение.
Например, оценивается стоимость жилья по некоторым признакам. И есть особая категория жилья, например двухэтажные квартиры. И если окажется, что все двухэтажные квартиры, которых немного, попали
в отложенную выборку, то после обучения алгоритм будет давать на них очень плохое качество, поскольку в
обучающей выборке таких объектов не было.
Чтобы решить эту проблему, можно использовать следующий подход: построить n различных разбиений
выборки на 2 части, для каждого разбиения найти оценку качества, а в качестве итоговой оценки качества
работы алгоритма использовать усредненное по всем разбиениям значение. Но и в данном случае, поскольку
разбиения строятся случайно, нет никаких гарантий, что особый объект хотя бы раз попадет на обучение.
3.3.3. Кросс-валидация
Более системный подход — кросс валидация. В этом случае выборка делится на k блоков примерно одинакового размера. Далее по очереди каждый из этих блоков используется в качестве тестового, а все остальные
— в качестве обучающей выборки.
После того, как каждый блок побывает в качестве тестового, будут получены k показателей качества. В
результате усреднения получается оценка качества по кросс-валидации.
При этом встает вопрос, какое число блоков использовать. Если блоков мало, получаются надежные, но
смещенные оценки. В случае большого числа блоков оценки, наоборот, получаются ненадежными (большой
разброс оценок), но несмещенными.
Нет конкретных рекомендаций относительно выбора k. Обычно выбирают k = 3, 5, 10. Чем больше k,
тем больше раз приходится обучать алгоритм. Поэтому на больших выборках следует выбирать небольшие
значения k, так как даже при удалении 1/3 выборки (а она большая) оставшихся данных будет достаточно
для обучения.
3.3.4. Совет: перемешивайте данные в выборке
Часто данные в файле записаны в отсортированном виде по какого-нибудь признаку. Поэтому всегда следует
перемешивать выборку прежде, чем производить кросс-валидацию. В ином случае алгоритм будет показывать
плохое качество и причина этого будет не так очевидна.
6
При этом есть задачи, в которых выборку нельзя перемешивать. Это задачи предсказания будущего,
например предсказание погоды на следующий день. В этом случае нужно особо следить за тем, как происходит
деление выборки.
3.4. Выбор гиперпараметров и сравнение алгоритмов
В этом разделе речь пойдет о выборе гиперпараметров и сравнении различных алгоритмов с помощью изученных ранее схем.
3.4.1. Гиперпараметры
Гиперпараметрами называются такие параметры алгоритмов, которые не могут быть получены из обучающей
выборки при обучении, поэтому их надо подбирать путем многократного обучения алгоритма. Примерами
гиперпараметров являются:
• Параметр регуляризации λ (при использовании регуляризатора)
• Степень полинома в задаче регрессии с семейством алгоритмов, заданным множеством полиномов определенной степени.
3.4.2. Сравнение разных алгоритмов
Более общая задача — сравнение разных алгоритмов:
• обученных с разными значениями гиперпараметров;
• использующих различный способ регуляризации;
• настроенных с использованием разного функционала ошибки, например среднеквадратичной ошибки и
средней абсолютной ошибки;
• которые принадлежат разным классам алгоритмов.
При сравнении алгоритмов можно использовать как отложенную выборку, так и кросс-валидацию, но при
этом следует соблюдать осторожность.
Действительно, пусть 1000 алгоритмов сравниваются по качеству на отложенной выборке. Каждый из
1000 алгоритмов, обученных на обучающей выборке, тестируется на отложенной, и в результате выбирается
лучший. Фактически на этом шаге отложенная выборка также становится своего рода обучающей, и возникает
проблема переобучения: из большого числа алгоритмов выбирается тот, который лучше всего ведет себя на
отложенной выборке, лучше подогнан под нее.
3.4.3. Улучшенная схема сравнения алгоритмов
Чтобы бороться с этим, следует использовать несколько усовершенствованную схему оценивания качества
алгоритмов, а именно все данные нужно будет делить на 3 части (в случае использования отложенной выборки): обучение, валидация и контроль. Каждый из тысячи алгоритмов будет обучен на обучающей выборке, а
его качество будет измерено на валидационной. Алгоритм с наилучшим качеством будет проверен на тестовой
выборке, чтобы исключить переобучение и проверить алгоритм на адекватность. По сути именно тестовая
выборка будет играть роль новых данных.
Если предпочтительно использовать кросс-валидацию, то данные следует разбить на 2 части. Первая из
них будет использоваться для обучения алгоритмов и оценки качества с помощью кросс-валидации, после
чего лучший алгоритм будет проверен на адекватность на контрольной выборке.
